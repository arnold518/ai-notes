
<!doctype html>
<html lang="ko" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.12">
    
    
      
        <title>§ 11. Variational Autoencoders - Artificial Intelligence Notes</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.2afb09e1.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      
  
  
    
    
  
    
    
  
  
  <style>:root{--md-admonition-icon--note:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2024%2024%22%3E%3Cpath%20d%3D%22M12%206a6%206%200%200%201%206%206c0%202.22-1.21%204.16-3%205.2V19a1%201%200%200%201-1%201h-4a1%201%200%200%201-1-1v-1.8c-1.79-1.04-3-2.98-3-5.2a6%206%200%200%201%206-6m2%2015v1a1%201%200%200%201-1%201h-2a1%201%200%200%201-1-1v-1zm6-10h3v2h-3zM1%2011h3v2H1zM13%201v3h-2V1zM4.92%203.5l2.13%202.14-1.42%201.41L3.5%204.93zm12.03%202.13%202.12-2.13%201.43%201.43-2.13%202.12z%22/%3E%3C/svg%3E');--md-admonition-icon--tip:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20512%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%206.7.2%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202024%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M256%200a256%20256%200%201%201%200%20512%20256%20256%200%201%201%200-512m-24%20120v136c0%208%204%2015.5%2010.7%2020l96%2064c11%207.4%2025.9%204.4%2033.3-6.7s4.4-25.9-6.7-33.3L280%20243.2V120c0-13.3-10.7-24-24-24s-24%2010.7-24%2024%22/%3E%3C/svg%3E');}</style>



    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:300,300i,400,400i,700,700i%7CUbuntu+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Noto Sans";--md-code-font:"Ubuntu Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="deep-orange" data-md-color-accent="deep-orange">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#11-variational-autoencoders" class="md-skip">
          콘텐츠로 이동
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="상단/헤더">
    <a href="../../.." title="Artificial Intelligence Notes" class="md-header__button md-logo" aria-label="Artificial Intelligence Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Artificial Intelligence Notes
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              § 11. Variational Autoencoders
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="deep-orange" data-md-color-accent="deep-orange"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="deep-orange" data-md-color-accent="deep-orange"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="검색" placeholder="검색" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="검색">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="공유" aria-label="공유" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="지우기" aria-label="지우기" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            검색 초기화
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/arnold518/ai-notes" title="저장소로 이동" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    arnold518/ai-notes
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="탭" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../format/" class="md-tabs__link">
          
  
  
    
  
  Books & Courses

        </a>
      </li>
    
  

    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="네비게이션" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Artificial Intelligence Notes" class="md-nav__button md-logo" aria-label="Artificial Intelligence Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Artificial Intelligence Notes
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/arnold518/ai-notes" title="저장소로 이동" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    arnold518/ai-notes
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Books & Courses
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Books & Courses
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../format/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Mathematical Foundations of Deep Neural Networks
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            Mathematical Foundations of Deep Neural Networks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_2" >
        
          
          <label class="md-nav__link" for="__nav_2_1_2" id="__nav_2_1_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Ch 1. Optimization and Stochastic Gradient Descent
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_2">
            <span class="md-nav__icon md-icon"></span>
            Ch 1. Optimization and Stochastic Gradient Descent
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../format/1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1. Optimization Problem
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../format/2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2. Gradient Descent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/1PSpoeseUPIptYQOPuQpxNawxtZbVR_K6/view?usp=sharing" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter 1 Code
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_3" >
        
          
          <label class="md-nav__link" for="__nav_2_1_3" id="__nav_2_1_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Ch 2. Shallow Neural Networks to Multilayer Perceptrons
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_3">
            <span class="md-nav__icon md-icon"></span>
            Ch 2. Shallow Neural Networks to Multilayer Perceptrons
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../format/3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3. Shallow Neural Networks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../format/4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4. Deep Neural Networks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/15kXC3cJUV63gZNfXK6JdPPuSrwQZBzI8/view?usp=sharing" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter 2 Code
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_4" >
        
          
          <label class="md-nav__link" for="__nav_2_1_4" id="__nav_2_1_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Ch 3. Convolutional Neural Networks
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_4">
            <span class="md-nav__icon md-icon"></span>
            Ch 3. Convolutional Neural Networks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../format/5/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    5. Convolutional Neural Networks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../format/6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    6. Foundations of Design and Training of Deep Neural Networks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../format/7/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    7. ImageNet Challenge
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/12O9fLasWDA-kOKBD-lE-1UhCl-PoDf0z/view?usp=sharing" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter 3 Code
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_5" >
        
          
          <label class="md-nav__link" for="__nav_2_1_5" id="__nav_2_1_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Ch 4. CNNs for Other Supervised Learning Tasks
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_5">
            <span class="md-nav__icon md-icon"></span>
            Ch 4. CNNs for Other Supervised Learning Tasks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../format/8/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    8. CNNs for Other Supervised Learning Tasks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/16IOKVF6IiDMyUvL73pGKBaEMKyXvezLB/view?usp=sharing" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter 4 Code
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_6" >
        
          
          <label class="md-nav__link" for="__nav_2_1_6" id="__nav_2_1_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Ch 5. Unsupervised Learning
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_6">
            <span class="md-nav__icon md-icon"></span>
            Ch 5. Unsupervised Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../format/9/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    9. Autoencoder
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../format/10/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    10. Flow Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../format/11/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    11. Variational Autoencoders
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../format/12/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    12. Generative Adversarial Networks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/1JM5k-e6LkhZ0vXRlfROWpiuw4YC85Jv1/view?usp=sharing" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter 5 Code
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_7" >
        
          
          <label class="md-nav__link" for="__nav_2_1_7" id="__nav_2_1_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Ch A. Appendix - Basics of Monte Carlo
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_7">
            <span class="md-nav__icon md-icon"></span>
            Ch A. Appendix - Basics of Monte Carlo
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../format/13/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    13. Basics of Monte Carlo
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/18b01xoORd0LFQmpfc_4ou5Rv44MY1neg/view?usp=sharing" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter A Code
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_8" >
        
          
          <label class="md-nav__link" for="__nav_2_1_8" id="__nav_2_1_8_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Python Basics
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_8">
            <span class="md-nav__icon md-icon"></span>
            Python Basics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/1-iY9XfDhWNRDq3z_wVVvOzU04aRQWAfW/view?usp=drive_link" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Python Lecture 1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/1BANbCC6jBjPEUFSRJMFkcLbc4oVmoQHm/view?usp=sharing" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Python Lecture 2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/1-Bc11RZmno6yx37kfVLjsyY-XKpLK5Je/view?usp=drive_link" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Python Lecture 3
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="목차">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      목차
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#latent-variable-model" class="md-nav__link">
    <span class="md-ellipsis">
      Latent Variable Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-latent-variable-model-with-importance-sampling" class="md-nav__link">
    <span class="md-ellipsis">
      Training Latent Variable Model with Importance Sampling
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#definition-of-vae" class="md-nav__link">
    <span class="md-ellipsis">
      Definition of VAE
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vae-standard-instance" class="md-nav__link">
    <span class="md-ellipsis">
      VAE Standard Instance
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-vae" class="md-nav__link">
    <span class="md-ellipsis">
      Training VAE
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#researches" class="md-nav__link">
    <span class="md-ellipsis">
      Researches
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="11-variational-autoencoders">§ 11. Variational Autoencoders<a class="headerlink" href="#11-variational-autoencoders" title="Permanent link">&para;</a></h1>
<p><strong>Prerequisites</strong> : <a href="../13/">Ch A. Appendix - Basics of Monte Carlo</a></p>
<div class="admonition concept">
<p class="admonition-title">Concept 11.1 : Math Review : Conditional Probabilities</p>
<p>Let <span class="arithmatex">\(A\)</span> and <span class="arithmatex">\(B\)</span> be probabilistic events. Assume <span class="arithmatex">\(A\)</span> has nonzero probability.</p>
<p><strong>Conditional probability</strong> satisfies</p>
<div class="arithmatex">\[
\mathbb{P}(B \mid A) \mathbb{P}(A)=\mathbb{P}(A \cap B)
\]</div>
<p><strong>Bayes' theorem</strong> is an application of conditional probability:</p>
<div class="arithmatex">\[
\mathbb{P}(B \mid A)=\frac{\mathbb{P}(A \mid B) \mathbb{P}(B)}{\mathbb{P}(A)}
\]</div>
</div>
<div class="admonition concept">
<p class="admonition-title">Concept 11.2 : Math Review: Conditional Densities</p>
<p>Let <span class="arithmatex">\(X \in \mathbb{R}^{m}\)</span> and <span class="arithmatex">\(Z \in \mathbb{R}^{n}\)</span> be continuous random variables with joint density <span class="arithmatex">\(p(x, z)\)</span>.</p>
<p>The marginal densities are defined by</p>
<div class="arithmatex">\[
p_{X}(x)=\int_{\mathbb{R}^{n}} p(x, z) d z, \quad p_{Z}(z)=\int_{\mathbb{R}^{m}} p(x, z) d x
\]</div>
<p>The conditional density function <span class="arithmatex">\(p(z \mid x)\)</span> has the following properties</p>
<div class="arithmatex">\[
\begin{gathered}
\mathbb{P}(Z \in S \mid X=x)=\int_{S} p(z \mid x) d z \\
p(z \mid x) p_{X}(x)=p(x, z), \quad p(z \mid x)=\frac{p(x \mid z) p_{Z}(z)}{p_{X}(x)}
\end{gathered}
\]</div>
</div>
<div class="admonition concept">
<p class="admonition-title">Concept 11.3 : Introduction for Variational Autoencoders (VAE)</p>
<p>Key idea of <strong>VAE</strong>:</p>
<ul>
<li><strong>Latent variable model</strong> with conditional probability distribution represented by <span class="arithmatex">\(p_{\theta}(x \mid z)\)</span>.</li>
<li>Efficiently estimate <span class="arithmatex">\(p_{\theta}(x)=\mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}(x \mid Z)\right]\)</span> by <strong>importance sampling</strong> with <span class="arithmatex">\(Z \sim q_{\phi}(z \mid x)\)</span>.</li>
</ul>
<p>We can interpret <span class="arithmatex">\(q_{\phi}(z \mid x)\)</span> as an encoder and <span class="arithmatex">\(p_{\theta}(x \mid z)\)</span> as a decoder.</p>
<p>VAEs differ from autoencoders as follows:</p>
<ul>
<li>Derivations (latent variable model vs. dimensionality reduction)</li>
<li>VAE regularizes/controls latent distribution, while AE does not.</li>
</ul>
</div>
<center>
![](./assets/11.1.png){: width="80%"}
</center>

<p>These are synthetic (fake) images made with VAE.</p>
<p>(A. Vahdat and J. Kautz, NVAE: A deep hierarchical variational autoencoder, NeurIPS, 2020.)</p>
<h2 id="latent-variable-model">Latent Variable Model<a class="headerlink" href="#latent-variable-model" title="Permanent link">&para;</a></h2>
<ul>
<li>
<p>Assumption on data <span class="arithmatex">\(X_{1}, \ldots, X_{N}\)</span></p>
<p>Assumes there is an underlying latent variable <span class="arithmatex">\(Z\)</span> representing the "essential structure" of the data and an observable variable <span class="arithmatex">\(X\)</span> which generation is conditioned on <span class="arithmatex">\(Z\)</span>. Implicitly assumes the conditional randomness of <span class="arithmatex">\(X \sim p_{X \mid Z}\)</span> is significantly smaller than the overall randomness <span class="arithmatex">\(X \sim p_{X}\)</span>.</p>
</li>
<li>
<p>Example</p>
<p><span class="arithmatex">\(X\)</span> is a cat picture. <span class="arithmatex">\(Z\)</span> encodes information about the body position, fur color, and facial expression of a cat. Latent variable <span class="arithmatex">\(Z\)</span> encodes the overall content of the image, but <span class="arithmatex">\(X\)</span> does contain details not specified in <span class="arithmatex">\(Z\)</span>.</p>
</li>
</ul>
<div class="admonition definition">
<p class="admonition-title">Definition 11.4 : Latent Variable Model</p>
<p>VAEs implements a <strong>latent variable model</strong> with a NN that generates <span class="arithmatex">\(X\)</span> given <span class="arithmatex">\(Z\)</span>. More precisely, NN is a deterministic function that outputs the conditional distribution <span class="arithmatex">\(p_{\theta}(x \mid Z)\)</span>, and <span class="arithmatex">\(X\)</span> is randomly generated according to this distribution. This structure may effectively learn the latent structure from data if the assumption on data is accurate.</p>
<hr />
<p><center>
<img alt="" src="../assets/11.2.png" width="20%" />
</center></p>
<p>Sampling process:</p>
<div class="arithmatex">\[
X \sim p_{\theta}(x \mid Z), \quad Z \sim p_{Z}(z)
\]</div>
<p>Usually <span class="arithmatex">\(p_{Z}\)</span> is a Gaussian (fixed) and <span class="arithmatex">\(p_{\theta}(x \mid z)\)</span> is a NN parameterized by <span class="arithmatex">\(\theta\)</span>.</p>
<p>Evaluating density (likelihood):</p>
<div class="arithmatex">\[
p_{\theta}\left(X_{i}\right)=\int_{z} p_{Z}(z) p_{\theta}\left(X_{i} \mid z\right) d z=\mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}\left(X_{i} \mid Z\right)\right]
\]</div>
<p>Training via MLE:</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \log p_{\theta}\left(X_{i}\right)=\underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \log \mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}\left(X_{i} \mid Z\right)\right]
\]</div>
<hr />
<p>When <span class="arithmatex">\(p_{Z}\)</span> is a discrete:</p>
<div class="arithmatex">\[
p_{\theta}(x)=\mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}(x \mid Z)\right]=\sum_{z} p_{Z}(z) p_{\theta}(x \mid Z)
\]</div>
<p>When <span class="arithmatex">\(p_{Z}\)</span> is a continuous:</p>
<div class="arithmatex">\[
p_{\theta}(x)=\mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}(x \mid Z)\right]=\int_{z} p_{Z}(z) p_{\theta}(x \mid z) d z
\]</div>
<p>To clarify, specification of <span class="arithmatex">\(p_{Z}(z)\)</span> and <span class="arithmatex">\(p_{\theta}(x \mid z)\)</span> fully determines <span class="arithmatex">\(p_{\theta}(x)\)</span> (as above) and</p>
<div class="arithmatex">\[
p_{\theta}(z \mid x)=\frac{p_{\theta}(x \mid z) p_{Z}(z)}{p_{\theta}(x)}
\]</div>
<hr />
<p>Training</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \log p_{\theta}\left(X_{i}\right)=\underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \log \mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}\left(X_{i} \mid Z\right)\right]
\]</div>
<p>requires evaluation <span class="arithmatex">\(\mathbb{E}_{Z}\)</span>.</p>
<ul>
<li>Scenario 1: If <span class="arithmatex">\(Z\)</span> is discrete and takes a few of values, then compute <span class="arithmatex">\(\sum_{z}\)</span> exactly.</li>
<li>Scenario 2: If <span class="arithmatex">\(Z\)</span> takes many values or if it is a continuous, then <span class="arithmatex">\(\sum_{z}\)</span> or <span class="arithmatex">\(\mathbb{E}_{Z}\)</span> is impractical to compute. In this case, approximate expectation with Monte Carlo and importance sampling.</li>
</ul>
</div>
<div class="admonition example">
<p class="admonition-title">Example 11.5 : Example Latent Variable Model: Mixture of Gaussians</p>
<p>Mixture of 3 Gaussians in <span class="arithmatex">\(\mathbb{R}^{2}\)</span>, uniform prior over components. (We can make the mixture weights a trainable parameter.)</p>
<div class="arithmatex">\[
\begin{gathered}
p_{Z}(Z=A)=p_{Z}(Z=B)=p_{Z}(Z=C)=\frac{1}{3} \\
p_{\theta}(x \mid Z=k)=\frac{1}{2 \pi\left|\Sigma_{k}\right|^{\frac{1}{2}}} \exp \left(-\frac{1}{2}\left(x-\mu_{k}\right)^{\top} \Sigma_{k}^{-1}\left(x-\mu_{k}\right)\right)
\end{gathered}
\]</div>
<p>Training objective:</p>
<div class="arithmatex">\[
\begin{aligned}
\underset{\mu, \Sigma}{\operatorname{maximize}} \sum_{i=1}^{N} \log p_{\theta}\left(X_{i}\right)=\underset{\mu, \Sigma}{\operatorname{maximize}} \sum_{i=1}^{N} \log &amp; \left[ \frac{1}{3} \frac{1}{2 \pi\left|\Sigma_{A}\right|^{\frac{1}{2}}} \exp \left(-\frac{1}{2}\left(X_{i}-\mu_{A}\right)^{\top} \Sigma_{A}^{-1}\left(X_{i}-\mu_{A}\right)\right) \right.\\
&amp; +\frac{1}{3} \frac{1}{2 \pi\left|\Sigma_{B}\right|^{\frac{1}{2}}} \exp \left(-\frac{1}{2}\left(X_{i}-\mu_{B}\right)^{\top} \Sigma_{B}^{-1}\left(X_{i}-\mu_{B}\right)\right) \\
&amp; \left.+\frac{1}{3} \frac{1}{2 \pi\left|\Sigma_{C}\right|^{\frac{1}{2}}} \exp \left(-\frac{1}{2}\left(X_{i}-\mu_{C}\right)^{\top} \Sigma_{C}^{-1}\left(X_{i}-\mu_{C}\right)\right)\right]
\end{aligned}
\]</div>
<p><center>
<img alt="" src="../assets/11.3.png" width="100%" />
</center></p>
</div>
<h2 id="training-latent-variable-model-with-importance-sampling">Training Latent Variable Model with Importance Sampling<a class="headerlink" href="#training-latent-variable-model-with-importance-sampling" title="Permanent link">&para;</a></h2>
<p>From now on, we will focus on <strong>HOW</strong> to train latent variable model with MLE,</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \log p_{\theta}\left(X_{i}\right)=\underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \log \mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}\left(X_{i} \mid Z\right)\right]
\]</div>
<div class="admonition concept">
<p class="admonition-title">Concept 11.6 : VAE Outline</p>
<p>Outline of variational autoencoder (VAE):</p>
<ol>
<li>
<p>(Choice 1) Approximate intractable objective with a single <span class="arithmatex">\(Z\)</span> sample</p>
<div class="arithmatex">\[
\sum_{i=1}^{N} \log \mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}\left(X_{i} \mid Z\right)\right] \approx \sum_{i=1}^{N} \log p_{\theta}\left(X_{i} \mid Z_{i}\right), \quad Z_{i} \sim p_{Z}
\]</div>
</li>
<li>
<p>(Choice 2) Improve accuracy of approximation by sampling <span class="arithmatex">\(Z_{i}\)</span> with importance sampling</p>
<div class="arithmatex">\[
\sum_{i=1}^{N} \log \mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}\left(X_{i} \mid Z\right)\right] \approx \sum_{i=1}^{N} \log \frac{p_{\theta}\left(X_{i} \mid Z_{i}\right) p_{Z}\left(Z_{i}\right)}{q_{i}\left(Z_{i}\right)}, \quad Z_{i} \sim q_{i}
\]</div>
</li>
<li>
<p>Optimize approximate objective with SGD.</p>
</li>
</ol>
<p>(D. Kingma and M. Welling, VAE: Auto-encoding variational Bayes, ICLR, 2014.)</p>
</div>
<div class="admonition concept">
<p class="admonition-title">Concept 11.7 : IWAE Outline</p>
<p>Importance weighted autoencoders (IWAE) approximates intractable with <span class="arithmatex">\(K\)</span> samples of <span class="arithmatex">\(Z\)</span> :</p>
<div class="arithmatex">\[
\sum_{i=1}^{N} \log \mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}\left(X_{i} \mid Z\right)\right] \approx \sum_{i=1}^{N} \log \frac{1}{K} \sum_{k=1}^{K} \frac{p_{\theta}\left(X_{i} \mid Z_{i, k}\right) p_{Z}\left(Z_{i, k}\right)}{q_{i}\left(Z_{i, k}\right)}, \quad Z_{i, 1}, \ldots, Z_{i, K} \sim q_{i}
\]</div>
<p>(Y. Burda, R. Grosse, and R. Salakhutdinov, Importance weighted autoencoders, ICLR, 2016.)</p>
</div>
<div class="admonition concept">
<p class="admonition-title">Concept 11.8 : Why does VAE need IS?</p>
<p>Among the two choices given in <strong>Concept 11.6</strong>, VAEs improve the accuracy of latent variable model with IS (Choice 2).</p>
<p>Sampling <span class="arithmatex">\(Z_{i} \sim p_{Z}\)</span> (Choice 1) results in a high-variance estimator:</p>
<div class="arithmatex">\[
\mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}\left(X_{i} \mid Z\right)\right] \approx p_{\theta}\left(X_{i} \mid Z_{i}\right),
\]</div>
<p>In the Gaussian mixture example (<strong>Example 11.5</strong>), only <span class="arithmatex">\(1 / 3\)</span> of the <span class="arithmatex">\(Z\)</span> samples meaningfully contribute to the estimate. More specifically, if <span class="arithmatex">\(X_{i}\)</span> is near <span class="arithmatex">\(\mu_{A}\)</span> but is far from <span class="arithmatex">\(\mu_{B}\)</span> and <span class="arithmatex">\(\mu_{C}\)</span>, then <span class="arithmatex">\(p_{\theta}\left(X_{i} \mid Z=A\right) \gg 0\)</span> but <span class="arithmatex">\(p_{\theta}\left(X_{i} \mid Z=B\right) \approx 0\)</span> and <span class="arithmatex">\(p_{\theta}\left(X_{i} \mid Z=C\right) \approx 0\)</span>.</p>
<p>The issue worsens as the observable and latent variable dimension increases.</p>
</div>
<hr />
<div class="admonition concept">
<p class="admonition-title">Concept 11.9 : Naïve Approach : Naïvely using IS for each <span class="arithmatex">\(X_{i}\)</span></p>
<p>To improve estimation of <span class="arithmatex">\(\mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}\left(X_{i} \mid Z\right)\right]\)</span>, consider importance sampling (IS) with sampling distribution <span class="arithmatex">\(Z_{i} \sim q_{i}(z)\)</span> :</p>
<div class="arithmatex">\[
\mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}\left(X_{i} \mid Z\right)\right] \approx p_{\theta}\left(X_{i} \mid Z_{i}\right) \frac{p_{Z}\left(Z_{i}\right)}{q_{i}\left(Z_{i}\right)}
\]</div>
<p>Optimal IS sampling distribution</p>
<div class="arithmatex">\[
q_{i}^{\star}(z)=\frac{p_{\theta}\left(X_{i} \mid z\right) p_{Z}(z)}{\textcolor{red}{p_{\theta}\left(X_{i}\right)}}=\textcolor{red}{p_{\theta}\left(z \mid X_{i}\right)}
\]</div>
<p>To clarify, optimal sampling distribution depends on <span class="arithmatex">\(X_{i}\)</span>.
To clarify, <span class="arithmatex">\(\textcolor{red}{p_{\theta}\left(X_{i}\right)}\)</span> is the unkown normalizing factor so <span class="arithmatex">\(\textcolor{red}{p_{\theta}\left(z \mid X_{i}\right)}\)</span> is also unkown.
We call <span class="arithmatex">\(q_{i}^{\star}(z)=p_{\theta}\left(z \mid X_{i}\right)\)</span> the true <strong>posterior</strong> distribution and we will soon consider the approximation <span class="arithmatex">\(q_{\phi}(z \mid x) \approx p_{\theta}(z \mid x)\)</span>, which we call the <strong>approximate posterior</strong>.</p>
<hr />
<p>For each <span class="arithmatex">\(X_{i}\)</span>, let <span class="arithmatex">\(q_i(z)\)</span> be the optimal approximate posterior dependent on <span class="arithmatex">\(X_i\)</span>, and consider</p>
<div class="arithmatex">\[
\begin{gathered}
\underset{q_{i}}{\operatorname{minimize}} D_{\mathrm{KL}}\left(q_{i}(\cdot) \| \textcolor{red}{p_{\theta}\left(\cdot \mid X_{i}\right)} \right)\\
=\underset{q_{i}}{\operatorname{minimize}} \mathbb{E}_{Z \sim q_{i}} \log \left(\frac{q_{i}(Z)}{\textcolor{red}{p_{\theta}\left(Z \mid X_{i}\right)}}\right) \\
=\underset{q_{i}}{\operatorname{minimize}} \mathbb{E}_{Z \sim q_{i}} \log \left(\frac{q_{i}(Z)}{p_{\theta}\left(X_{i} \mid Z\right) p_{Z}(Z) / \textcolor{red}{p_{\theta}\left(X_{i}\right)}}\right) \\
=\underset{Z \sim q_{i}}{\operatorname{minimize}}\left[\log q_{i}(Z)-\log p_{Z}(Z)-\log p_{\theta}\left(X_{i} \mid Z\right)\right]+\textcolor{red}{\log p_{\theta}\left(X_{i}\right)}
\end{gathered}
\]</div>
<p>Note, <span class="arithmatex">\(q_{i}(z), p_{Z}(z)\)</span>, and <span class="arithmatex">\(p_{\theta}(x \mid z)\)</span> are tractable/known while <span class="arithmatex">\(\textcolor{red}{p_{\theta}\left(X_{i}\right)}\)</span> and <span class="arithmatex">\(\textcolor{red}{p_{\theta}\left(z \mid X_{i}\right)}\)</span> are intractable/unknown. Since <span class="arithmatex">\(\textcolor{red}{\log p_{\theta}\left(X_{i}\right)}\)</span> does not depend on <span class="arithmatex">\(q_{i}\)</span>, all quantities needed in the optimization problems are tractable. However, solving this minimization problem to obtain each <span class="arithmatex">\(q_{i}\)</span> for each data point <span class="arithmatex">\(X_{i}\)</span> is computationally too expensive.</p>
<hr />
<p>Individual inference (not amortized): For each <span class="arithmatex">\(X_{1}, \ldots, X_{N}\)</span>, find corresponding optimal <span class="arithmatex">\(q_{1}, \ldots, q_{N}\)</span> by solving</p>
<div class="arithmatex">\[
\underset{q_{i}}{\operatorname{minimize}} \quad D_{\mathrm{KL}}\left(q_{i}(\cdot) \| p_{\theta}\left(\cdot \mid X_{i}\right)\right)
\]</div>
<p>This is expensive as it requires solving <span class="arithmatex">\(N\)</span> separate optimization problems.</p>
<p>We need variational approach and amortized inference.</p>
</div>
<div class="admonition concept">
<p class="admonition-title">Concept 11.10 : Variational Approach and Amortized Inference</p>
<p>General principle of variational approach: We can't directly use the <span class="arithmatex">\(q\)</span> we want. So, instead, we propose a parameterized distribution <span class="arithmatex">\(q_{\phi}\)</span> that we can work with easily (in this case, sample from easily), and find a parameter setting that makes it as good as possible.</p>
<p>Parametrization of VAE:</p>
<div class="arithmatex">\[
q_{\phi}\left(z \mid X_{i}\right) \approx q_{i}^{\star}(z)=p_{\theta}\left(z \mid X_{i}\right) \quad \text { for all } i=1, \ldots, N
\]</div>
<p>Amortized inference: Train a neural network <span class="arithmatex">\(q_{\phi}(\cdot \mid x)\)</span> such that <span class="arithmatex">\(q_{\phi}\left(\cdot \mid X_{i}\right)\)</span> approximates the optimal <span class="arithmatex">\(q_{i}(\cdot)\)</span>.</p>
<div class="arithmatex">\[
\underset{\phi \in \Phi}{\operatorname{minimize}} \sum_{i=1}^{N} D_{\mathrm{KL}}\left(q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{\theta}\left(\cdot \mid X_{i}\right)\right)
\]</div>
<p>Approximation <span class="arithmatex">\(q_{\phi}\left(z \mid X_{i}\right) \approx p_{\theta}\left(z \mid X_{i}\right)\)</span> is often less precise than that of individual inference <span class="arithmatex">\(q_{i}(z) \approx\)</span> <span class="arithmatex">\(p_{\theta}\left(z \mid X_{i}\right)\)</span>, but amortized inference is often significantly faster.</p>
</div>
<div class="admonition concept">
<p class="admonition-title">Concept 11.11 : Encoder <span class="arithmatex">\(q_{\phi}\)</span> Optimization</p>
<p>In analogy with autoencoders, we call <span class="arithmatex">\(q_{\phi}\)</span> the <strong>encoder</strong>.</p>
<p>Optimization problem for encoder (derived from <strong>Concept 11.9</strong>) :</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \underset{\phi \in \Phi}{\operatorname{minimize}} \sum_{i=1}^{N} D_{\mathrm{KL}}\left(q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{\theta}\left(\cdot \mid X_{i}\right)\right) \\
= &amp; \underset{\phi \in \Phi}{\operatorname{maximize}} \sum_{i=1}^{N} \mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\log \left(\frac{p_{\theta}\left(X_{i} \mid Z\right) p_{Z}(Z)}{q_{\phi}\left(Z \mid X_{i}\right)}\right)\right]+\text { constant independent of } \phi \\
= &amp; \underset{\phi \in \Phi}{\operatorname{maximize}} \sum_{i=1}^{N} \mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\log p_{\theta}\left(X_{i} \mid Z\right)\right]-D_{\mathrm{KL}}\left(q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{Z}(\cdot)\right)
\end{aligned}
\]</div>
</div>
<div class="admonition concept">
<p class="admonition-title">Concept 11.12 : Decoder <span class="arithmatex">\(p_{\theta}\)</span> Optimization</p>
<p>In analogy with autoencoders, we call <span class="arithmatex">\(p_{\theta}\)</span> the <strong>decoder</strong>.
Perform approximate MLE (derived from IS, Choice 2 of <strong>Concept 11.6</strong>) :</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \log p_{\theta}\left(X_{i}\right)=\underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \log \mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}\left(X_{i} \mid Z\right)\right] \\
\stackrel{(a)}{\approx} &amp; \underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \log \left(\frac{p_{\theta}\left(X_{i} \mid Z_{i}\right) p_{Z}\left(Z_{i}\right)}{q_{\phi}\left(Z_{i} \mid X_{i}\right)}\right), \quad Z_{i} \sim q_{\phi}\left(z \mid X_{i}\right) \\
\stackrel{(b)}{\approx} &amp; \underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\log \left(\frac{p_{\theta}\left(X_{i} \mid Z\right) p_{Z}(Z)}{q_{\phi}\left(Z \mid X_{i}\right)}\right)\right] \\
= &amp; \underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\log p_{\theta}\left(X_{i} \mid Z\right)\right]-D_{\mathrm{KL}}\left(q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{Z}(\cdot)\right)
\end{aligned}
\]</div>
<p>The <span class="arithmatex">\(\stackrel{(a)}{\approx}\)</span> step replaces expectation inside the log with an estimate with <span class="arithmatex">\(Z_{i}\)</span>.
The <span class="arithmatex">\(\stackrel{(b)}{\approx}\)</span> step replaces the random variable with the expectation.
These steps take <span class="arithmatex">\(\mathbb{E}_{Z}\)</span> outside of the log (which can not be normally done).
More on this later (<strong>Concept 11.14</strong>).</p>
</div>
<h2 id="definition-of-vae">Definition of VAE<a class="headerlink" href="#definition-of-vae" title="Permanent link">&para;</a></h2>
<div class="admonition definition">
<p class="admonition-title">Definition 11.13 : Variational Lower Bound (VLB)</p>
<p>The optimization objectives for the encoder (<strong>Concept 11.11</strong>) and decoder (<strong>Concept 11.12</strong>) are the same!</p>
<p>Simultaneously train <span class="arithmatex">\(p_{\theta}\)</span> and <span class="arithmatex">\(q_{\phi}\)</span> by solving</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta, \phi \in \Phi}{\operatorname{maximize}} \sum_{i=1}^{N} \underbrace{\mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\log p_{\theta}\left(X_{i} \mid Z\right)\right]-D_{\mathrm{KL}}\left(q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{Z}(\cdot)\right)}_{\stackrel{\text { def }}{=} \mathrm{VLB}_{\theta, \phi}\left(X_{i}\right)}
\]</div>
<p>We refer to the optimization objective as the <strong>variational lower bound (VLB)</strong> or <strong>evidence lower bound (ELBO)</strong> for reasons that will be explained soon (<strong>Concept 11.14</strong>).</p>
</div>
<div class="admonition concept">
<p class="admonition-title">Concept 11.14 : How tight lower bound is the VLB?</p>
<p>How accurate is the approximation?</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \log p_{\theta}\left(X_{i}\right)=\underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \log \mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\frac{p_{\theta}\left(X_{i} \mid Z\right) p_{Z}(Z)}{q_{\phi}\left(Z \mid X_{i}\right)}\right] \\
&amp; \stackrel{?}{\approx} \underset{\theta \in \Theta, \phi \in \Phi}{\operatorname{maximize}} \sum_{i=1}^{N} \mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\log \left(\frac{p_{\theta}\left(X_{i} \mid Z\right) p_{Z}(Z)}{q_{\phi}\left(Z \mid X_{i}\right)}\right)\right] \\
&amp;=\underset{\theta \in \Theta, \phi \in \Phi}{\operatorname{maximize}} \sum_{i=1}^{N} \operatorname{VLB}_{\theta, \phi}\left(X_{i}\right)
\end{aligned}
\]</div>
<p>This turns out that </p>
<div class="arithmatex">\[
\log p_{\theta}\left(X_{i}\right) \geq \operatorname{VLB}_{\theta, \phi}\left(X_{i}\right)
\]</div>
<p>So we are maximizing a lower bound of the log likelihood. How large is the gap?</p>
<hr />
<ul>
<li>Log-likelihood <span class="arithmatex">\(\geq\)</span> VLB: Derivation 1</li>
</ul>
<div class="admonition proof">
<p class="admonition-title">Proof</p>
<p>Derivation via Jensen inequality:</p>
<div class="arithmatex">\[
\begin{aligned}
\log p_{\theta}\left(X_{i}\right) &amp; =\log \mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}\left(X_{i} \mid Z\right)\right] \\
&amp; =\log \left(\mathbb{E}_{Z \sim q_{\phi}\left(Z \mid X_{i}\right)}\left[p_{\theta}\left(X_{i} \mid Z\right) \frac{p_{Z}(Z)}{q_{\phi}\left(Z \mid X_{i}\right)}\right]\right) \\
&amp; \geq \mathbb{E}_{Z \sim q_{\phi}\left(Z \mid X_{i}\right)}\left[\log \left(p_{\theta}\left(X_{i} \mid Z\right) \frac{p_{Z}(Z)}{q_{\phi}\left(Z \mid X_{i}\right)}\right)\right] \\
&amp; \stackrel{\text { def }}{=} \mathrm{VLB}_{\theta, \phi}\left(X_{i}\right)
\end{aligned}
\]</div>
</div>
<p>Does not explicitly characterize gap.</p>
<hr />
<ul>
<li>Log-likelihood <span class="arithmatex">\(\geq\)</span> VLB: Derivation 2</li>
</ul>
<div class="admonition proof">
<p class="admonition-title">Proof</p>
<p>Derivation via KL divergence:</p>
<div class="arithmatex">\[
\begin{aligned}
D_{\mathrm{KL}}\left[q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{\theta}\left(\cdot \mid X_{i}\right)\right] &amp; =\mathbb{E}_{Z \sim q_{\theta}\left(z \mid X_{i}\right)}\left[\log q_{\theta}\left(Z \mid X_{i}\right)-\log p_{\theta}\left(Z \mid X_{i}\right)\right] \\
&amp; =\underbrace{\mathbb{E}_{Z \sim q_{\theta}\left(z \mid X_{i}\right)}\left[\log q_{\theta}\left(Z \mid X_{i}\right)-\log p_{Z}(Z)-\log p_{\theta}\left(X_{i} \mid Z\right)\right]}_{=-\mathrm{VLB}_{\theta, \phi}\left(X_{i}\right)}+\log p_{\theta}\left(X_{i}\right)
\end{aligned}
\]</div>
<p>and</p>
<div class="arithmatex">\[
\begin{aligned}
\log p_{\theta}\left(X_{i}\right) &amp;= \operatorname{VLB}_{\theta, \phi}\left(X_{i}\right)+\underbrace{D_{\mathrm{KL}}\left[q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{\theta}\left(\cdot \mid X_{i}\right)\right]}_{\geq 0} \\
&amp; \geq \operatorname{VLB}_{\theta, \phi}\left(X_{i}\right)
\end{aligned}
\]</div>
</div>
<p>This derivation explicitly characterizes the gap as <span class="arithmatex">\(D_{\mathrm{KL}}\left[q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{\theta}\left(\cdot \mid X_{i}\right)\right]\)</span>.</p>
<div class="arithmatex">\[
\log p_{\theta}\left(X_{i}\right) - \operatorname{VLB}_{\theta, \phi}\left(X_{i}\right) = D_{\mathrm{KL}}\left[q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{\theta}\left(\cdot \mid X_{i}\right)\right]
\]</div>
</div>
<div class="admonition concept">
<p class="admonition-title">Concept 11.15 : VLB is tight if encoder is infinitely powerful.</p>
<p>If the encoder <span class="arithmatex">\(q_{\phi}\)</span> is powerful enough such that there is a <span class="arithmatex">\(\phi^{\star}\)</span> achieving</p>
<div class="arithmatex">\[
q_{\phi^{\star}}\left(\cdot \mid X_{i}\right)=p_{\theta}\left(\cdot \mid X_{i}\right)
\]</div>
<p>or equivalently</p>
<div class="arithmatex">\[
D_{\mathrm{KL}}\left[q_{\phi^{\star}}\left(\cdot \mid X_{i}\right) \| p_{\theta}\left(\cdot \mid X_{i}\right)\right]=0
\]</div>
<p>Then</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \log p_{\theta}\left(X_{i}\right)=\underset{\theta \in \Theta, \phi \in \Phi}{\operatorname{maximize}} \sum_{i=1}^{N} \operatorname{VLB}_{\theta, \phi}\left(X_{i}\right)
\]</div>
</div>
<div class="admonition definition">
<p class="admonition-title">Definition 11.16 : Variational Autoencoder (VAE) Terminology</p>
<p><center>
<img alt="" src="../assets/11.4.png" width="50%" />
</center></p>
<ul>
<li><strong>Likelihood</strong> : <span class="arithmatex">\(\textcolor{red}{p_{\theta}(x)}\)</span> (exact evaluation intractable)</li>
<li><strong>Prior</strong> : <span class="arithmatex">\(p_{Z}(z)\)</span></li>
<li><strong>Conditional distribution (decoder)</strong> : <span class="arithmatex">\(p_{\theta}(x \mid z)\)</span></li>
<li><strong>True posterior</strong> : <span class="arithmatex">\(\textcolor{red}{p_{\theta}(z \mid x)}\)</span> (exact evaluation intractable)</li>
<li><strong>Approximate posterior (encoder)</strong> : <span class="arithmatex">\(q_{\phi}(z \mid x)\)</span></li>
</ul>
<hr />
<p>Conditional distribution <span class="arithmatex">\(p_{\theta}(x \mid z)\)</span> and prior <span class="arithmatex">\(p_{Z}(z)\)</span> determines the posterior <span class="arithmatex">\(p_{\theta}(z \mid x)\)</span>.</p>
<p>There is no easy way to evaluate <span class="arithmatex">\(p_{\theta}(x)\)</span>, but we can sample <span class="arithmatex">\(X \sim p_{\theta}(x)\)</span> easily: <span class="arithmatex">\(Z \sim p_{Z}(z)\)</span> then <span class="arithmatex">\(X \sim p_{\theta}(x \mid Z)\)</span>.</p>
<p>NN in VAE do not directly generate random output. NN outputs parameters for random sampling.</p>
</div>
<h2 id="vae-standard-instance">VAE Standard Instance<a class="headerlink" href="#vae-standard-instance" title="Permanent link">&para;</a></h2>
<div class="admonition definition">
<p class="admonition-title">Definition 11.17 : VAE Standard Instance</p>
<p>A <strong>standard VAE setup</strong>:</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; p_{Z}=\mathcal{N}(0, I) \\
&amp; q_{\phi}(z \mid x)=\mathcal{N}\left(\mu_{\phi}(x), \Sigma_{\phi}(x)\right) \text { with diagonal } \Sigma_{\phi} \\
&amp; p_{\theta}(x \mid z)=\mathcal{N}\left(f_{\theta}(z), \sigma^{2} I\right)
\end{aligned}
\]</div>
<p><span class="arithmatex">\(\mu_{\phi}(x), \Sigma_{\phi}^{2}(x)\)</span>, and <span class="arithmatex">\(f_{\theta}(z)\)</span> are deterministic NN.</p>
<hr />
<p>Using the following equation,</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; D_{\mathrm{KL}}\left(\mathcal{N}\left(\mu_{\phi}(X), \Sigma_{\phi}(X)\right) \| \mathcal{N}(0, I)\right) \\
= &amp; \frac{1}{2}\left(\operatorname{tr}\left(\Sigma_{\phi}(X)\right)+\left\|\mu_{\phi}(X)\right\|^{2}-d-\log \operatorname{det}\left(\Sigma_{\phi}(X)\right)\right) \\
\end{aligned}
\]</div>
<p>the training objective</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta, \phi \in \Phi}{\operatorname{maximize}} \sum_{i=1}^{N} \mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\log p_{\theta}\left(X_{i} \mid Z\right)\right]-D_{\mathrm{KL}}\left(q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{Z}(\cdot)\right)
\]</div>
<p>becomes</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta, \phi \in \Phi}{\operatorname{minimize}} \sum_{i=1}^{N} \frac{1}{\sigma^{2}} \mathbb{E}_{Z \sim \mathcal{N}\left(\mu_{\phi}\left(X_{i}\right), \Sigma_{\phi}\left(X_{i}\right)\right)}\left\|X_{i}-f_{\theta}(Z)\right\|^{2}+\operatorname{tr}\left(\Sigma_{\phi}\left(X_{i}\right)\right)+\left\|\mu_{\phi}\left(X_{i}\right)\right\|^{2}-\log \operatorname{det}\left(\Sigma_{\phi}\left(X_{i}\right)\right)
\]</div>
</div>
<div class="admonition concept">
<p class="admonition-title">Concept 11.18 : VAE Standard Instance with Reparameterization Trick</p>
<p>The standard instance of VAE</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta, \phi \in \Phi}{\operatorname{minimize}} \sum_{i=1}^{N} \frac{1}{\sigma^{2}} \mathbb{E}_{Z \sim \mathcal{N}\left(\mu_{\phi}\left(X_{i}\right), \Sigma_{\phi}\left(X_{i}\right)\right)}\left\|X_{i}-f_{\theta}(Z)\right\|^{2}+\operatorname{tr}\left(\Sigma_{\phi}\left(X_{i}\right)\right)+\left\|\mu_{\phi}\left(X_{i}\right)\right\|^{2}-\log \operatorname{det}\left(\Sigma_{\phi}\left(X_{i}\right)\right)
\]</div>
<p>can be equivalently written with the reparameterization trick</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta, \phi \in \Phi}{\operatorname{minimize}} \sum_{i=1}^{N} \frac{1}{\sigma^{2}} \mathbb{E}_{\varepsilon \sim \mathcal{N}(0, I)}\left\|X_{i}-f_{\theta}\left(\mu_{\phi}\left(X_{i}\right)+\Sigma_{\phi}^{1 / 2}\left(X_{i}\right) \varepsilon\right)\right\|^{2}+\operatorname{tr}\left(\Sigma_{\phi}\left(X_{i}\right)\right)+\left\|\mu_{\phi}\left(X_{i}\right)\right\|^{2}-\log \operatorname{det}\left(\Sigma_{\phi}\left(X_{i}\right)\right)
\]</div>
<p>where <span class="arithmatex">\(\Sigma_{\phi}^{1 / 2}\)</span> is diagonal with <span class="arithmatex">\(\sqrt{\cdot}\)</span> of the diagonal elements of <span class="arithmatex">\(\Sigma_{\phi}\)</span>.
(Remember, <span class="arithmatex">\(\Sigma_{\phi}\)</span> is diagonal.)</p>
<p>To clarify <span class="arithmatex">\(Z \stackrel{\mathcal{D}}{=} \mu_{\phi}\left(X_{i}\right)+\Sigma_{\phi}^{1 / 2}\left(X_{i}\right) \varepsilon\)</span>, where <span class="arithmatex">\(\stackrel{\mathcal{D}}{=}\)</span> denotes equality in distribution.</p>
<p>We now have an objective amenable to stochastic optimization.</p>
</div>
<div class="admonition concept">
<p class="admonition-title">Concept 11.19 : VAE Standard Instance Architecture</p>
<ul>
<li>Training (Without reparameterization trick)</li>
</ul>
<p><center>
<img alt="" src="../assets/11.5.png" width="70%" />
</center></p>
<ul>
<li>Training (With reparameterization trick)</li>
</ul>
<p><center>
<img alt="" src="../assets/11.6.png" width="70%" />
</center></p>
<hr />
<ul>
<li>
<p>Sampling</p>
<p>During sampling, only the decoder network is used.</p>
</li>
</ul>
<p><center>
<img alt="" src="../assets/11.7.png" width="40%" />
</center></p>
</div>
<div class="admonition concept">
<p class="admonition-title">Concept 11.20 : Why variational "autoencoder"?</p>
<p>VAE loss (VLB) contains a reconstruction loss resembling that of an autoencoder.</p>
<div class="arithmatex">\[
\begin{aligned}
\operatorname{VLB}_{\theta, \phi}\left(X_{i}\right) &amp; =\mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\log p_{\theta}\left(X_{i} \mid Z\right)\right]-D_{\mathrm{KL}}\left(q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{Z}(\cdot)\right) \\
&amp; =-\frac{1}{2 \sigma^{2}} \mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\left\|X_{i}-f_{\theta}(Z)\right\|^{2}\right]-D_{\mathrm{KL}}\left(q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{Z}(\cdot)\right) \\
&amp; =-\underbrace{\frac{1}{2 \sigma^{2}} \mathbb{E}_{\varepsilon \sim \mathcal{N}(0, I)}\left\|X_{i}-f_{\theta}\left(\mu_{\phi}\left(X_{i}\right)+\Sigma_{\phi}^{1 / 2}\left(X_{i}\right) \varepsilon\right)\right\|^{2}}_{\text {Reconstruction loss }}-\underbrace{D_{\mathrm{KL}}\left(q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{Z}(\cdot)\right)}_{\text {Regularization }}
\end{aligned}
\]</div>
<p>VLB also contains a regularization term on the output of the encoder, which is not present in standard autoencoder losses.</p>
<p>The choice of <span class="arithmatex">\(\sigma\)</span> determines the relative weight between the reconstruction loss and the regularization.</p>
</div>
<h2 id="training-vae">Training VAE<a class="headerlink" href="#training-vae" title="Permanent link">&para;</a></h2>
<div class="admonition concept">
<p class="admonition-title">Concept 11.21 : Training VAE with RT</p>
<p>To obtain stochastic gradients of the VAE standard instance </p>
<div class="arithmatex">\[
\underset{\theta \in \Theta, \phi \in \Phi}{\operatorname{minimize}} \sum_{i=1}^{N} \frac{1}{\sigma^{2}} \mathbb{E}_{\varepsilon \sim \mathcal{N}(0, I)}\left\|X_{i}-f_{\theta}\left(\mu_{\phi}\left(X_{i}\right)+\Sigma_{\phi}^{1 / 2}\left(X_{i}\right) \varepsilon\right)\right\|^{2}+\operatorname{tr}\left(\Sigma_{\phi}\left(X_{i}\right)\right)+\left\|\mu_{\phi}\left(X_{i}\right)\right\|^{2}-\log \operatorname{det}\left(\Sigma_{\phi}\left(X_{i}\right)\right)
\]</div>
<p>select a data <span class="arithmatex">\(X_{i}\)</span>, sample <span class="arithmatex">\(\varepsilon_{i} \sim \mathcal{N}(0, I)\)</span>, evaluate</p>
<div class="arithmatex">\[
-\operatorname{VLB}_{\theta, \phi}\left(X_{i}, \varepsilon_{i}\right) \stackrel{\text { def }}{=} \frac{1}{\sigma^{2}}\left\|X_{i}-f_{\theta}\left(\mu_{\phi}\left(X_{i}\right)+\Sigma_{\phi}^{1 / 2}\left(X_{i}\right) \varepsilon_{i}\right)\right\|^{2}+\operatorname{tr}\left(\Sigma_{\phi}\left(X_{i}\right)\right)+\left\|\mu_{\phi}\left(X_{i}\right)\right\|^{2}-\log \operatorname{det}\left(\Sigma_{\phi}\left(X_{i}\right)\right)
\]</div>
<p>and backprop on <span class="arithmatex">\(\operatorname{VLB}_{\theta, \phi}\left(X_{i}, \varepsilon_{i}\right)\)</span>.</p>
<p>Usually, batch of <span class="arithmatex">\(X_{i}\)</span> is selected.<br />
One can sample multiple <span class="arithmatex">\(Z_{i, 1}, \ldots, Z_{i, K}\)</span> (equivalently <span class="arithmatex">\(\varepsilon_{i, 1}, \ldots, \varepsilon_{i, K}\)</span> ) for each <span class="arithmatex">\(X_{i}\)</span>.</p>
</div>
<div class="admonition concept">
<p class="admonition-title">Concept 11.22 : Traning VAE with Log-Derivative Trick</p>
<p>Computing stochastic gradients without the reparameterization trick.</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta, \phi \in \Phi}{\operatorname{maximize}} \sum_{i=1}^{N} \underbrace{\mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\log \left(\frac{p_{\theta}\left(X_{i} \mid Z\right) p_{Z}(Z)}{q_{\phi}\left(Z \mid X_{i}\right)}\right)\right]}_{\stackrel{\text { def }}{=} \operatorname{VLB}_{\theta, \phi}\left(X_{i}\right)}
\]</div>
<p>To obtain unbiased estimates of <span class="arithmatex">\(\nabla_{\theta}\)</span>, compute</p>
<div class="arithmatex">\[
\frac{1}{K} \sum_{k=1}^{K} \log p_{\theta}\left(X_{i} \mid Z_{i, k}\right), \quad Z_{i, 1}, \ldots, Z_{i, K} \sim q_{\phi}\left(z \mid X_{i}\right)
\]</div>
<p>and backprop with respect to <span class="arithmatex">\(\theta\)</span>.</p>
<p>We differentiate the VLB objectives</p>
<div class="arithmatex">\[
\begin{aligned}
\nabla_{\phi} \mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\log \left(\frac{p_{\theta}\left(X_{i} \mid Z\right) p_{Z}(Z)}{q_{\phi}\left(Z \mid X_{i}\right)}\right)\right] &amp; =\nabla_{\phi} \int \log \left(\frac{p_{\theta}\left(X_{i} \mid z\right) p_{Z}(z)}{q_{\phi}\left(z \mid X_{i}\right)}\right) q_{\phi}\left(z \mid X_{i}\right) d z \\
&amp; =\mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\left(\nabla_{\phi} \log q_{\phi}\left(Z \mid X_{i}\right)\right) \log \left(\frac{p_{\theta}\left(X_{i} \mid Z\right) p_{Z}(Z)}{q_{\phi}\left(Z \mid X_{i}\right)}\right)\right]
\end{aligned}
\]</div>
<p>To obtain unbiased estimates of <span class="arithmatex">\(\nabla_{\phi}\)</span>, compute</p>
<div class="arithmatex">\[
\frac{1}{K} \sum_{k=1}^{K}\left(\nabla_{\phi} \log q_{\phi}\left(Z_{i, k} \mid X_{i}\right)\right) \log \left(\frac{p_{\theta}\left(X_{i} \mid Z_{i, k}\right) p_{Z}\left(Z_{i, k}\right)}{q_{\phi}\left(Z_{i, k} \mid X_{i}\right)}\right), \quad Z_{i, 1}, \ldots, Z_{i, K} \sim q_{\phi}\left(z \mid X_{i}\right)
\]</div>
</div>
<h2 id="researches">Researches<a class="headerlink" href="#researches" title="Permanent link">&para;</a></h2>
<div class="admonition concept">
<p class="admonition-title">Concept 11.23 : VQ-VAE</p>
<p><center>
<img alt="" src="../assets/11.8.png" width="100%" />
<img alt="" src="../assets/11.9.png" width="100%" />
</center></p>
<p>(A. van den Oord, O. Vinyals, and K. Kavukcuoglu, Neural discrete representation learning, NeurIPS, 2017.)</p>
</div>
<div class="admonition concept">
<p class="admonition-title">Concept 11.24 : VQ-VAE-2</p>
<p><center>
<img alt="" src="../assets/11.10.png" width="50%" />
<img alt="" src="../assets/11.11.png" width="70%" />
<img alt="" src="../assets/11.12.png" width="100%" />
</center></p>
<p>(A. Razavi, A. van den Oord, and O. Vinyals, Generating diverse high-fidelity images with VQ-VAE-2, NeurIPS, 2019.)</p>
</div>
<div class="admonition concept">
<p class="admonition-title">Concept 11.25 : <span class="arithmatex">\(\beta\)</span>-VAE</p>
<p>Uses the loss</p>
<div class="arithmatex">\[
\ell_{\theta, \phi}\left(X_{i}\right)=\mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\log p_{\theta}\left(X_{i} \mid Z\right)\right]-\beta D_{\mathrm{KL}}\left(q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{Z}(\cdot)\right)
\]</div>
<p>when <span class="arithmatex">\(\beta=1, \ell_{\theta, \phi}\left(X_{i}\right)=\operatorname{VLB}_{\theta, \phi}\left(X_{i}\right)\)</span>, i.e., <span class="arithmatex">\(\beta\)</span>-VAE coincides with VAE when <span class="arithmatex">\(\beta=1\)</span>.</p>
<p>With <span class="arithmatex">\(\beta&gt;1\)</span>, authors observed better feature disentanglement.</p>
<p>(I. Higgins, L. Matthey, A. Pal, C. Burgess, X. Glorot, M. Botvinick, S. Mohamed, and A. Lerchner, β-VAE: Learning basic visual concepts with a constrained variational framework, ICLR, 2017.)</p>
</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  맨위로
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/arnold518" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../..", "features": ["content.code.copy", "header.autohide", "navigation.instant", "navigation.tracking", "navigation.tabs", "toc.follow", "navigation.top", "search.suggest", "search.highlight", "search.share", "navigation.indexes"], "search": "../../../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "\ud074\ub9bd\ubcf4\ub4dc\uc5d0 \ubcf5\uc0ac\ub428", "clipboard.copy": "\ud074\ub9bd\ubcf4\ub4dc\ub85c \ubcf5\uc0ac", "search.result.more.one": "\uc774 \ubb38\uc11c\uc5d0\uc11c 1\uac1c\uc758 \uac80\uc0c9 \uacb0\uacfc \ub354 \ubcf4\uae30", "search.result.more.other": "\uc774 \ubb38\uc11c\uc5d0\uc11c #\uac1c\uc758 \uac80\uc0c9 \uacb0\uacfc \ub354 \ubcf4\uae30", "search.result.none": "\uac80\uc0c9\uc5b4\uc640 \uc77c\uce58\ud558\ub294 \ubb38\uc11c\uac00 \uc5c6\uc2b5\ub2c8\ub2e4", "search.result.one": "1\uac1c\uc758 \uc77c\uce58\ud558\ub294 \ubb38\uc11c", "search.result.other": "#\uac1c\uc758 \uc77c\uce58\ud558\ub294 \ubb38\uc11c", "search.result.placeholder": "\uac80\uc0c9\uc5b4\ub97c \uc785\ub825\ud558\uc138\uc694", "search.result.term.missing": "\ud3ec\ud568\ub418\uc9c0 \uc54a\uc740 \uac80\uc0c9\uc5b4", "select.version": "\ubc84\uc804 \uc120\ud0dd"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>