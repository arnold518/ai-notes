
<!doctype html>
<html lang="ko" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../7/">
      
      
        <link rel="next" href="../9/">
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.12">
    
    
      
        <title>8. CNNs for Other Supervised Learning Tasks - Artificial Intelligence Notes</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.2afb09e1.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.06af60db.min.css">
      
      
  
  
    
    
  
    
    
  
  
  <style>:root{--md-admonition-icon--note:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2024%2024%22%3E%3Cpath%20d%3D%22M12%206a6%206%200%200%201%206%206c0%202.22-1.21%204.16-3%205.2V19a1%201%200%200%201-1%201h-4a1%201%200%200%201-1-1v-1.8c-1.79-1.04-3-2.98-3-5.2a6%206%200%200%201%206-6m2%2015v1a1%201%200%200%201-1%201h-2a1%201%200%200%201-1-1v-1zm6-10h3v2h-3zM1%2011h3v2H1zM13%201v3h-2V1zM4.92%203.5l2.13%202.14-1.42%201.41L3.5%204.93zm12.03%202.13%202.12-2.13%201.43%201.43-2.13%202.12z%22/%3E%3C/svg%3E');--md-admonition-icon--tip:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20512%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%206.7.2%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202024%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M256%200a256%20256%200%201%201%200%20512%20256%20256%200%201%201%200-512m-24%20120v136c0%208%204%2015.5%2010.7%2020l96%2064c11%207.4%2025.9%204.4%2033.3-6.7s4.4-25.9-6.7-33.3L280%20243.2V120c0-13.3-10.7-24-24-24s-24%2010.7-24%2024%22/%3E%3C/svg%3E');}</style>



    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:300,300i,400,400i,700,700i%7CUbuntu+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Noto Sans";--md-code-font:"Ubuntu Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="deep-orange" data-md-color-accent="deep-orange">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#8-cnns-for-other-supervised-learning-tasks" class="md-skip">
          콘텐츠로 이동
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="상단/헤더">
    <a href="../../../.." title="Artificial Intelligence Notes" class="md-header__button md-logo" aria-label="Artificial Intelligence Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Artificial Intelligence Notes
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              8. CNNs for Other Supervised Learning Tasks
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="deep-orange" data-md-color-accent="deep-orange"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="deep-orange" data-md-color-accent="deep-orange"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="검색" placeholder="검색" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="검색">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="공유" aria-label="공유" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="지우기" aria-label="지우기" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            검색 초기화
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/arnold518/ai-notes" title="저장소로 이동" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    arnold518/ai-notes
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="탭" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
  
    
  
  Books & Courses

        </a>
      </li>
    
  

    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="네비게이션" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="Artificial Intelligence Notes" class="md-nav__button md-logo" aria-label="Artificial Intelligence Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Artificial Intelligence Notes
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/arnold518/ai-notes" title="저장소로 이동" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    arnold518/ai-notes
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Books & Courses
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Books & Courses
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Mathematical Foundations of Deep Neural Networks
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            Mathematical Foundations of Deep Neural Networks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_2" >
        
          
          <label class="md-nav__link" for="__nav_2_1_2" id="__nav_2_1_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Ch 1. Optimization and Stochastic Gradient Descent
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_2">
            <span class="md-nav__icon md-icon"></span>
            Ch 1. Optimization and Stochastic Gradient Descent
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1. Optimization Problem
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2. Gradient Descent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/1PSpoeseUPIptYQOPuQpxNawxtZbVR_K6/view?usp=sharing" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter 1 Code
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_3" >
        
          
          <label class="md-nav__link" for="__nav_2_1_3" id="__nav_2_1_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Ch 2. Shallow Neural Networks to Multilayer Perceptrons
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_3">
            <span class="md-nav__icon md-icon"></span>
            Ch 2. Shallow Neural Networks to Multilayer Perceptrons
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3. Shallow Neural Networks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4. Deep Neural Networks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/15kXC3cJUV63gZNfXK6JdPPuSrwQZBzI8/view?usp=sharing" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter 2 Code
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_4" >
        
          
          <label class="md-nav__link" for="__nav_2_1_4" id="__nav_2_1_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Ch 3. Convolutional Neural Networks
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_4">
            <span class="md-nav__icon md-icon"></span>
            Ch 3. Convolutional Neural Networks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../5/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    5. Convolutional Neural Networks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    6. Foundations of Design and Training of Deep Neural Networks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../7/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    7. ImageNet Challenge
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/12O9fLasWDA-kOKBD-lE-1UhCl-PoDf0z/view?usp=sharing" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter 3 Code
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_5" checked>
        
          
          <label class="md-nav__link" for="__nav_2_1_5" id="__nav_2_1_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Ch 4. CNNs for Other Supervised Learning Tasks
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_1_5">
            <span class="md-nav__icon md-icon"></span>
            Ch 4. CNNs for Other Supervised Learning Tasks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    8. CNNs for Other Supervised Learning Tasks
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    8. CNNs for Other Supervised Learning Tasks
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="목차">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      목차
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#inverse-problem" class="md-nav__link">
    <span class="md-ellipsis">
      Inverse Problem
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Inverse Problem">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gaussian-denoising" class="md-nav__link">
    <span class="md-ellipsis">
      Gaussian Denoising
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#image-super-resolution" class="md-nav__link">
    <span class="md-ellipsis">
      Image Super-Resolution
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#other-examples" class="md-nav__link">
    <span class="md-ellipsis">
      Other Examples
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#operations-increasing-spatial-dimensions" class="md-nav__link">
    <span class="md-ellipsis">
      Operations Increasing Spatial Dimensions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Operations Increasing Spatial Dimensions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#transposed-convolution" class="md-nav__link">
    <span class="md-ellipsis">
      Transposed convolution
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#upsampling" class="md-nav__link">
    <span class="md-ellipsis">
      Upsampling
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#semantic-segmentation" class="md-nav__link">
    <span class="md-ellipsis">
      Semantic Segmentation
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/16IOKVF6IiDMyUvL73pGKBaEMKyXvezLB/view?usp=sharing" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter 4 Code
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_6" >
        
          
          <label class="md-nav__link" for="__nav_2_1_6" id="__nav_2_1_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Ch 5. Unsupervised Learning
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_6">
            <span class="md-nav__icon md-icon"></span>
            Ch 5. Unsupervised Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../9/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    9. Autoencoder
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../10/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    10. Flow Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../11/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    11. Variational Autoencoders
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../12/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    12. Generative Adversarial Networks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/1JM5k-e6LkhZ0vXRlfROWpiuw4YC85Jv1/view?usp=sharing" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter 5 Code
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_7" >
        
          
          <label class="md-nav__link" for="__nav_2_1_7" id="__nav_2_1_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Ch A. Appendix - Basics of Monte Carlo
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_7">
            <span class="md-nav__icon md-icon"></span>
            Ch A. Appendix - Basics of Monte Carlo
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../13/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    13. Basics of Monte Carlo
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/18b01xoORd0LFQmpfc_4ou5Rv44MY1neg/view?usp=sharing" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter A Code
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_8" >
        
          
          <label class="md-nav__link" for="__nav_2_1_8" id="__nav_2_1_8_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Python Basics
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_8">
            <span class="md-nav__icon md-icon"></span>
            Python Basics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/1-iY9XfDhWNRDq3z_wVVvOzU04aRQWAfW/view?usp=drive_link" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Python Lecture 1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/1BANbCC6jBjPEUFSRJMFkcLbc4oVmoQHm/view?usp=sharing" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Python Lecture 2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/1-Bc11RZmno6yx37kfVLjsyY-XKpLK5Je/view?usp=drive_link" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Python Lecture 3
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="목차">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      목차
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#inverse-problem" class="md-nav__link">
    <span class="md-ellipsis">
      Inverse Problem
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Inverse Problem">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gaussian-denoising" class="md-nav__link">
    <span class="md-ellipsis">
      Gaussian Denoising
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#image-super-resolution" class="md-nav__link">
    <span class="md-ellipsis">
      Image Super-Resolution
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#other-examples" class="md-nav__link">
    <span class="md-ellipsis">
      Other Examples
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#operations-increasing-spatial-dimensions" class="md-nav__link">
    <span class="md-ellipsis">
      Operations Increasing Spatial Dimensions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Operations Increasing Spatial Dimensions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#transposed-convolution" class="md-nav__link">
    <span class="md-ellipsis">
      Transposed convolution
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#upsampling" class="md-nav__link">
    <span class="md-ellipsis">
      Upsampling
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#semantic-segmentation" class="md-nav__link">
    <span class="md-ellipsis">
      Semantic Segmentation
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="8-cnns-for-other-supervised-learning-tasks">§ 8. CNNs for Other Supervised Learning Tasks<a class="headerlink" href="#8-cnns-for-other-supervised-learning-tasks" title="Permanent link">&para;</a></h1>
<h2 id="inverse-problem">Inverse Problem<a class="headerlink" href="#inverse-problem" title="Permanent link">&para;</a></h2>
<div class="admonition definition">
<p class="admonition-title">Definition 8.1 <a id="definition-8-1"></a>: Inverse Problem Model</p>
<p>In <strong>inverse problems</strong>, we wish to recover a signal <span class="arithmatex">\(X_{\text {true }}\)</span> given measurements <span class="arithmatex">\(Y\)</span>. The unknown and the measurements are related through</p>
<div class="arithmatex">\[
\mathcal{A}\left[X_{\text {true }}\right]+\varepsilon=Y,
\]</div>
<p>where <span class="arithmatex">\(\mathcal{A}\)</span> is often, but not always, linear, and <span class="arithmatex">\(\varepsilon\)</span> represents small error.</p>
<p>The <strong>forward model</strong> <span class="arithmatex">\(\mathcal{A}\)</span> may or may not be known. In other words, the goal of an inverse problem is to find an <strong>approximation of <span class="arithmatex">\(\mathcal{A}^{-1}\)</span></strong>.</p>
<p>In many cases, <span class="arithmatex">\(\mathcal{A}\)</span> is not even be invertible. In such cases, we can still hope to find an mapping that serves as an approximate inverse in practice.</p>
</div>
<div class="admonition concept">
<p class="admonition-title">Concept 8.2 <a id="concept-8-2"></a>: Inverse Problems via Deep Learning</p>
<p>In deep learning, we use a neural network to approximate the inverse mapping</p>
<div class="arithmatex">\[
f_{\theta} \approx \mathcal{A}^{-1}
\]</div>
<p>i.e., we want <span class="arithmatex">\(f_{\theta}(Y) \approx X_{\text {true }}\)</span> for the measurements <span class="arithmatex">\(X\)</span> that we care about.</p>
<p>If we have <span class="arithmatex">\(X_{1}, \ldots, X_{N}\)</span> and <span class="arithmatex">\(Y_{1}, \ldots, Y_{N}\)</span> (but no direct knowledge of <span class="arithmatex">\(\mathcal{A}\)</span> ), we can solve</p>
<div class="arithmatex">\[
\underset{\theta \in \mathbb{R}^{p}}{\operatorname{minimize}} \sum_{i=1}^{N}\left\|f_{\theta}\left(Y_{i}\right)-X_{i}\right\|
\]</div>
<p>If we have <span class="arithmatex">\(X_{1}, \ldots, X_{N}\)</span> and knowledge of <span class="arithmatex">\(\mathcal{A}\)</span>, we can solve</p>
<div class="arithmatex">\[
\underset{\theta \in \mathbb{R}^{p}}{\operatorname{minimize}} \sum_{i=1}^{N}\left\|f_{\theta}\left[\mathcal{A}\left(X_{i}\right)\right]-X_{i}\right\|
\]</div>
<p>If we have <span class="arithmatex">\(Y_{1}, \ldots, Y_{N}\)</span> and knowledge of <span class="arithmatex">\(\mathcal{A}\)</span>, we can solve</p>
<div class="arithmatex">\[
\underset{\theta \in \mathbb{R}^{p}}{\operatorname{minimize}} \sum_{i=1}^{N}\left\|\mathcal{A}\left[f_{\theta}\left(Y_{i}\right)\right]-Y_{i}\right\|
\]</div>
</div>
<h3 id="gaussian-denoising">Gaussian Denoising<a class="headerlink" href="#gaussian-denoising" title="Permanent link">&para;</a></h3>
<div class="admonition definition">
<p class="admonition-title">Definition 8.3 <a id="definition-8-3"></a>: Gaussian Denoising</p>
<p>Given <span class="arithmatex">\(X_{\text {true }} \in \mathbb{R}^{w \times h}\)</span>, we measure</p>
<div class="arithmatex">\[
Y=X_{\text {true }}+\varepsilon
\]</div>
<p>where <span class="arithmatex">\(\varepsilon_{i j} \sim \mathcal{N}\left(0, \sigma^{2}\right)\)</span> is IID Gaussian noise. For the sake of simplicity, assume we know <span class="arithmatex">\(\sigma\)</span>. Goal is to recover <span class="arithmatex">\(X_{\text {true }}\)</span> from <span class="arithmatex">\(Y\)</span>.</p>
<p><strong>Gaussian denoising</strong> is the simplest setup in which the goal is to remove noise from the image. In more realistic setups, the noise model will be more complicated and the noise level <span class="arithmatex">\(\sigma\)</span> will be unknown.</p>
</div>
<div class="admonition definition">
<p class="admonition-title">Definition 8.4 <a id="definition-8-4"></a>: DnCNN</p>
<p>In 2017, Zhang et al. presented the <strong>denoising convolutional neural networks (DnCNNs)</strong>. They trained a 17-layer CNN <span class="arithmatex">\(f_{\theta}\)</span> to learn the noise with the loss</p>
<div class="arithmatex">\[
\mathcal{L}(\theta)=\sum_{i=1}^{N}\left\|f_{\theta}\left(Y_{i}\right)-\left(Y_{i}-X_{i}\right)\right\|^{2}
\]</div>
<p>so that the clean recovery can be obtained with <span class="arithmatex">\(Y_{i}-f_{\theta}\left(Y_{i}\right)\)</span>. (This is equivalent to using a residual connection from beginning to end.)</p>
<p><center>
<img alt="" src="../../assets/8.1.png" width="70%" />
</center></p>
<hr />
<p>Image denoising is was an area with a large body of prior work. DnCNN dominated all prior approaches that were not based on deep learning.</p>
<p>Nowadays, all state-of-the-art denoising algorithms are based on deep learning.</p>
<p><center>
<img alt="" src="../../assets/8.2.png" width="100%" />
</center></p>
<p>(K. Zhang, W. Zuo, Y. Chen, D. Meng, and L. Zhang, Beyond a Gaussian denoiser: Residual learning of deep CNN for image denoising, IEEE TIP, 2017.)</p>
</div>
<h3 id="image-super-resolution">Image Super-Resolution<a class="headerlink" href="#image-super-resolution" title="Permanent link">&para;</a></h3>
<div class="admonition definition">
<p class="admonition-title">Definition 8.5 <a id="definition-8-5"></a>: Image Super-Resolution</p>
<p>Given <span class="arithmatex">\(X_{\text {true }} \in \mathbb{R}^{w \times h}\)</span>, we measure</p>
<div class="arithmatex">\[
Y=\mathcal{A}\left(X_{\text {true }}\right)
\]</div>
<p>where <span class="arithmatex">\(\mathcal{A}\)</span> is a "downsampling" operator. So <span class="arithmatex">\(Y \in \mathbb{R}^{w_{2} \times h_{2}}\)</span> with <span class="arithmatex">\(w_{2}&lt;w\)</span> and <span class="arithmatex">\(h_{2}&lt;h\)</span>. Goal is to recover <span class="arithmatex">\(X_{\text {true }}\)</span> from <span class="arithmatex">\(Y\)</span>.</p>
<p>In the simplest setup, <span class="arithmatex">\(\mathcal{A}\)</span> is an average pool operator with <span class="arithmatex">\(r \times r\)</span> kernel and a stride <span class="arithmatex">\(r\)</span>.</p>
</div>
<div class="admonition definition">
<p class="admonition-title">Definition 8.6 <a id="definition-8-6"></a>: SRCNN</p>
<p>In 2015, Dong et al. presented super-resolution convolutional neural network (SRCNN). They trained a 3-layer <span class="arithmatex">\(\operatorname{CNN} f_{\theta}\)</span> to learn the high-resolution reconstruction with the loss</p>
<div class="arithmatex">\[
\mathcal{L}(\theta)=\sum_{i=1}^{N}\left\|f_{\theta}\left(\tilde{Y}_{i}\right)-X_{i}\right\|^{2}
\]</div>
<p>where <span class="arithmatex">\(\tilde{Y}_{i} \in \mathbb{R}^{w \times h}\)</span> is an upsampled version of <span class="arithmatex">\(Y_{i} \in \mathbb{R}^{(w / r) \times(h / r)}\)</span>, i.e., <span class="arithmatex">\(\tilde{Y}_{i}\)</span> has the same number of pixels as <span class="arithmatex">\(X_{i}\)</span>, but the image is pixelated or blurry. The goal is to have <span class="arithmatex">\(f_{\theta}\left(\tilde{Y}_{i}\right)\)</span> be a sharp reconstruction.</p>
<p><center>
<img alt="" src="../../assets/8.3.png" width="70%" />
</center></p>
<hr />
<p>SRCNN showed that simple learning based approaches can match the state-of the art performances of superresolution task.</p>
<p><center>
<img alt="" src="../../assets/8.4.png" width="100%" />
</center></p>
<p>(C. Dong, C. C. Loy, K. He, and X. Tang, Image super-resolution using deep convolutional networks, IEEE TPAMI, 2015.)</p>
</div>
<div class="admonition definition">
<p class="admonition-title">Definition 8.7 <a id="definition-8-7"></a>: VDSR</p>
<p>In 2016, Kim et al. presented VDSR. They trained a 20-layer CNN with a residual connection <span class="arithmatex">\(f_{\theta}\)</span> to learn the high-resolution reconstruction with the loss</p>
<div class="arithmatex">\[
\mathcal{L}(\theta)=\sum_{i=1}^{N}\left\|f_{\theta}\left(\tilde{Y}_{i}\right)-X_{i}\right\|^{2}
\]</div>
<p>The residual connection was the key insight that enabled the training of much deeper CNNs.</p>
<p><center>
<img alt="" src="../../assets/8.5.png" width="70%" />
</center></p>
<hr />
<p>VDSR dominated all prior approaches not based on deep learning.
Showed that simple learning based approaches can batch the state-of theart performances of super-resolution task.</p>
<p><center>
<img alt="" src="../../assets/8.6.png" width="100%" />
</center></p>
<p>(J. Kim, J. K. Lee, and K. M. Lee, Accurate image super-resolution using very deep convolutional networks, CVPR, 2016.)</p>
</div>
<h3 id="other-examples">Other Examples<a class="headerlink" href="#other-examples" title="Permanent link">&para;</a></h3>
<div class="admonition example">
<p class="admonition-title">Example 8.8 <a id="example-8-8"></a>: SRGAN</p>
<p><center>
<img alt="" src="../../assets/8.7.png" width="100%" />
</center></p>
<p><center>
<img alt="" src="../../assets/8.8.png" width="100%" />
</center></p>
<p><center>
<img alt="" src="../../assets/8.9.png" width="100%" />
</center></p>
<p>(C. Ledig, L. Theis, F. Huszar, J. Caballero, A. Cunningham, A. Acosta, A. Aitken, A. Tejani, J. Totz, Z. Wang, and W. Shi, Photo-realistic single image super-resolution using a generative adversarial network, CVPR, 2017.)</p>
</div>
<div class="admonition example">
<p class="admonition-title">Example 8.9 <a id="example-8-9"></a>: Image Colorization</p>
<p><center>
<img alt="" src="../../assets/8.10.png" width="100%" />
</center></p>
<p>(R. Zhang, P. Isola, and A. A. Efros, Colorful image colorization, ECCV, 2016.)</p>
</div>
<div class="admonition example">
<p class="admonition-title">Example 8.10 <a id="example-8-10"></a>: Image Inpainting</p>
<p><center>
<img alt="" src="../../assets/8.11.png" width="100%" />
</center></p>
<p><center>
<img alt="" src="../../assets/8.12.png" width="100%" />
</center></p>
<p>(J. Yu, Z. Lin, J. Yang, X. Shen, X. Lu, and T. S. Huang, Generative image inpainting with contextual attention, CVPR, 2018.)</p>
</div>
<h2 id="operations-increasing-spatial-dimensions">Operations Increasing Spatial Dimensions<a class="headerlink" href="#operations-increasing-spatial-dimensions" title="Permanent link">&para;</a></h2>
<div class="admonition concept">
<p class="admonition-title">Concept 8.11 <a id="concept-8-11"></a>: Operations Increasing Spatial Dimensions</p>
<p>In image classification tasks, the spatial dimensions of neural networks often decrease as the depth progresses.</p>
<p>This is because we are trying to forget location information. (In classification, we care about what is in the image, but we do not where it is in the image.)</p>
<p>However, there are many networks for which we want to increase the spatial dimension:</p>
<ul>
<li>Linear layers</li>
<li>Upsampling</li>
<li>Transposed convolution</li>
</ul>
</div>
<h3 id="transposed-convolution">Transposed convolution<a class="headerlink" href="#transposed-convolution" title="Permanent link">&para;</a></h3>
<div class="admonition concept">
<p class="admonition-title">Concept 8.12 <a id="concept-8-12"></a>: Linear Operator <span class="arithmatex">\(\cong\)</span> Matrix</p>
<p>Core tenet of linear algebra: matrices are linear operators and linear operators are matrices.</p>
<p>Let <span class="arithmatex">\(f: \mathbb{R}^{n} \rightarrow \mathbb{R}^{m}\)</span> be linear, i.e.,</p>
<div class="arithmatex">\[
f(x+y)=f(x)+f(y) \text { and } f(\alpha x)=\alpha f(x)
\]</div>
<p>for all <span class="arithmatex">\(x, y \in \mathbb{R}^{n}\)</span> and <span class="arithmatex">\(\alpha \in \mathbb{R}\)</span>.</p>
<p>There exists a matrix <span class="arithmatex">\(A \in \mathbb{R}^{m \times n}\)</span> that represents <span class="arithmatex">\(f: \mathbb{R}^{n} \rightarrow \mathbb{R}^{m}\)</span>, i.e.,</p>
<div class="arithmatex">\[
f(x)=A x
\]</div>
<p>for all <span class="arithmatex">\(x \in \mathbb{R}^{n}\)</span>.</p>
<p>Let <span class="arithmatex">\(e_{i}\)</span> be the <span class="arithmatex">\(i\)</span>-th unit vector, i.e., <span class="arithmatex">\(e_{i}\)</span> has all zeros elements except entry 1 in the <span class="arithmatex">\(i\)</span>-th coordinate.</p>
<p>Given a linear <span class="arithmatex">\(f: \mathbb{R}^{n} \rightarrow \mathbb{R}^{m}\)</span>, we can find the matrix</p>
<div class="arithmatex">\[
A=\left[\begin{array}{llll}
A_{;, 1} &amp; A_{;, 2} &amp; \cdots &amp; A_{;, n}
\end{array}\right] \in \mathbb{R}^{m \times n}
\]</div>
<p>representing <span class="arithmatex">\(f\)</span> with</p>
<div class="arithmatex">\[
f\left(e_{j}\right)=A e_{j}=A_{;, j}
\]</div>
<p>for all <span class="arithmatex">\(j=1, \ldots, n\)</span>, or with</p>
<div class="arithmatex">\[
e_{i}^{\top} f\left(e_{j}\right)=e_{i}^{\top} A e_{j}=A_{i, j}
\]</div>
<p>for all <span class="arithmatex">\(i=1, \ldots, m\)</span> and <span class="arithmatex">\(j=1, \ldots, n\)</span>.</p>
</div>
<div class="admonition concept">
<p class="admonition-title">Concept 8.13 <a id="concept-8-13"></a>: Linear Operator <span class="arithmatex">\(\ncong\)</span> Matrix</p>
<p>In applied mathematics and machine learning, there are many setups where explicitly forming the matrix representation <span class="arithmatex">\(A \in \mathbb{R}^{m \times n}\)</span> is costly, even though the matrix-vector products <span class="arithmatex">\(A x\)</span> and <span class="arithmatex">\(A^{\top} y\)</span> are efficient to evaluate.</p>
<p>In machine learning, convolutions are the primary example. Other areas, linear operators based on FFTs are the primary example.</p>
<p>In such setups, the matrix representation is still a useful conceptual tool, even if we never intend to form the matrix.</p>
</div>
<p>Given a matrix <span class="arithmatex">\(A\)</span>, the transpose <span class="arithmatex">\(A^{\top}\)</span> is obtained by flipping the row and column dimensions, i.e., <span class="arithmatex">\(\left(A^{\top}\right)_{i j}=(A)_{j i}\)</span>.
However, using this definition is not always the most effective when understanding the action of <span class="arithmatex">\(A^{\top}\)</span>.</p>
<p>Another approach is to use the adjoint view. Since</p>
<div class="arithmatex">\[
y^{\top}(A x)=\left(A^{\top} y\right)^{\top} x
\]</div>
<p>for any <span class="arithmatex">\(x \in \mathbb{R}^{n}\)</span> and <span class="arithmatex">\(y \in \mathbb{R}^{m}\)</span>, understand the action of <span class="arithmatex">\(A^{\top}\)</span> by finding an expression of the form</p>
<div class="arithmatex">\[
y^{\top} A x=\sum_{j=1}^{n}(\text { something })_{j} x_{j}=\left(A^{\top} y\right)^{\top} x
\]</div>
<div class="admonition example">
<p class="admonition-title">Example 8.14 <a id="example-8-14"></a>: 1D Transpose Convolution</p>
<p>Consider the 1D convolution represented by <span class="arithmatex">\(A \in \mathbb{R}^{(n-f+1) \times n}\)</span> defined with a given <span class="arithmatex">\(w \in \mathbb{R}^{f}\)</span> and</p>
<div class="arithmatex">\[
A=\left[\begin{array}{cccccccc}
w_{1} &amp; \cdots &amp; w_{f} &amp; 0 &amp; \cdots &amp; &amp; &amp; 0 \\
0 &amp; w_{1} &amp; \cdots &amp; w_{f} &amp; 0 &amp; \cdots &amp; &amp; 0 \\
0 &amp; 0 &amp; w_{1} &amp; \cdots &amp; w_{f} &amp; 0 &amp; \cdots &amp; 0 \\
\vdots &amp; &amp; &amp; \ddots &amp; &amp; \ddots &amp; &amp; \vdots \\
0 &amp; &amp; \cdots &amp; 0 &amp; w_{1} &amp; \cdots &amp; w_{f} &amp; 0 \\
0 &amp; &amp; \cdots &amp; 0 &amp; 0 &amp; w_{1} &amp; \cdots &amp; w_{f}
\end{array}\right]
\]</div>
<p>Then we have</p>
<div class="arithmatex">\[
(A x)_{j}=\sum_{i=1}^{f} w_{i} x_{j+i-1}
\]</div>
<hr />
<p>and we have the following formula which coincides with transposing the matrix <span class="arithmatex">\(A\)</span>.</p>
<div class="arithmatex">\[
\begin{aligned}
y^{\top} A x &amp; =\sum_{j=1}^{n-f+1} y_{j} \sum_{i=1}^{f} w_{i} x_{j+i-1} \\
&amp; =\sum_{j=1}^{n-f+1} \sum_{i=1}^{f} y_{j} w_{i} x_{j+i-1} \sum_{k=1}^{n} \mathbf{1}_{\{k=j+i-1\}} \\
&amp; =\sum_{k=1}^{n} \sum_{j=1}^{n-f+1} \sum_{i=1}^{f} y_{j} w_{i} x_{k} \mathbf{1}_{\{k-j+1=i\}} \\
&amp; =\sum_{k=1}^{n} x_{k} \sum_{j=1}^{n-f+1} \sum_{i=1}^{f} w_{k-j+1} y_{j} \mathbf{1}_{\{k-j+1=i\}} \\
&amp; =\sum_{k=1}^{n} x_{k} \sum_{j=1}^{n-f+1} w_{k-j+1} y_{j} \sum_{i=1}^{f} \mathbf{1}_{\{k-j+1=i\}} \\
&amp; =\sum_{k=1}^{n} x_{k} \sum_{j=1}^{n-f+1} w_{k-j+1} y_{j} \mathbf{1}_{\{1 \leq k-j+1 \leq f\}} \\
&amp; =\sum_{k=1}^{n} x_{k} \sum_{j=1}^{n-f+1} w_{k-j+1} y_{j} \mathbf{1}_{\{j \leq k\}} \mathbf{1}_{\{k-f+1 \leq j\}} \\
&amp; =\sum_{k=1}^{n} x_{k} \sum_{j=\max (k-f+1,1)}^{\min (n-f+1, k)} w_{k-j+1} y_{j}=\left(A^{\top} y\right)^{\top} x \\
\end{aligned}
\]</div>
</div>
<div class="admonition definition">
<p class="admonition-title">Definition 8.15 <a id="definition-8-15"></a>: Transposed Convolution</p>
<p>In transposed convolution, input neurons additively distribute values to the output via the kernel.
Before people noticed that this is the transpose of convolution, the names backwards convolution and deconvolution were used.</p>
<p>For each input neuron, multiply the kernel and add (accumulate) the value in the output.
Can accommodate strides, padding, and multiple channels.</p>
<p><center>
<img alt="" src="../../assets/8.13.png" width="100%" />
</center></p>
<p><center>
<img alt="" src="../../assets/8.14.png" width="100%" />
</center></p>
</div>
<ul>
<li>Convolution Visualized</li>
</ul>
<center>
![](.././assets/8.15.gif){: width="50%"}
</center>

<ul>
<li>Transpose Convolution Visualized</li>
</ul>
<center>
![](.././assets/8.16.gif){: width="100%"}
</center>

<div class="admonition definition">
<p class="admonition-title">Definition 8.16 <a id="definition-8-16"></a>: 2D Transpose Convolution Layer (Formal Definition)</p>
<ul>
<li><span class="arithmatex">\(B\)</span> : batch size</li>
<li><span class="arithmatex">\(C_{\text{in}}\)</span> : # of input channels</li>
<li><span class="arithmatex">\(C_{\text{out}}\)</span> : # of output channels</li>
<li><span class="arithmatex">\(m, n\)</span> : # of vertical and horizontal indices of input</li>
<li><span class="arithmatex">\(f_1, f_2\)</span> : # of vertical and horizontal indices of filter</li>
</ul>
<hr />
<ul>
<li>Input tensor: <span class="arithmatex">\(Y \in \mathbb{R}^{B \times C_{\mathrm{in}} \times m \times n}\)</span></li>
<li>Output tensor: <span class="arithmatex">\(X \in \mathbb{R}^{B \times C_{\text {out }} \times\left(m+f_{1}-1\right) \times\left(n+f_{2}-1\right)}\)</span></li>
<li>Filter <span class="arithmatex">\(w \in \mathbb{R}^{C_{\text {in }} \times C_{\text {out }} \times f_{1} \times f_{2}}\)</span></li>
<li>Bias <span class="arithmatex">\(b \in \mathbb{R}^{C_{\text {out }}}\)</span> (If <code>bias=False</code>, then <span class="arithmatex">\(b=0\)</span>.) </li>
</ul>
<hr />
<div class="language-text highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>def trans_conv(Y, w, b):
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    c_in, c_out, f1, f2 = w.shape
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    batch, c_in, m, n = Y.shape
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    X = torch.zeros(batch, c_out, m + f1 - 1, n + f2 - 1)
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    for k in range(c_in):
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>        for i in range(Y.shape[2]):
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>            for j in range(Y.shape[3]):
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>                X[:, :, i:i+f1, j:j+f2] += Y[:, k, i, j].view(-1,1,1,1)*w[k, :, :, :].unsqueeze(0)
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    return X + b.view(1,-1,1,1)
</span></code></pre></div>
</div>
<p>In a matrix representation <span class="arithmatex">\(A\)</span> of convolution, the dependencies of the inputs and outputs are represented by the non-zeros of <span class="arithmatex">\(A\)</span>, i.e., the sparsity pattern of <span class="arithmatex">\(A\)</span>.
If <span class="arithmatex">\(A_{i j}=0\)</span>, then input neuron <span class="arithmatex">\(j\)</span> does not affect the output neuron <span class="arithmatex">\(i\)</span>. If <span class="arithmatex">\(A_{i j} \neq 0\)</span>, then <span class="arithmatex">\(\left(A^{\top}\right)_{j i} \neq 0\)</span>. So if input neuron <span class="arithmatex">\(j\)</span> affects output neuron <span class="arithmatex">\(i\)</span> in convolution, then input neuron <span class="arithmatex">\(i\)</span> affects output neuron <span class="arithmatex">\(j\)</span> in transposed convolution.</p>
<center>
![](.././assets/8.17.png){: width="50%"}
</center>

<p>We can combine this reasoning with our visual understanding of convolution. The diagram simultaneously illustrates the dependencies for both convolution and transposed convolution.</p>
<h3 id="upsampling">Upsampling<a class="headerlink" href="#upsampling" title="Permanent link">&para;</a></h3>
<div class="admonition concept">
<p class="admonition-title">Concept 8.17 <a id="concept-8-17"></a>: Upsampling</p>
<p><code>torch.nn.Upsample</code> with <code>mode='nearest'</code></p>
<p><center>
<img alt="" src="../../assets/8.18.png" width="75%" />
</center></p>
</div>
<div class="admonition concept">
<p class="admonition-title">Concept 8.18 <a id="concept-8-18"></a>: Upsampling</p>
<p><code>Torch.nn.Upsample</code> with <code>mode='bilinear'</code><br />
<code>linear</code> interpolation is available for 1D data<br />
<code>trilinear</code> interpolation is available for 3D data<br />
(We won't pay attention to the interpolation formula.)</p>
<p><center>
<img alt="" src="../../assets/8.19.png" width="75%" />
</center></p>
</div>
<h2 id="semantic-segmentation">Semantic Segmentation<a class="headerlink" href="#semantic-segmentation" title="Permanent link">&para;</a></h2>
<div class="admonition definition">
<p class="admonition-title">Definition 8.19 <a id="definition-8-19"></a>: Semantic Segmentation</p>
<p>In <strong>semantic segmentation</strong>, the goal is to segment the image into semantically meaningful regions by classifying each pixel.</p>
<p><center>
<img alt="" src="../../assets/8.20.png" width="100%" />
</center></p>
</div>
<div class="admonition definition">
<p class="admonition-title">Definition 8.20 <a id="definition-8-20"></a>: Object Localization</p>
<p><strong>Object localization</strong> localizes a single object usually via a bounding box.</p>
<p><center>
<img alt="" src="../../assets/8.21.png" width="60%" />
</center></p>
</div>
<div class="admonition definition">
<p class="admonition-title">Definition 8.21 <a id="definition-8-21"></a>: Object Detection</p>
<p><strong>Object detection</strong> detects many objects, with the same class often repeated, usually via bounding boxes.</p>
<p><center>
<img alt="" src="../../assets/8.22.png" width="100%" />
</center></p>
</div>
<div class="admonition definition">
<p class="admonition-title">Definition 8.22 <a id="definition-8-22"></a>: Image Segmentation</p>
<p><strong>Instance segmentation</strong> distinguishes multiple instances of the same object type.</p>
<p><center>
<img alt="" src="../../assets/8.23.png" width="100%" />
</center></p>
</div>
<p>We will focus on semantic segmentation.</p>
<div class="admonition definition">
<p class="admonition-title">Definition 8.23 <a id="definition-8-23"></a>: Pascal VOC</p>
<p>We will use <strong>PASCAL Visual Object Classes (VOC) dataset</strong> for semantic segmentation.
(Dataset also contains labels for object detection.)</p>
<p>There are 21 classes: 20 main classes and 1 "unlabeled" class.</p>
<p>Data <span class="arithmatex">\(X_{1}, \ldots, X_{N} \in \mathbb{R}^{3 \times m \times n}\)</span> and labels <span class="arithmatex">\(Y_{1}, \ldots, Y_{N} \in\{0,1, \ldots, 20\}^{m \times n}\)</span>, i.e., <span class="arithmatex">\(Y_{i}\)</span> provides a class label for every pixel of <span class="arithmatex">\(X_{i}\)</span>.</p>
<p><center>
<img alt="" src="../../assets/8.24.png" width="40%" />
</center></p>
</div>
<div class="admonition concept">
<p class="admonition-title">Concept 8.24 <a id="concept-8-24"></a>: Loss for Semantic Segmentation</p>
<p>Consider the neural network</p>
<div class="arithmatex">\[
f_{\theta}: \mathbb{R}^{3 \times m \times n} \rightarrow \mathbb{R}^{k \times m \times n}
\]</div>
<p>such that <span class="arithmatex">\(\mu\left(f_{\theta}(X)\right)_{i j} \in \Delta^{k}\)</span> is the probabilities for the <span class="arithmatex">\(k\)</span> classes for pixel <span class="arithmatex">\((i, j)\)</span>.</p>
<p>We minimize the sum of pixel-wise cross-entropy losses</p>
<div class="arithmatex">\[
\mathcal{L}(\theta)=\sum_{l=1}^{N} \sum_{i=1}^{m} \sum_{j=1}^{n} \ell^{\mathrm{CE}}\left(f_{\theta}\left(X_{l}\right)_{i j},\left(Y_{l}\right)_{i j}\right)
\]</div>
<p>where <span class="arithmatex">\(\ell^{C E}\)</span> is the cross entropy loss.</p>
</div>
<div class="admonition definition">
<p class="admonition-title">Definition 8.25 <a id="definition-8-25"></a>: U-Net</p>
<p>The U-Net architecture:</p>
<ul>
<li>Reduce the spatial dimension to obtain high-level (coarse scale) features</li>
<li>Upsample or transpose convolution to restore spatial dimension.</li>
<li>Use residual connections across each dimension reduction stage.</li>
</ul>
<p><center>
<img alt="" src="../../assets/8.25.jpg" width="100%" />
</center></p>
</div>
<div class="admonition definition">
<p class="admonition-title">Definition 8.26 <a id="definition-8-26"></a>: Magnetic Resonance Imaging (MRI)</p>
<p><strong>Magnetic resonance imaging (MRI)</strong> is an inverse problem in which we partially measure the Fourier transform of the patient and the goal is to reconstruct the patient's image.</p>
<p>So <span class="arithmatex">\(X_{\text {true }} \in \mathbb{R}^{n}\)</span> is the true original image (reshaped into a vector) with <span class="arithmatex">\(n\)</span> pixels or voxels and <span class="arithmatex">\(\mathcal{A}\left[X_{\text {true }}\right] \in \mathbb{C}^{k}\)</span> with <span class="arithmatex">\(k \ll n\)</span>. (If <span class="arithmatex">\(k=n\)</span>, MRI scan can take hours.)</p>
<p>Classical reconstruction algorithms rely on Fourier analysis, total variation regularization, compressed sensing, and optimization.</p>
<p>Recent state-of-the-art use deep neural networks.</p>
</div>
<div class="admonition definition">
<p class="admonition-title">Definition 8.27 <a id="definition-8-27"></a>: FastMRI Dataset</p>
<p>A team of researchers from Facebook AI Research and NYU released a large MRI dataset to stimulate datadriven deep learning research for MRI reconstruction.</p>
<p><center>
<img alt="" src="../../assets/8.26.jpg" width="70%" />
</center></p>
<p>(J. Zbontar, F. Knoll, A. Sriram, T. Murrell, Z. Huang, M. J. Muckley, A. Defazio, R. Stern, P. Johnson, M. Bruno, M. Parente, K. J. Geras, J. Katsnelson, H. Chandarana, Z. Zhang, M. Drozdzal, A. Romero, M. Rabbat, P. Vincent, N. Yakubova, J. Pinkerton, D. Wang, E. Owens, C. L. Zitnick, M. P. Recht, D. K. Sodickson, and Y. W. Lui, fastMRI: An open dataset and benchmarks for accelerated MRI, arXiv, 2019.)</p>
</div>
<div class="admonition definition">
<p class="admonition-title">Definition 8.28 <a id="definition-8-28"></a>: Computational Tomography (CT)</p>
<p><strong>Computational tomography (CT)</strong> is an inverse problem in which we partially measure the Radon transform of the patient and the goal is to reconstruct the patient's image.</p>
<p>So <span class="arithmatex">\(X_{\text {true }} \in \mathbb{R}^{n}\)</span> is the true original image (reshaped into a vector) with <span class="arithmatex">\(n\)</span> pixels or voxels and <span class="arithmatex">\(\mathcal{A}\left[X_{\text {true }}\right] \in \mathbb{R}^{k}\)</span> with <span class="arithmatex">\(k \ll n\)</span>. (If <span class="arithmatex">\(k=n\)</span>, the X -ray exposure to perform the CT scan can be harmful.)</p>
<p>Recent state-of-the-art use deep neural networks.</p>
</div>
<div class="admonition concept">
<p class="admonition-title">Concept 8.29 <a id="concept-8-29"></a>: U-Net is used for inverse problems.</p>
<p>Although U-Net was originally proposed as an architecture for semantic segmentation, it is also being used widely as one of the default architectures in inverse problems, including MRI reconstruction.</p>
<p><center>
<img alt="" src="../../assets/8.27.jpg" width="100%" />
</center></p>
<p>(J. Zbontar, F. Knoll, A. Sriram, T. Murrell, Z. Huang, M. J. Muckley, A. Defazio, R. Stern, P. Johnson, M. Bruno, M. Parente, K. J. Geras, J. Katsnelson, H. Chandarana, Z. Zhang, M. Drozdzal, A. Romero, M. Rabbat, P. Vincent, N. Yakubova, J. Pinkerton, D. Wang, E. Owens, C. L. Zitnick, M. P. Recht, D. K. Sodickson, and Y. W. Lui, fastMRI: An open dataset and benchmarks for accelerated MRI, arXiv, 2019.)</p>
<hr />
<p>U-Net is also used as one of the default architectures in CT reconstruction.</p>
<p><center>
<img alt="" src="../../assets/8.28.png" width="100%" />
</center></p>
<p><center>
<img alt="" src="../../assets/8.29.png" width="70%" />
</center></p>
<p>(K. H. Jin, M. T. McCann, E. Froustey, and M. Unser, Deep convolutional neural network for inverse problems in imaging, IEEE TIP, 2017.)</p>
</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  맨위로
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/arnold518" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../../..", "features": ["content.code.copy", "header.autohide", "navigation.instant", "navigation.tracking", "navigation.tabs", "toc.follow", "navigation.top", "search.suggest", "search.highlight", "search.share", "navigation.indexes"], "search": "../../../../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "\ud074\ub9bd\ubcf4\ub4dc\uc5d0 \ubcf5\uc0ac\ub428", "clipboard.copy": "\ud074\ub9bd\ubcf4\ub4dc\ub85c \ubcf5\uc0ac", "search.result.more.one": "\uc774 \ubb38\uc11c\uc5d0\uc11c 1\uac1c\uc758 \uac80\uc0c9 \uacb0\uacfc \ub354 \ubcf4\uae30", "search.result.more.other": "\uc774 \ubb38\uc11c\uc5d0\uc11c #\uac1c\uc758 \uac80\uc0c9 \uacb0\uacfc \ub354 \ubcf4\uae30", "search.result.none": "\uac80\uc0c9\uc5b4\uc640 \uc77c\uce58\ud558\ub294 \ubb38\uc11c\uac00 \uc5c6\uc2b5\ub2c8\ub2e4", "search.result.one": "1\uac1c\uc758 \uc77c\uce58\ud558\ub294 \ubb38\uc11c", "search.result.other": "#\uac1c\uc758 \uc77c\uce58\ud558\ub294 \ubb38\uc11c", "search.result.placeholder": "\uac80\uc0c9\uc5b4\ub97c \uc785\ub825\ud558\uc138\uc694", "search.result.term.missing": "\ud3ec\ud568\ub418\uc9c0 \uc54a\uc740 \uac80\uc0c9\uc5b4", "select.version": "\ubc84\uc804 \uc120\ud0dd"}, "version": null}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
        <script src="../../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>