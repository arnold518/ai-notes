
<!doctype html>
<html lang="ko" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.12">
    
    
      
        <title>Chapter 1: Optimization and Stochastic Gradient Descent - Artificial Intelligence Notes</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.2afb09e1.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      
  
  
    
    
  
    
    
  
  
  <style>:root{--md-admonition-icon--note:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2024%2024%22%3E%3Cpath%20d%3D%22M12%206a6%206%200%200%201%206%206c0%202.22-1.21%204.16-3%205.2V19a1%201%200%200%201-1%201h-4a1%201%200%200%201-1-1v-1.8c-1.79-1.04-3-2.98-3-5.2a6%206%200%200%201%206-6m2%2015v1a1%201%200%200%201-1%201h-2a1%201%200%200%201-1-1v-1zm6-10h3v2h-3zM1%2011h3v2H1zM13%201v3h-2V1zM4.92%203.5l2.13%202.14-1.42%201.41L3.5%204.93zm12.03%202.13%202.12-2.13%201.43%201.43-2.13%202.12z%22/%3E%3C/svg%3E');--md-admonition-icon--tip:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20512%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%206.7.2%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202024%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M256%200a256%20256%200%201%201%200%20512%20256%20256%200%201%201%200-512m-24%20120v136c0%208%204%2015.5%2010.7%2020l96%2064c11%207.4%2025.9%204.4%2033.3-6.7s4.4-25.9-6.7-33.3L280%20243.2V120c0-13.3-10.7-24-24-24s-24%2010.7-24%2024%22/%3E%3C/svg%3E');}</style>



    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:300,300i,400,400i,700,700i%7CUbuntu+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Noto Sans";--md-code-font:"Ubuntu Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="deep-orange" data-md-color-accent="deep-orange">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#chapter-1-optimization-and-stochastic-gradient-descent" class="md-skip">
          콘텐츠로 이동
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="상단/헤더">
    <a href="../../.." title="Artificial Intelligence Notes" class="md-header__button md-logo" aria-label="Artificial Intelligence Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Artificial Intelligence Notes
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Chapter 1: Optimization and Stochastic Gradient Descent
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="deep-orange" data-md-color-accent="deep-orange"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="deep-orange" data-md-color-accent="deep-orange"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="검색" placeholder="검색" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="검색">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="공유" aria-label="공유" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="지우기" aria-label="지우기" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            검색 초기화
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/arnold518/ai-notes" title="저장소로 이동" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    arnold518/ai-notes
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="탭" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../format/" class="md-tabs__link">
          
  
  
    
  
  Books & Courses

        </a>
      </li>
    
  

    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="네비게이션" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Artificial Intelligence Notes" class="md-nav__button md-logo" aria-label="Artificial Intelligence Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Artificial Intelligence Notes
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/arnold518/ai-notes" title="저장소로 이동" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    arnold518/ai-notes
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Books & Courses
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Books & Courses
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../format/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Mathematical Foundations of Deep Neural Networks
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            Mathematical Foundations of Deep Neural Networks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_2" >
        
          
          <label class="md-nav__link" for="__nav_2_1_2" id="__nav_2_1_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Ch 1. Optimization and Stochastic Gradient Descent
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_2">
            <span class="md-nav__icon md-icon"></span>
            Ch 1. Optimization and Stochastic Gradient Descent
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../format/1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1. Optimization Problem
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../format/2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2. Gradient Descent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/1PSpoeseUPIptYQOPuQpxNawxtZbVR_K6/view?usp=sharing" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter 1 Code
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_3" >
        
          
          <label class="md-nav__link" for="__nav_2_1_3" id="__nav_2_1_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Ch 2. Shallow Neural Networks to Multilayer Perceptrons
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_3">
            <span class="md-nav__icon md-icon"></span>
            Ch 2. Shallow Neural Networks to Multilayer Perceptrons
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../format/3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3. Shallow Neural Networks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../format/4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4. Deep Neural Networks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/15kXC3cJUV63gZNfXK6JdPPuSrwQZBzI8/view?usp=sharing" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter 2 Code
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_4" >
        
          
          <label class="md-nav__link" for="__nav_2_1_4" id="__nav_2_1_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Ch 3. Convolutional Neural Networks
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_4">
            <span class="md-nav__icon md-icon"></span>
            Ch 3. Convolutional Neural Networks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../format/5/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    5. Convolutional Neural Networks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../format/6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    6. Foundations of Design and Training of Deep Neural Networks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../format/7/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    7. ImageNet Challenge
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/12O9fLasWDA-kOKBD-lE-1UhCl-PoDf0z/view?usp=sharing" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter 3 Code
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_5" >
        
          
          <label class="md-nav__link" for="__nav_2_1_5" id="__nav_2_1_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Ch 4. CNNs for Other Supervised Learning Tasks
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_5">
            <span class="md-nav__icon md-icon"></span>
            Ch 4. CNNs for Other Supervised Learning Tasks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../format/8/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    8. CNNs for Other Supervised Learning Tasks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/16IOKVF6IiDMyUvL73pGKBaEMKyXvezLB/view?usp=sharing" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter 4 Code
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_6" >
        
          
          <label class="md-nav__link" for="__nav_2_1_6" id="__nav_2_1_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Ch 5. Unsupervised Learning
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_6">
            <span class="md-nav__icon md-icon"></span>
            Ch 5. Unsupervised Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../format/9/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    9. Autoencoder
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../format/10/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    10. Flow Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../format/11/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    11. Variational Autoencoders
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../format/12/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    12. Generative Adversarial Networks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/1JM5k-e6LkhZ0vXRlfROWpiuw4YC85Jv1/view?usp=sharing" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter 5 Code
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_7" >
        
          
          <label class="md-nav__link" for="__nav_2_1_7" id="__nav_2_1_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Ch A. Appendix - Basics of Monte Carlo
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_7">
            <span class="md-nav__icon md-icon"></span>
            Ch A. Appendix - Basics of Monte Carlo
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../format/13/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    13. Basics of Monte Carlo
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/18b01xoORd0LFQmpfc_4ou5Rv44MY1neg/view?usp=sharing" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter A Code
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_8" >
        
          
          <label class="md-nav__link" for="__nav_2_1_8" id="__nav_2_1_8_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Python Basics
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_8">
            <span class="md-nav__icon md-icon"></span>
            Python Basics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/1-iY9XfDhWNRDq3z_wVVvOzU04aRQWAfW/view?usp=drive_link" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Python Lecture 1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/1BANbCC6jBjPEUFSRJMFkcLbc4oVmoQHm/view?usp=sharing" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Python Lecture 2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://drive.google.com/file/d/1-Bc11RZmno6yx37kfVLjsyY-XKpLK5Je/view?usp=drive_link" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Python Lecture 3
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="목차">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      목차
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#optimization-problem" class="md-nav__link">
    <span class="md-ellipsis">
      Optimization problem
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#minimization-vs-maximization" class="md-nav__link">
    <span class="md-ellipsis">
      Minimization vs. maximization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#feasible-point-and-constraints" class="md-nav__link">
    <span class="md-ellipsis">
      Feasible point and constraints
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#optimal-value-and-solution" class="md-nav__link">
    <span class="md-ellipsis">
      Optimal value and solution
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#example-curve-fitting" class="md-nav__link">
    <span class="md-ellipsis">
      Example: Curve fitting
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#example-least-squares" class="md-nav__link">
    <span class="md-ellipsis">
      Example: Least-squares
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#example-least-squares_1" class="md-nav__link">
    <span class="md-ellipsis">
      Example: Least-squares
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ls-is-an-instance-of-curve-fitting" class="md-nav__link">
    <span class="md-ellipsis">
      LS is an instance of curve fitting
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#local-vs-global-minima" class="md-nav__link">
    <span class="md-ellipsis">
      Local vs. global minima
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-descent" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient descent
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#definition-of-differentiability" class="md-nav__link">
    <span class="md-ellipsis">
      Definition of "differentiability"
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#why-does-gd-converge" class="md-nav__link">
    <span class="md-ellipsis">
      Why does GD converge?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#is-gd-a-descent-method" class="md-nav__link">
    <span class="md-ellipsis">
      Is GD a "descent method"?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#what-can-we-prove" class="md-nav__link">
    <span class="md-ellipsis">
      What can we prove?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#convergence-of-gd" class="md-nav__link">
    <span class="md-ellipsis">
      Convergence of GD
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lipschitz-gradient-lemma" class="md-nav__link">
    <span class="md-ellipsis">
      Lipschitz gradient lemma
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summability-lemma" class="md-nav__link">
    <span class="md-ellipsis">
      Summability Lemma
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#convergence-of-gd-proof" class="md-nav__link">
    <span class="md-ellipsis">
      Convergence of GD: Proof
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#purpose-of-gd-convergence-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Purpose of GD convergence analysis
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#finite-sum-optimization-problems" class="md-nav__link">
    <span class="md-ellipsis">
      Finite-sum optimization problems
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#finite-sum-cong-expectation" class="md-nav__link">
    <span class="md-ellipsis">
      Finite-sum \(\cong\) Expectation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stochastic-gradient-descent-sgd" class="md-nav__link">
    <span class="md-ellipsis">
      Stochastic gradient descent (SGD)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gd-vs-sgd" class="md-nav__link">
    <span class="md-ellipsis">
      GD vs. SGD
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#digression-randomized-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      Digression: Randomized algorithms
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#why-does-sgd-converge" class="md-nav__link">
    <span class="md-ellipsis">
      Why does SGD converge?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#variants-of-sgd-for-finite-sum-problems" class="md-nav__link">
    <span class="md-ellipsis">
      Variants of SGD for finite-sum problems
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sampling-with-replacement-lemma" class="md-nav__link">
    <span class="md-ellipsis">
      Sampling with replacement lemma
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#minibatch-sgd-with-replacement" class="md-nav__link">
    <span class="md-ellipsis">
      Minibatch SGD with replacement
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#random-permutations" class="md-nav__link">
    <span class="md-ellipsis">
      Random permutations
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="chapter-1-optimization-and-stochastic-gradient-descent">Chapter 1: <br> Optimization and Stochastic Gradient Descent<a class="headerlink" href="#chapter-1-optimization-and-stochastic-gradient-descent" title="Permanent link">&para;</a></h1>
<p>Mathematical Foundations of Deep Neural Networks
Spring 2024
Department of Mathematical Sciences
Ernest K. Ryu
Seoul National University</p>
<h2 id="optimization-problem">Optimization problem<a class="headerlink" href="#optimization-problem" title="Permanent link">&para;</a></h2>
<p>In an optimization problem, we minimize or maximize a function value, possibly subject to constraints.</p>
<div class="arithmatex">\[
\begin{array}{ll}
\underset{\theta \in \mathbb{R}^{p}}{\operatorname{minimize}} &amp; f(\theta) \\
\text { subject to } &amp; h_{1}(\theta)=0
\end{array}
\]</div>
<p>Decision variable: <span class="arithmatex">\(\theta\)</span>
Objective function: <span class="arithmatex">\(f\)</span>
Equality constraint: <span class="arithmatex">\(h_{i}(\theta)=0\)</span> for <span class="arithmatex">\(i=1, \ldots, m\)</span>
Inequality constraint: <span class="arithmatex">\(g_{j}(\theta) \leq 0\)</span> for <span class="arithmatex">\(j=1, \ldots, n\)</span></p>
<h2 id="minimization-vs-maximization">Minimization vs. maximization<a class="headerlink" href="#minimization-vs-maximization" title="Permanent link">&para;</a></h2>
<p>In machine learning (ML), we often minimize a "loss", but sometimes we maximize the "likelihood".</p>
<p>In any case, minimization and maximization are equivalent since</p>
<div class="arithmatex">\[
\text { maximize } f(\theta) \quad \Leftrightarrow \quad \text { minimize }-f(\theta)
\]</div>
<h2 id="feasible-point-and-constraints">Feasible point and constraints<a class="headerlink" href="#feasible-point-and-constraints" title="Permanent link">&para;</a></h2>
<p><span class="arithmatex">\(\theta \in \mathbb{R}^{p}\)</span> is a feasible point if it satisfies all constraints:</p>
<div class="arithmatex">\[
\begin{array}{cc}
h_{1}(\theta)=0 &amp; g_{1}(\theta) \leq 0 \\
\vdots &amp; \vdots \\
h_{m}(\theta)=0 &amp; g_{n}(\theta) \leq 0
\end{array}
\]</div>
<p>Optimization problem is infeasible if there is no feasible point.</p>
<p>An optimization problem with no constraint is called an unconstrained optimization problem. Optimization problems with constraints is called a constrained optimization problem.</p>
<h2 id="optimal-value-and-solution">Optimal value and solution<a class="headerlink" href="#optimal-value-and-solution" title="Permanent link">&para;</a></h2>
<p>Optimal value of an optimization problem is</p>
<div class="arithmatex">\[
p^{\star}=\inf \left\{f(\theta) \mid \theta \in \mathbb{R}^{n}, \theta \text { feasible }\right\}
\]</div>
<ul>
<li><span class="arithmatex">\(p^{\star}=\infty\)</span> if problem is infeasible</li>
<li><span class="arithmatex">\(p^{\star}=-\infty\)</span> is possible</li>
<li>In ML, it is often a priori clear that <span class="arithmatex">\(0 \leq p^{\star}&lt;\infty\)</span>.</li>
</ul>
<p>If <span class="arithmatex">\(f\left(\theta^{\star}\right)=p^{\star}\)</span>, we say <span class="arithmatex">\(\theta^{\star}\)</span> is a solution or <span class="arithmatex">\(\theta^{\star}\)</span> is optimal.</p>
<ul>
<li>A solution may or may not exist.</li>
<li>A solution may or may not be unique.</li>
</ul>
<h2 id="example-curve-fitting">Example: Curve fitting<a class="headerlink" href="#example-curve-fitting" title="Permanent link">&para;</a></h2>
<p>Consider setup with data <span class="arithmatex">\(X_{1}, \ldots, X_{N}\)</span> and corresponding labels <span class="arithmatex">\(Y_{1}, \ldots, Y_{N}\)</span> satisfying the relationship</p>
<div class="arithmatex">\[
Y_{i}=f_{\star}\left(X_{i}\right)+\text { error }
\]</div>
<p>for <span class="arithmatex">\(i=1, \ldots, N\)</span>. Hopefully, "error" is small. True function <span class="arithmatex">\(f_{\star}\)</span> is unknown.</p>
<p>Goal is to find a function (curve) <span class="arithmatex">\(f\)</span> such that <span class="arithmatex">\(f \approx f_{\star}\)</span>.</p>
<h2 id="example-least-squares">Example: Least-squares<a class="headerlink" href="#example-least-squares" title="Permanent link">&para;</a></h2>
<p>In least-squares minimization, we solve</p>
<div class="arithmatex">\[
\operatorname{minimize}_{\theta \in \mathbb{R} P} \quad \frac{1}{2}\|X \theta-Y\|^{2}
\]</div>
<p>where <span class="arithmatex">\(X \in \mathbb{R}^{N \times p}\)</span> and <span class="arithmatex">\(Y \in \mathbb{R}^{N}\)</span>. Equivalent to</p>
<div class="arithmatex">\[
\operatorname{minimize}_{\theta \in \mathbb{R}^{p}} \frac{1}{2} \sum_{i=1}^{N}\left(X_{i}^{\top} \theta-Y_{i}\right)^{2}
\]</div>
<p>where <span class="arithmatex">\(X=\left[\begin{array}{c}X_{1}^{\top} \\ \vdots \\ X_{N}^{\top}\end{array}\right]\)</span> and <span class="arithmatex">\(Y=\left[\begin{array}{c}Y_{1} \\ \vdots \\ Y_{N}\end{array}\right]\)</span>.</p>
<h2 id="example-least-squares_1">Example: Least-squares<a class="headerlink" href="#example-least-squares_1" title="Permanent link">&para;</a></h2>
<p>To solve</p>
<div class="arithmatex">\[
\underset{\theta \in \mathbb{R}^{p}}{\operatorname{minimize}} \frac{1}{2}\|X \theta-Y\|^{2}
\]</div>
<p>take grad and set it to 0 :</p>
<div class="arithmatex">\[
\begin{gathered}
X^{\top}\left(X \theta^{\star}-Y\right)=0 \\
\theta^{\star}=\left(X^{\top} X\right)^{-1} X^{\top} Y
\end{gathered}
\]</div>
<p>Here, we assume <span class="arithmatex">\(X^{\top} X\)</span> is invertible.</p>
<p>Make sure you understand why</p>
<div class="arithmatex">\[
\nabla_{\theta} \frac{1}{2}\|X \theta-Y\|^{2}=X^{\top}(X \theta-Y)
\]</div>
<h2 id="ls-is-an-instance-of-curve-fitting">LS is an instance of curve fitting<a class="headerlink" href="#ls-is-an-instance-of-curve-fitting" title="Permanent link">&para;</a></h2>
<p>How is LS curve fitting? Define <span class="arithmatex">\(f_{\theta}(x)=x^{\top} \theta\)</span>. Then LS becomes</p>
<div class="arithmatex">\[
\underset{\theta \in \mathbb{R}^{p}}{\operatorname{minimize}} \frac{1}{2} \sum_{i=1}^{N}\left(f_{\theta}\left(X_{i}\right)-Y_{i}\right)^{2}
\]</div>
<p>and the solution hopefully satisfies</p>
<div class="arithmatex">\[
Y_{i}=f_{\theta}\left(X_{i}\right)+\text { small. }
\]</div>
<p>Since <span class="arithmatex">\(X_{i}\)</span> and <span class="arithmatex">\(Y_{i}\)</span> is assumed to satisfy</p>
<div class="arithmatex">\[
Y_{i}=f_{\star}\left(X_{i}\right)+\text { error }
\]</div>
<p>we are searching over linear functions (linear curves) <span class="arithmatex">\(f_{\theta}\)</span> that best fit (approximate) <span class="arithmatex">\(f_{\star}\)</span>.</p>
<h2 id="local-vs-global-minima">Local vs. global minima<a class="headerlink" href="#local-vs-global-minima" title="Permanent link">&para;</a></h2>
<p><span class="arithmatex">\(\theta^{\star}\)</span> is a local minimum if <span class="arithmatex">\(f(\theta) \geq f\left(\theta^{\star}\right)\)</span> for all feasible <span class="arithmatex">\(\theta\)</span> within a small neighborhood.
<span class="arithmatex">\(\theta^{\star}\)</span> is a global minimum if <span class="arithmatex">\(f(\theta) \geq f\left(\theta^{\star}\right)\)</span> for all feasible <span class="arithmatex">\(\theta\)</span>.</p>
<p>In the worst case, finding the global minimum of an optimization problem is difficult*.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-010.jpg?height=851&amp;width=1103&amp;top_left_y=506&amp;top_left_x=2170" /></p>
<p>However, in deep learning, optimization problems are often "solved" without any guarantee of global optimality.</p>
<h2 id="gradient-descent">Gradient descent<a class="headerlink" href="#gradient-descent" title="Permanent link">&para;</a></h2>
<p>Consider the unconstrained optimization problem</p>
<div class="arithmatex">\[
\underset{\theta \in \mathbb{R}^{P}}{\operatorname{minimize}} f(\theta)
\]</div>
<p>where <span class="arithmatex">\(f\)</span> is differentiable.</p>
<p>Gradient Descent (GD) algorithm:</p>
<div class="arithmatex">\[
\theta^{k+1}=\theta^{k}-\alpha_{k} \nabla f\left(\theta^{k}\right) \quad \text { for } k=0,1, \ldots,
\]</div>
<p>where <span class="arithmatex">\(\theta^{0} \in \mathbb{R}^{p}\)</span> is the initial point and <span class="arithmatex">\(\alpha_{k}&gt;0\)</span> is the learning rate or the stepsize.</p>
<p>The terminology learning rate is common the machine learning literature while stepsize is more common in the optimization literature.</p>
<h2 id="definition-of-differentiability">Definition of "differentiability"<a class="headerlink" href="#definition-of-differentiability" title="Permanent link">&para;</a></h2>
<p>In math, a function is "differentiable" if its derivative exists everywhere.</p>
<p>In deep learning (DL), a function is often said to be differentiable if its derivative exists almost everywhere and the function is nice*. ReLU activation functions are said to be differentiable.</p>
<p>We won't be too concerned with this distinction.</p>
<p>Differentiable in
DL \&amp; Math</p>
<p>Differentiable in
DL but not in Math
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-012.jpg?height=201&amp;width=465&amp;top_left_y=954&amp;top_left_x=2591" /></p>
<p>Not differentiable in DL or Math
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-012.jpg?height=74&amp;width=252&amp;top_left_y=1494&amp;top_left_x=2740" />
<span class="arithmatex">\(\longrightarrow\)</span></p>
<h2 id="why-does-gd-converge">Why does GD converge?<a class="headerlink" href="#why-does-gd-converge" title="Permanent link">&para;</a></h2>
<div class="arithmatex">\[
\theta^{k+1}=\theta^{k}-\alpha_{k} \nabla f\left(\theta^{k}\right)
\]</div>
<p>Taylor expansion of <span class="arithmatex">\(f\)</span> about <span class="arithmatex">\(\theta^{k}\)</span> :</p>
<div class="arithmatex">\[
f(\theta)=f\left(\theta^{k}\right)+\nabla f\left(\theta^{k}\right)^{\top}\left(\theta-\theta^{k}\right)+\mathcal{O}\left(\left\|\theta-\theta^{k}\right\|^{2}\right)
\]</div>
<p>Plug in <span class="arithmatex">\(\theta^{k+1}\)</span> :</p>
<div class="arithmatex">\[
f\left(\theta^{k+1}\right)=f\left(\theta^{k}\right)-\alpha_{k}\left\|\nabla f\left(\theta^{k}\right)\right\|^{2}+\mathcal{O}\left(\alpha_{k}^{2}\right)
\]</div>
<p><span class="arithmatex">\(-\nabla f\left(\theta^{k}\right)\)</span> is steepest descent direction. For small (cautious) <span class="arithmatex">\(\alpha_{k}\)</span>, GD step reduces function value.</p>
<h2 id="is-gd-a-descent-method">Is GD a "descent method"?<a class="headerlink" href="#is-gd-a-descent-method" title="Permanent link">&para;</a></h2>
<div class="arithmatex">\[
\theta^{k+1}=\theta^{k}-\alpha_{k} \nabla f\left(\theta^{k}\right)
\]</div>
<p>Without further assumptions, <span class="arithmatex">\(-\nabla f\left(\theta^{k}\right)\)</span> only gives you directional information. How far should you go? How large should <span class="arithmatex">\(\alpha_{k}\)</span> be?</p>
<p>A step of GD need not result in descent, i.e., <span class="arithmatex">\(f\left(\theta^{k+1}\right)&gt;f\left(\theta^{k}\right)\)</span> is possible.</p>
<p>We need an assumption that ensures the first-order Taylor expansion is a good approximation within a sufficiently large neighborhood.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-014.jpg?height=1327&amp;width=1004&amp;top_left_y=306&amp;top_left_x=2326" /></p>
<h2 id="what-can-we-prove">What can we prove?<a class="headerlink" href="#what-can-we-prove" title="Permanent link">&para;</a></h2>
<p>Without further assumptions, there is no hope of finding the global minimum.</p>
<p>We cannot prove the function value converges to global optimum. We instead prove <span class="arithmatex">\(\nabla f\left(\theta^{k}\right) \rightarrow 0\)</span>. Roughly speaking, this is similar, but weaker than proving that <span class="arithmatex">\(\theta^{k}\)</span> converges to a local minimum.*
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-015.jpg?height=771&amp;width=1460&amp;top_left_y=941&amp;top_left_x=1252" />
<span class="arithmatex">\({ }^{*}\)</span> Without further assumptions, we cannot show that <span class="arithmatex">\(\theta^{k}\)</span> converges to a limit, and even <span class="arithmatex">\(\theta^{k}\)</span> does converge to a limit, we cannot guarantee that that limit is not a saddle point or even a local maximum. Nevertheless, people commonly use the argument that <span class="arithmatex">\(\theta^{k}\)</span> usually converges and that it is unlikely that the</p>
<h2 id="convergence-of-gd">Convergence of GD<a class="headerlink" href="#convergence-of-gd" title="Permanent link">&para;</a></h2>
<p>Theorem) Assume <span class="arithmatex">\(f: \mathbb{R}^{p} \rightarrow \mathbb{R}\)</span> is differentiable, <span class="arithmatex">\(\nabla f\)</span> is <span class="arithmatex">\(L\)</span>-Lipschitz continuous, and <span class="arithmatex">\(\inf _{\theta \in \mathbb{R}^{p}} f(\theta)&gt;-\infty\)</span>. Then</p>
<div class="arithmatex">\[
\theta^{k+1}=\theta^{k}-\alpha \nabla f\left(\theta^{k}\right)
\]</div>
<p>with <span class="arithmatex">\(\alpha \in\left(0, \frac{2}{L}\right)\)</span> satisfies <span class="arithmatex">\(\nabla f\left(\theta^{k}\right) \rightarrow 0\)</span>.</p>
<h2 id="lipschitz-gradient-lemma">Lipschitz gradient lemma<a class="headerlink" href="#lipschitz-gradient-lemma" title="Permanent link">&para;</a></h2>
<p>We say <span class="arithmatex">\(\nabla f: \mathbb{R}^{p} \rightarrow \mathbb{R}^{p}\)</span> is <span class="arithmatex">\(L\)</span>-Lipschitz if</p>
<div class="arithmatex">\[
\|\nabla f(x)-\nabla f(y)\| \leq L\|x-y\| \quad \forall x, y \in \mathbb{R}^{p} .
\]</div>
<p>Roughly, this means <span class="arithmatex">\(\nabla f\)</span> does not change rapidly. As a consequence, we can trust the first-order Taylor expansion on a non-infinitesimal neighborhood.</p>
<p>Lemma) Let <span class="arithmatex">\(f: \mathbb{R}^{p} \rightarrow \mathbb{R}\)</span> be differentiable and <span class="arithmatex">\(\nabla f: \mathbb{R}^{p} \rightarrow \mathbb{R}^{p}\)</span> be L-Lipschitz. Then</p>
<div class="arithmatex">\[
f(\theta+\delta) \leq f(\theta)+\nabla f(\theta)^{\top} \delta+\frac{L}{2}\|\delta\|^{2} \quad \forall \theta, \delta \in \mathbb{R}^{p}
\]</div>
<p><span class="arithmatex">\(f(\theta)+\nabla f(\theta)^{\top} \delta-\frac{L}{2}\|\delta\|^{2} \leq f(\theta+\delta)\)</span> is also true, but we do not need this other direction. Together the inequalities imply</p>
<div class="arithmatex">\[
\left|f(\theta+\delta)-\left(f(\theta)+\nabla f(\theta)^{\top} \delta\right)\right| \leq \frac{L}{2}\|\delta\|^{2} \quad \forall \theta, \delta \in \mathbb{R}^{p}
\]</div>
<p>(I don't think this proof is important enough to cover in class, but I provide it here for completeness.)</p>
<p>Proof) Define <span class="arithmatex">\(g: \mathbb{R} \rightarrow \mathbb{R}\)</span> as <span class="arithmatex">\(g(t)=f(\theta+t \delta)\)</span>. Then <span class="arithmatex">\(g\)</span> is differentiable and</p>
<div class="arithmatex">\[
g^{\prime}(t)=\nabla f(\theta+t \delta)^{\top} \delta
\]</div>
<p>Note <span class="arithmatex">\(g^{\prime}\)</span> is <span class="arithmatex">\(\left(L\|\delta\|^{2}\right)\)</span>-Lipschitz continuous since</p>
<div class="arithmatex">\[
\begin{gathered}
\left|g^{\prime}\left(t_{1}\right)-g^{\prime}\left(t_{0}\right)\right|=\left|\left(\nabla f\left(\theta+t_{1} \delta\right)-\nabla f\left(\theta+t_{0} \delta\right)\right)^{\top} \delta\right| \\
\leq\left\|\nabla f\left(\theta+t_{1} \delta\right)-\nabla f\left(\theta+t_{0} \delta\right)\right\|\| \| \delta \| \\
\leq L\left\|t_{1} \delta-t_{0} \delta\right\|\|\delta\| \\
=L\|\delta\|^{2}\left|t_{1}-t_{0}\right|
\end{gathered}
\]</div>
<p>Finally, we conclude with</p>
<div class="arithmatex">\[
\begin{gathered}
f(\theta+\delta)=g(1)=g(0)+\int_{0}^{1} g^{\prime}(t) \mathrm{d} t \\
\leq f(\theta)+\int_{0}^{1}\left(g^{\prime}(0)+L\|\delta\|^{2} t\right) \mathrm{d} t \\
=f(\theta)+\nabla f(\theta)^{\top} \delta+\frac{L}{2}\|\delta\|^{2}
\end{gathered}
\]</div>
<h2 id="summability-lemma">Summability Lemma<a class="headerlink" href="#summability-lemma" title="Permanent link">&para;</a></h2>
<p>Lemma) Let <span class="arithmatex">\(V^{0}, V^{1}, \ldots \in \mathbb{R}\)</span> and <span class="arithmatex">\(S^{0}, S^{1}, \ldots \in \mathbb{R}\)</span> be nonnegative sequences satisfying</p>
<div class="arithmatex">\[
V^{k+1} \leq V^{k}-S^{k}
\]</div>
<p>for <span class="arithmatex">\(k=0,1,2, \ldots\)</span> Then <span class="arithmatex">\(S^{k} \rightarrow 0\)</span>.
Key idea. <span class="arithmatex">\(S^{k}\)</span> measures progress (decrease) made in iteration <span class="arithmatex">\(k\)</span>. Since <span class="arithmatex">\(V^{k} \geq 0, V^{k}\)</span> cannot decrease forever, so the progress (magnitude of <span class="arithmatex">\(S^{k}\)</span> ) must diminish to 0.
Proof) Sum the inequality from <span class="arithmatex">\(i=0\)</span> to <span class="arithmatex">\(k\)</span></p>
<div class="arithmatex">\[
V^{k+1}+\sum_{i=0}^{k} S^{i} \leq V^{0}
\]</div>
<p>Let <span class="arithmatex">\(k \rightarrow \infty\)</span></p>
<div class="arithmatex">\[
\sum_{i=0}^{\infty} S^{i} \leq V^{0}-\lim _{k \rightarrow \infty} V^{k} \leq V^{0}
\]</div>
<p>Since <span class="arithmatex">\(\sum_{i=0}^{\infty} S^{i}&lt;\infty, S^{i} \rightarrow 0\)</span></p>
<h2 id="convergence-of-gd-proof">Convergence of GD: Proof<a class="headerlink" href="#convergence-of-gd-proof" title="Permanent link">&para;</a></h2>
<p>Theorem) Under the assumptions, if <span class="arithmatex">\(\theta^{k+1}=\theta^{k}-\alpha \nabla f\left(\theta^{k}\right)\)</span> and <span class="arithmatex">\(\alpha \in\left(0, \frac{2}{L}\right)\)</span>, then <span class="arithmatex">\(\nabla f\left(\theta^{k}\right) \rightarrow 0\)</span>.
Proof) Use Lipschitz gradient lemma with <span class="arithmatex">\(\theta=\theta^{k}\)</span> and <span class="arithmatex">\(\delta=-\alpha \nabla f\left(\theta^{k}\right)\)</span> to get</p>
<div class="arithmatex">\[
f\left(\theta^{k+1}\right) \leq f\left(\theta^{k}\right)-\alpha\left(1-\frac{\alpha L}{2}\right)\left\|\nabla f\left(\theta^{k}\right)\right\|^{2}
\]</div>
<p>and</p>
<div class="arithmatex">\[
\begin{array}{r}
\left(f\left(\theta^{k+1}\right)-\inf _{\theta} f(\theta)\right) \leq\left(f\left(\theta^{k}\right)-\inf _{\theta} f(\theta)\right)-\alpha\left(1-\frac{\alpha L}{2}\right)\left\|\nabla f\left(\theta^{k}\right)\right\|^{2} \\
\geq 0
\end{array}
\]</div>
<p>By the summability lemma, <span class="arithmatex">\(\left\|\nabla f\left(\theta^{k}\right)\right\|^{2} \rightarrow 0\)</span> and thus <span class="arithmatex">\(\nabla f\left(\theta^{k}\right) \rightarrow 0\)</span>.</p>
<h2 id="purpose-of-gd-convergence-analysis">Purpose of GD convergence analysis<a class="headerlink" href="#purpose-of-gd-convergence-analysis" title="Permanent link">&para;</a></h2>
<p>In deep learning, the condition that <span class="arithmatex">\(\nabla f\)</span> is <span class="arithmatex">\(L\)</span>-Lipschitz is usually not true*.</p>
<p>Rather, the purpose of these mathematical analyses is to obtain qualitative insights; this convergence proof and the exercises of hw1 are meant to provide you with intuition on the training dynamics of GD and SGD.</p>
<p>Because analyzing deep learning systems as is rigorously is usually difficult, people usually</p>
<ul>
<li>analyze modified (simplified) setups rigorously or</li>
<li>analyze the full setup heuristically.</li>
</ul>
<p>In both cases, the goal is to obtain qualitative insights, rather than theoretical guarantees.</p>
<h2 id="finite-sum-optimization-problems">Finite-sum optimization problems<a class="headerlink" href="#finite-sum-optimization-problems" title="Permanent link">&para;</a></h2>
<p>A finite-sum optimization problem has the structure</p>
<div class="arithmatex">\[
\underset{\theta \in \mathbb{R}^{p}}{\operatorname{minimize}} \frac{1}{N} \sum_{i=1}^{N} f_{i}(\theta):=F(\theta)
\]</div>
<p>Finite-sum is ubiquitous in ML. <span class="arithmatex">\(N\)</span> usually corresponds to the number of data points.</p>
<p>Using GD</p>
<div class="arithmatex">\[
\theta^{k+1}=\theta^{k}-\frac{\alpha_{k}}{N} \sum_{i=1}^{N} \nabla f_{i}\left(\theta^{k}\right)
\]</div>
<p>is impractical when <span class="arithmatex">\(N\)</span> is large since <span class="arithmatex">\(\frac{1}{N} \sum_{i=1}^{N} \cdot\)</span> takes too long to compute.</p>
<h2 id="finite-sum-cong-expectation">Finite-sum <span class="arithmatex">\(\cong\)</span> Expectation<a class="headerlink" href="#finite-sum-cong-expectation" title="Permanent link">&para;</a></h2>
<p>Although the finite-sum optimization problem has no inherent randomness, we can reformulate this problem with randomness:</p>
<div class="arithmatex">\[
\operatorname{minimize}_{\theta \in \mathbb{R}^{p}} \quad \mathbb{E}_{I}\left[f_{I}(\theta)\right]
\]</div>
<p>where <span class="arithmatex">\(I \sim\)</span> Uniform <span class="arithmatex">\(\{1, \ldots, N\}\)</span>. To see the equivalence,</p>
<div class="arithmatex">\[
\mathbb{E}_{I}\left[f_{I}(\theta)\right]=\sum_{i=1}^{N} f_{i}(\theta) \mathbb{P}(I=i)=\frac{1}{N} \sum_{i=1}^{N} f_{i}(\theta)=F(\theta)
\]</div>
<h2 id="stochastic-gradient-descent-sgd">Stochastic gradient descent (SGD)<a class="headerlink" href="#stochastic-gradient-descent-sgd" title="Permanent link">&para;</a></h2>
<p>Stochastic gradient descent (SGD)</p>
<div class="arithmatex">\[
\begin{gathered}
i(k) \sim \operatorname{Uniform}\{1, \ldots, N\} \\
\theta^{k+1}=\theta^{k}-\alpha_{k} \nabla f_{i(k)}\left(\theta^{k}\right)
\end{gathered}
\]</div>
<p>for <span class="arithmatex">\(k=0,1, \ldots\)</span>, where <span class="arithmatex">\(\theta^{0} \in \mathbb{R}^{p}\)</span> is the initial point and <span class="arithmatex">\(\alpha_{k}&gt;0\)</span> is the learning rate.
<span class="arithmatex">\(\nabla f_{i(k)}\left(\theta^{k}\right)\)</span> is a stochastic gradient of <span class="arithmatex">\(F\)</span> at <span class="arithmatex">\(\theta^{k}\)</span>, i.e.,</p>
<div class="arithmatex">\[
\mathbb{E}\left[\nabla f_{i(k)}\left(\theta^{k}\right)\right]=\nabla \mathbb{E}\left[f_{i(k)}\left(\theta^{k}\right)\right]=\nabla F\left(\theta^{k}\right)
\]</div>
<h2 id="gd-vs-sgd">GD vs. SGD<a class="headerlink" href="#gd-vs-sgd" title="Permanent link">&para;</a></h2>
<p>GD uses all indices <span class="arithmatex">\(i=1, \ldots, N\)</span> every iteration</p>
<div class="arithmatex">\[
\theta^{k+1}=\theta^{k}-\frac{\alpha_{k}}{N} \sum_{i=1}^{N} \nabla f_{i}\left(\theta^{k}\right)
\]</div>
<p>SGD uses only a single random index <span class="arithmatex">\(i(k)\)</span> every iteration</p>
<div class="arithmatex">\[
\begin{gathered}
i(k) \sim \text { Uniform }\{1, \ldots, N\} \\
\theta^{k+1}=\theta^{k}-\alpha_{k} \nabla f_{i(k)}\left(\theta^{k}\right)
\end{gathered}
\]</div>
<p>When size of the data <span class="arithmatex">\(N\)</span> is large, SGD is often more effective than GD.</p>
<h2 id="digression-randomized-algorithms">Digression: Randomized algorithms<a class="headerlink" href="#digression-randomized-algorithms" title="Permanent link">&para;</a></h2>
<p>A randomized algorithm utilizes artificial randomness to solve an otherwise deterministic problem.</p>
<p>There are problems* for which a randomized algorithm is faster than the best known deterministic algorithm.</p>
<p>The most famous example of this is SGD in deep learning.</p>
<h2 id="why-does-sgd-converge">Why does SGD converge?<a class="headerlink" href="#why-does-sgd-converge" title="Permanent link">&para;</a></h2>
<p>Plug <span class="arithmatex">\(\theta^{k+1}\)</span> into Taylor expansion of <span class="arithmatex">\(F\)</span> about <span class="arithmatex">\(\theta^{k}\)</span> :</p>
<div class="arithmatex">\[
F\left(\theta^{k+1}\right)=F\left(\theta^{k}\right)-\alpha_{k} \nabla F\left(\theta^{k}\right)^{\top} \nabla f_{i(k)}\left(\theta^{k}\right)+\mathcal{O}\left(\alpha_{k}^{2}\right)
\]</div>
<p>Take expectation on both sides:</p>
<div class="arithmatex">\[
\mathbb{E}_{k}\left[F\left(\theta^{k+1}\right)\right]=F\left(\theta^{k}\right)-\alpha_{k}\left\|\nabla F\left(\theta^{k}\right)\right\|^{2}+\mathcal{O}\left(\alpha_{k}^{2}\right)
\]</div>
<p>( <span class="arithmatex">\(\mathbb{E}_{k}\)</span> is expectation conditioned on <span class="arithmatex">\(\theta^{k}\)</span> )
<span class="arithmatex">\(-\nabla f_{i(k)}\left(\theta^{k}\right)\)</span> is descent direction in expectation. For small (cautious) <span class="arithmatex">\(\alpha_{k}\)</span>, SGD step reduces function value in expectation.</p>
<h2 id="variants-of-sgd-for-finite-sum-problems">Variants of SGD for finite-sum problems<a class="headerlink" href="#variants-of-sgd-for-finite-sum-problems" title="Permanent link">&para;</a></h2>
<p>Consider</p>
<div class="arithmatex">\[
\operatorname{minimize}_{\theta \in \mathbb{R}^{p}} \frac{1}{N} \sum_{i=1}^{N} f_{i}(\theta)
\]</div>
<p>SGD can be generalized to</p>
<div class="arithmatex">\[
\theta^{k+1}=\theta^{k}-\alpha_{k} g^{k}
\]</div>
<p>where <span class="arithmatex">\(g^{k}\)</span> is a stochastic gradient. The choice <span class="arithmatex">\(g^{k}=\nabla f_{i(k)}\left(\theta^{k}\right)\)</span> is just one option.</p>
<h2 id="sampling-with-replacement-lemma">Sampling with replacement lemma<a class="headerlink" href="#sampling-with-replacement-lemma" title="Permanent link">&para;</a></h2>
<p>Lemma) Let <span class="arithmatex">\(X_{1}, \ldots, X_{N} \in \mathbb{R}^{p}\)</span> be given (non-random) vectors. Let <span class="arithmatex">\(\frac{1}{N} \sum_{i=1}^{N} X_{i}=\mu\)</span>. Let <span class="arithmatex">\(i(1), \ldots, i(B) \subseteq\{1, \ldots, N\}\)</span> be random indices. Then</p>
<div class="arithmatex">\[
\mathbb{E} \frac{1}{B} \sum_{b=1}^{B} X_{i(b)}=\mu
\]</div>
<p>Proof)</p>
<div class="arithmatex">\[
\mathbb{E} \frac{1}{B} \sum_{b=1}^{B} X_{i(b)}=\frac{1}{B} \sum_{b=1}^{B} \mathbb{E} X_{i(b)}=\frac{1}{B} \sum_{b=1}^{B} \mu=\mu
\]</div>
<h2 id="minibatch-sgd-with-replacement">Minibatch SGD with replacement<a class="headerlink" href="#minibatch-sgd-with-replacement" title="Permanent link">&para;</a></h2>
<p>Minibatch SGD with replacement</p>
<div class="arithmatex">\[
\begin{gathered}
i(k, 1), \ldots, i(k, B) \sim \text { Uniform }\{1, \ldots, N\} \\
\theta^{k+1}=\theta^{k}-\frac{\alpha_{k}}{B} \sum_{b=1}^{B} \nabla f_{i(k, b)}\left(\theta^{k}\right)
\end{gathered}
\]</div>
<p>To clarify, we sample <span class="arithmatex">\(B\)</span> out of <span class="arithmatex">\(N\)</span> indices with replacement, i.e., the same index can be sampled multiple times.</p>
<p>By previous lemma, <span class="arithmatex">\(\frac{1}{B} \sum_{b=1}^{B} \nabla f_{i(k, b)}\left(\theta^{k}\right)\)</span> is a stochastic gradient of <span class="arithmatex">\(F\)</span> at <span class="arithmatex">\(\theta^{k}\)</span></p>
<h2 id="random-permutations">Random permutations<a class="headerlink" href="#random-permutations" title="Permanent link">&para;</a></h2>
<p>A permutation <span class="arithmatex">\(\sigma\)</span> is a list of length <span class="arithmatex">\(N\)</span> containing integers <span class="arithmatex">\(1, \ldots, N\)</span> all exactly once. We write <span class="arithmatex">\(S_{n}\)</span> for the set of permutations of length <span class="arithmatex">\(N\)</span>.</p>
<p>There are <span class="arithmatex">\(N\)</span> ! possible permutations of length <span class="arithmatex">\(N\)</span>.</p>
<p>A random permutation is a permutation chosen randomly with uniform probability; each of the <span class="arithmatex">\(N!\)</span> permutations are chosen with probability <span class="arithmatex">\(\frac{1}{N}\)</span> :</p>
<h1 id="digression-0-based-indexing-and-random-permutations-in-python">Digression: 0-based indexing and random permutations in Python<a class="headerlink" href="#digression-0-based-indexing-and-random-permutations-in-python" title="Permanent link">&para;</a></h1>
<p>In Python, generate random permutations with</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>np.random.permutation(np.arange(N))
</span></code></pre></div>
<p>In Python, array indices start at 0, although in math and in human language, counting starts at 1 . We use permutations containing <span class="arithmatex">\(0,1, \ldots, N-1\)</span> in our Python code.</p>
<h2 id="sampling-without-replacement-lemma">Sampling without replacement lemma<a class="headerlink" href="#sampling-without-replacement-lemma" title="Permanent link">&para;</a></h2>
<p>Lemma) Let <span class="arithmatex">\(X_{1}, \ldots, X_{N} \in \mathbb{R}^{p}\)</span> be given (non-random) vectors. Let <span class="arithmatex">\(\frac{1}{N} \sum_{i=1}^{N} X_{i}=\mu\)</span>. Let <span class="arithmatex">\(\sigma\)</span> be a random permutation. Then</p>
<div class="arithmatex">\[
\mathbb{E} \frac{1}{B} \sum_{b=1}^{B} X_{\sigma(b)}=\mu
\]</div>
<p>Proof)</p>
<div class="arithmatex">\[
\mathbb{E} \frac{1}{B} \sum_{b=1}^{B} X_{\sigma(b)}=\frac{1}{B} \sum_{b=1}^{B} \mathbb{E} X_{\sigma(b)}=\frac{1}{B} \sum_{b=1}^{B} \mu=\mu
\]</div>
<h2 id="minibatch-sgd-without-replacement">Minibatch SGD without replacement<a class="headerlink" href="#minibatch-sgd-without-replacement" title="Permanent link">&para;</a></h2>
<p>Minibatch SGD without replacement</p>
<div class="arithmatex">\[
\begin{gathered}
\sigma^{k} \sim \operatorname{permutation}(N) \\
\theta^{k+1}=\theta^{k}-\frac{\alpha_{k}}{B} \sum_{b=1}^{B} \nabla f_{\sigma^{k}(b)}\left(\theta^{k}\right)
\end{gathered}
\]</div>
<p>We assume <span class="arithmatex">\(B \leq N\)</span>. To clarify, we sample <span class="arithmatex">\(B\)</span> out of <span class="arithmatex">\(N\)</span> indices without replacement, i.e., the same index cannot be sampled multiple times.</p>
<p>By previous lemma, <span class="arithmatex">\(\frac{1}{B} \sum_{b=1}^{B} \nabla f_{\sigma^{k}(b)}\left(\theta^{k}\right)\)</span> is a stochastic gradient of <span class="arithmatex">\(F\)</span> at <span class="arithmatex">\(\theta^{k}\)</span>.</p>
<h2 id="how-to-choose-batch-size-b">How to choose batch size <span class="arithmatex">\(B\)</span> ?<a class="headerlink" href="#how-to-choose-batch-size-b" title="Permanent link">&para;</a></h2>
<p>Note <span class="arithmatex">\(B=1\)</span> minibatch SGD becomes SGD.</p>
<p>Mathematically (measuring performance per iteration)</p>
<ul>
<li>Use large batch is when noise/randomness is large.</li>
<li>Use small batch is when noise/randomness is small.</li>
</ul>
<p>Practically (measuring performance per unit time)</p>
<ul>
<li>Large batch allows more efficient computation on GPUs.</li>
<li>Often best to increase batch size up to the GPU memory limit.</li>
</ul>
<h2 id="gd-and-sgd-without-differentiability">GD and SGD without differentiability<a class="headerlink" href="#gd-and-sgd-without-differentiability" title="Permanent link">&para;</a></h2>
<p>In DL, SGD is applied to nice continuous but non-differentiable* functions that are differentiable almost everywhere.</p>
<p>In this case, if we choose <span class="arithmatex">\(\theta^{0} \in \mathbb{R}^{n}\)</span> randomly and run</p>
<div class="arithmatex">\[
\theta^{k+1}=\theta^{k}-\alpha_{k} \nabla f\left(\theta^{k}\right)
\]</div>
<p>the algorithm is usually well-defined, i.e., <span class="arithmatex">\(\theta^{k}\)</span> never hits a point of non-differentiability.</p>
<p>With a proof or not, GD and SGD are applied to non-differentiable minimization in ML. The absence of differentiability <span class="arithmatex">\({ }^{*}\)</span> does not seem to cause serious problems.</p>
<h2 id="cyclic-sgd">Cyclic SGD<a class="headerlink" href="#cyclic-sgd" title="Permanent link">&para;</a></h2>
<p>Consider the sequence of indices</p>
<div class="arithmatex">\[
\{\bmod (k, N)+1\}_{k=0,1, \ldots}=1,2, \ldots, N, 1,2, \ldots, N, \ldots
\]</div>
<p>Here, <span class="arithmatex">\(\bmod (k, N)\)</span> is the remainder of <span class="arithmatex">\(k\)</span> when divided by <span class="arithmatex">\(N\)</span>. In Python, this is written with <span class="arithmatex">\(k \% N\)</span>.</p>
<p>Cyclic SGD:</p>
<div class="arithmatex">\[
\theta^{k+1}=\theta^{k}-\alpha_{\mathbf{k}} \nabla f_{\bmod (k, N)+1}\left(\theta^{k}\right)
\]</div>
<p>To clarify, this samples the indices in a (deterministic) cyclic order.</p>
<h2 id="cyclic-mini-batch-sgd">Cyclic (mini-batch) SGD<a class="headerlink" href="#cyclic-mini-batch-sgd" title="Permanent link">&para;</a></h2>
<p>Strictly speaking, cyclic SGD is not an instance of SGD as unbiased estimation property lost.</p>
<p>Advantage:</p>
<ul>
<li>Uses all indices (data) every <span class="arithmatex">\(N\)</span> iterations.</li>
</ul>
<p>Disadvantage:</p>
<ul>
<li>Worse than SGD in some cases, theoretically and empirically.</li>
<li>In DL, neural networks can learn to anticipate cyclic order.</li>
</ul>
<h2 id="shuffled-cyclic-sgd">Shuffled Cyclic SGD<a class="headerlink" href="#shuffled-cyclic-sgd" title="Permanent link">&para;</a></h2>
<p>Shuffled Cyclic SGD:</p>
<div class="arithmatex">\[
\theta^{k+1}=\theta^{k}-\left.\alpha_{k} \nabla f\right|_{\left.\left.\right|^{\frac{k}{N}}\right|_{(\bmod (k, N)+1)}}\left(\theta^{k}\right)
\]</div>
<p>where <span class="arithmatex">\(\sigma^{0}, \sigma^{1}, \ldots\)</span> is a sequence of random permutations, i.e., we shuffle the order every cycle. Again, strictly speaking, shuffled cyclic SGD is not an instance of SGD as unbiased estimation property lost.</p>
<p>Advantages :</p>
<ul>
<li>Uses all indices (data) every <span class="arithmatex">\(N\)</span> iterations.</li>
<li>Neural network cannot learn to anticipate data order.</li>
<li>Empirically best performance.</li>
</ul>
<p>Disadvantages:</p>
<ul>
<li>Theory not as strong as regular SGD.</li>
</ul>
<h2 id="which-variant-of-sgd-to-use">Which variant of SGD to use?<a class="headerlink" href="#which-variant-of-sgd-to-use" title="Permanent link">&para;</a></h2>
<p>Theoretical comparison of SGD variants:</p>
<ul>
<li>Not that easy.</li>
<li>Result does not strongly correlate with practical performance in DL.</li>
</ul>
<p>In DL, the most common choice is</p>
<ul>
<li>shuffled cyclic minibatch SGD (without replacement) and</li>
<li>batchsize <span class="arithmatex">\(B\)</span> is as large as possible within the GPU memory limit.</li>
</ul>
<p>One can generally consider this to be the default option.</p>
<h2 id="epoch-in-finite-sum-optimization-and-machine-learning-training">Epoch in finite-sum optimization and machine learning training<a class="headerlink" href="#epoch-in-finite-sum-optimization-and-machine-learning-training" title="Permanent link">&para;</a></h2>
<p>An epoch is loosely defined as the unit of optimization or training progress of processing all indices or data once.</p>
<ul>
<li>1 iteration of GD constitutes an epoch.</li>
<li><span class="arithmatex">\(N\)</span> iterations of SGD, cyclic SGD, or shuffled cyclic SGD constitute an epoch.</li>
<li><span class="arithmatex">\(N / B\)</span> iterations of minibatch SGD constitute an epoch.</li>
</ul>
<p>Epoch is often a convenient unit for counting iterations compared to directly counting the iteration number.</p>
<h2 id="sgd-with-general-expectation">SGD with general expectation<a class="headerlink" href="#sgd-with-general-expectation" title="Permanent link">&para;</a></h2>
<p>Consider an optimization problem with its objective defined with a general expectation</p>
<div class="arithmatex">\[
\operatorname{minimize}_{\theta \in \mathbb{R}^{p}} \quad \mathbb{E}_{\omega}\left[f_{\omega}(\theta)\right]:=F(\theta)
\]</div>
<p>Here, <span class="arithmatex">\(\omega\)</span> is a random variable. We will encounter these expectations (non-finite sum) when we talk about generative models.</p>
<p>For this setup, the SGD algorithm is</p>
<div class="arithmatex">\[
\theta^{k+1}=\theta^{k}-\alpha_{k} \nabla f_{\omega^{k}}\left(\theta^{k}\right)
\]</div>
<p>where <span class="arithmatex">\(\omega^{0}, \omega^{1}, \ldots\)</span> are IID random samples of <span class="arithmatex">\(\omega\)</span>. If <span class="arithmatex">\(\nabla_{\theta} \mathbb{E}_{\omega}\left[f_{\omega}(\theta)\right]=\mathbb{E}_{\omega}\left[\nabla_{\theta} f_{\omega}(\theta)\right]\)</span>, then <span class="arithmatex">\(\nabla f_{\omega^{k}}\left(\theta^{k}\right)\)</span> is a stochastic gradient of <span class="arithmatex">\(F(\theta)\)</span> at <span class="arithmatex">\(\theta^{k}\)</span>. (Make sure you understand why the previous SGD for the finite-sum setup is a special case of this.)</p>
<p>GD for this setup is</p>
<div class="arithmatex">\[
\theta^{k+1}=\theta^{k}-\alpha_{k} \mathbb{E}_{\omega}\left[\nabla_{\theta} f_{\omega}\left(\theta^{k}\right)\right]
\]</div>
<p>However, if the expectation is difficult to compute GD is impractical and SGD is preferred.</p>
<h1 id="chapter-2-shallow-neural-networks-to-multilayer-perceptrons">Chapter 2: <br> Shallow Neural Networks to Multilayer Perceptrons<a class="headerlink" href="#chapter-2-shallow-neural-networks-to-multilayer-perceptrons" title="Permanent link">&para;</a></h1>
<p>Mathematical Foundations of Deep Neural Networks</p>
<p>Spring 2024
Department of Mathematical Sciences
Ernest K. Ryu
Seoul National University</p>
<h2 id="supervised-learning-setup">Supervised learning setup<a class="headerlink" href="#supervised-learning-setup" title="Permanent link">&para;</a></h2>
<p>We have data <span class="arithmatex">\(X_{1}, \ldots, X_{N} \in X\)</span> and corresponding labels <span class="arithmatex">\(Y_{1}, \ldots, Y_{N} \in \mathcal{Y}\)</span>.</p>
<p>Example) <span class="arithmatex">\(X_{i}\)</span> is the <span class="arithmatex">\(i\)</span> th email and <span class="arithmatex">\(Y_{i} \in\{-1,+1\}\)</span> denotes whether <span class="arithmatex">\(X_{i}\)</span> is a spam email.
Example) <span class="arithmatex">\(X_{i}\)</span> is the <span class="arithmatex">\(i\)</span> th image and <span class="arithmatex">\(Y_{i} \in\{0, \ldots, 9\}\)</span> denotes handwritten digit.</p>
<p>Assume there is a true unknown function</p>
<div class="arithmatex">\[
f_{\star}: x \rightarrow y
\]</div>
<p>mapping data to its label. In particular, <span class="arithmatex">\(Y_{i}=f_{\star}\left(X_{i}\right)\)</span> for <span class="arithmatex">\(i=1, \ldots, N\)</span>.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-044.jpg?height=568&amp;width=862&amp;top_left_y=846&amp;top_left_x=2468" /></p>
<p>The goal of supervised learning is to use <span class="arithmatex">\(X_{1}, \ldots, X_{N}\)</span> and <span class="arithmatex">\(Y_{1}, \ldots, Y_{N}\)</span> to find <span class="arithmatex">\(f \approx f_{\star}\)</span>.</p>
<h2 id="formulating-the-right-objective">Formulating the right objective<a class="headerlink" href="#formulating-the-right-objective" title="Permanent link">&para;</a></h2>
<p>The goal of "finding <span class="arithmatex">\(f \approx f_{\star}\)</span> " must be further quantified.</p>
<p>Assume a loss function such that <span class="arithmatex">\(\ell\left(y_{1}, y_{2}\right)=0\)</span> if <span class="arithmatex">\(y_{1}=y_{2}\)</span> and <span class="arithmatex">\(\ell\left(y_{1}, y_{2}\right)&gt;0\)</span> if <span class="arithmatex">\(y_{1} \neq y_{2}\)</span>.</p>
<p>Attempt 1)</p>
<div class="arithmatex">\[
\underset{f}{\operatorname{minimize}} \sup _{x \in \mathcal{X}} \ell\left(f(x), f_{\star}(x)\right)
\]</div>
<p>Problems:</p>
<ul>
<li>There is a trivial solution <span class="arithmatex">\(f=f_{\star}\)</span>.</li>
<li>Minimization over all functions <span class="arithmatex">\(f\)</span> is in general algorithmically intractable <span class="arithmatex">\({ }^{1}\)</span>. How would one represent a <span class="arithmatex">\(f\)</span> on a computer?</li>
</ul>
<h2 id="formulating-the-right-objective_1">Formulating the right objective<a class="headerlink" href="#formulating-the-right-objective_1" title="Permanent link">&para;</a></h2>
<p>Attempt 2) Restrict search to a class of parametrized functions <span class="arithmatex">\(f_{\theta}(x)\)</span> where <span class="arithmatex">\(\theta \in \Theta \subseteq \mathbb{R}^{p}\)</span>, i.e., only consider <span class="arithmatex">\(f \in\left\{f_{\theta} \mid \theta \in \Theta\right\}\)</span> where <span class="arithmatex">\(\Theta \subseteq \mathbb{R}^{p}\)</span>. Then solve</p>
<div class="arithmatex">\[
\operatorname{minimize}_{f \in\left\{f_{\theta} \mid \theta \in \Theta\right\}} \sup _{x \in \mathcal{X}} \ell\left(f(x), f_{\star}(x)\right)
\]</div>
<p>which is equivalent to</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{minimize}} \sup _{x \in \mathcal{X}} \ell\left(f_{\theta}(x), f_{\star}(x)\right)
\]</div>
<p>Problems:</p>
<ul>
<li>The supremum <span class="arithmatex">\(\sup _{x \in \mathcal{X}}\)</span> is computationally inconvenient to deal with.</li>
<li>Objective is too pessimistic. We do not need to do well all the time, we just need to do well on average.</li>
</ul>
<h2 id="formulating-the-right-objective_2">Formulating the right objective<a class="headerlink" href="#formulating-the-right-objective_2" title="Permanent link">&para;</a></h2>
<p>Attempt 3) Take a finite sample <span class="arithmatex">\({ }^{*} X_{1}, \ldots, X_{N} \in \mathcal{X}\)</span> and corresponding labels <span class="arithmatex">\(Y_{1}, \ldots, Y_{N} \in \mathcal{Y}\)</span>. Then solve</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{minimize}} \frac{1}{N} \sum_{i=1}^{N} \ell\left(f_{\theta}\left(X_{i}\right), f_{\star}\left(X_{i}\right)\right)
\]</div>
<p>which is equivalent to</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{minimize}} \frac{1}{N} \sum_{i=1}^{N} \ell\left(f_{\theta}\left(X_{i}\right), Y_{i}\right)
\]</div>
<p>This is the standard form of the optimization problem (except regularizers) we consider in the supervised learning. We will talk about regularizers later.</p>
<h2 id="aside-minimum-vs-infimum">Aside: Minimum vs. infimum<a class="headerlink" href="#aside-minimum-vs-infimum" title="Permanent link">&para;</a></h2>
<p>We clarify terminology.</p>
<ul>
<li>"Minimize": Used to specify an optimization problem.</li>
<li>"Minimizer": A solution to a minimization problem.</li>
<li>"Minimum": Used to specify the smallest objective value and asserts a minimizer exists.</li>
<li>"Infimum": Used to specify the limiting smallest objective value, but a minimizer may not exist.</li>
</ul>
<p>Analogous definitions with "maximize", "maximizer", "maximum", and "supremum"</p>
<h2 id="training-is-optimization">Training is optimization<a class="headerlink" href="#training-is-optimization" title="Permanent link">&para;</a></h2>
<p>In machine learning, the anthropomorphized word "training" refers to solving an optimization problem such as</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{minimize}} \frac{1}{N} \sum_{i=1}^{N} \ell\left(f_{\theta}\left(X_{i}\right), Y_{i}\right)
\]</div>
<p>In most cases, SGD or variants of SGD are used.</p>
<p>We call <span class="arithmatex">\(f_{\theta}\)</span> the machine learning model or the neural network.</p>
<h2 id="least-squares-regression">Least-squares regression<a class="headerlink" href="#least-squares-regression" title="Permanent link">&para;</a></h2>
<p><span class="arithmatex">\(\ln \mathrm{LS}, X=\mathbb{R}^{p}, \mathcal{Y}=\mathbb{R}, \Theta=\mathbb{R}^{p}, f_{\theta}(x)=x^{\top} \theta\)</span>, and <span class="arithmatex">\(\ell\left(y_{1}, y_{2}\right)=\frac{1}{2}\left(y_{1}-y_{2}\right)^{2}\)</span>.
So we solve</p>
<div class="arithmatex">\[
\operatorname{minimize}_{\theta \in \mathbb{R}^{p}} \frac{1}{N} \sum_{i=1}^{N} \frac{1}{2}\left(f_{\theta}\left(X_{i}\right)-Y_{i}\right)^{2}=\frac{1}{N} \sum_{i=1}^{N} \frac{1}{2}\left(X_{i}^{\top} \theta-Y_{i}\right)^{2}=\frac{1}{2 N}\|X \theta-Y\|^{2}
\]</div>
<p>where <span class="arithmatex">\(X=\left[\begin{array}{c}X_{1}^{\top} \\ \vdots \\ X_{N}^{\top}\end{array}\right]\)</span> and <span class="arithmatex">\(Y=\left[\begin{array}{c}Y_{1} \\ \vdots \\ Y_{N}\end{array}\right]\)</span>.</p>
<p>The model <span class="arithmatex">\(f_{\theta}(x)=x^{\top} \theta\)</span> is a shallow neural network. (The terminology will makes sense when contrasted with deep neural networks.)</p>
<h2 id="binary-classification-and-linear-separability">Binary classification and linear separability<a class="headerlink" href="#binary-classification-and-linear-separability" title="Permanent link">&para;</a></h2>
<p>In binary classification, we have <span class="arithmatex">\(X=\mathbb{R}^{p}\)</span> and <span class="arithmatex">\(\mathcal{Y}=\{-1,+1\}\)</span>.</p>
<p>The data is linearly separable if there is a hyperplane defined by ( <span class="arithmatex">\(a_{\text {true }}, b_{\text {true }}\)</span> ) such that</p>
<div class="arithmatex">\[
y=\left\{\begin{array}{cl}
1 &amp; \text { if } a_{\text {true }}^{\top} x+b_{\text {true }}&gt;0 \\
-1 &amp; \text { otherwis. }
\end{array}\right.
\]</div>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-051.jpg?height=807&amp;width=2712&amp;top_left_y=1041&amp;top_left_x=274" /></p>
<h2 id="linear-classification">Linear classification<a class="headerlink" href="#linear-classification" title="Permanent link">&para;</a></h2>
<p>Consider linear (affine) models</p>
<div class="arithmatex">\[
f_{a, b}(x)= \begin{cases}+1 &amp; \text { if } a^{\top} x+b&gt;0 \\ -1 &amp; \text { otherwise }\end{cases}
\]</div>
<p>Consider the loss function</p>
<div class="arithmatex">\[
\ell\left(y_{1}, y_{2}\right)=\frac{1}{2}\left|1-y_{1} y_{2}\right|= \begin{cases}0 &amp; \text { if } y_{1}=y_{2} \\ 1 &amp; \text { if } y_{1} \neq y_{2}\end{cases}
\]</div>
<p>The optimization problem</p>
<div class="arithmatex">\[
\operatorname{minimize}_{a \in \mathbb{R}^{p}, b \in \mathbb{R}} \frac{1}{N} \sum_{i=1}^{N} \ell\left(f_{a, b}\left(X_{i}\right), Y_{i}\right)
\]</div>
<p>has a solution with optimal value 0 when the data is linearly separable.
Problem: Optimization problem is discontinuous and thus cannot be solved with SGD.</p>
<h2 id="relaxing-into-continuous-formulation">Relaxing into continuous formulation<a class="headerlink" href="#relaxing-into-continuous-formulation" title="Permanent link">&para;</a></h2>
<p>Even if the underlying function or phenomenon to approximate is discontinuous, the model needs to be continuous* in its parameters. The loss function also needs to be continuous. (The prediction need not be continuous.)</p>
<p>We consider a relaxation, is a continuous proxy of the discontinuous thing. Specifically, consider</p>
<div class="arithmatex">\[
f_{a, b}(x)=a^{\top} x+b
\]</div>
<p>Once trained, <span class="arithmatex">\(f_{a, b}(x)&gt;0\)</span> means the neural network is predicting <span class="arithmatex">\(y=+1\)</span> to be "more likely", and <span class="arithmatex">\(f_{a, b}(x)&lt;0\)</span> means the neural network is predicting <span class="arithmatex">\(y=-1\)</span> to be "more likely".</p>
<p>Therefore, we train the model to satisfy</p>
<div class="arithmatex">\[
Y_{i} f_{a, b}\left(X_{i}\right)&gt;0 \text { for } i=1, \ldots, N .
\]</div>
<h2 id="relaxing-into-continuous-formulation_1">Relaxing into continuous formulation<a class="headerlink" href="#relaxing-into-continuous-formulation_1" title="Permanent link">&para;</a></h2>
<p>Problem with strict inequality <span class="arithmatex">\(Y_{i} f_{a, b}\left(X_{i}\right)&gt;0\)</span> :</p>
<ul>
<li>Strict inequality has numerical problems with round-off error.</li>
<li>The magnitude <span class="arithmatex">\(\left|f_{a, b}(x)\right|\)</span> can be viewed as the confidence* of the prediction, but having a small positive value for <span class="arithmatex">\(Y_{i} f_{a, b}\left(X_{i}\right)\)</span> indicates small confidence of the neural network.</li>
</ul>
<p>We modify our model's desired goal to be <span class="arithmatex">\(Y_{i} f_{a, b}\left(X_{i}\right) \geq 1\)</span>.</p>
<h2 id="support-vector-machine-svm">Support vector machine (SVM)<a class="headerlink" href="#support-vector-machine-svm" title="Permanent link">&para;</a></h2>
<p>To train the neural network to satisfy</p>
<div class="arithmatex">\[
0 \geq 1-Y_{i} f_{a, b}\left(X_{i}\right) \text { for } i=1, \ldots, N .
\]</div>
<p>we minimize the excess positive component of the RHS</p>
<div class="arithmatex">\[
\operatorname{minimize}_{a \in \mathbb{R}^{p}, b \in \mathbb{R}} \frac{1}{N} \sum_{i=1}^{N} \max \left\{0,1-Y_{i} f_{a, b}\left(X_{i}\right)\right\}
\]</div>
<p>which is equivalent to</p>
<div class="arithmatex">\[
\operatorname{minimize}_{a \in \mathbb{R}^{P}, b \in \mathbb{R}} \frac{1}{N} \sum_{i=1}^{N} \max \left\{0,1-Y_{i}\left(a^{\top} X_{i}+b\right)\right\}
\]</div>
<p>If the optimal value is 0 , then the data is linearly separable.</p>
<h2 id="support-vector-machine-svm_1">Support vector machine (SVM)<a class="headerlink" href="#support-vector-machine-svm_1" title="Permanent link">&para;</a></h2>
<p>This formulation is called the support vector machine (SVM)*</p>
<div class="arithmatex">\[
\operatorname{minimize}_{a \in \mathbb{R}^{p}, b \in \mathbb{R}} \frac{1}{N} \sum_{i=1}^{N} \max \left\{0,1-Y_{i}\left(a^{\top} X_{i}+b\right)\right\}
\]</div>
<p>It is also common to add a regularizer</p>
<div class="arithmatex">\[
\operatorname{minimize}_{a \in \mathbb{R}^{p}, b \in \mathbb{R}} \frac{1}{N} \sum_{i=1}^{N} \max \left\{0,1-Y_{i}\left(a^{\top} X_{i}+b\right)\right\}+\frac{\lambda}{2}\|a\|^{2}
\]</div>
<p>We will talk about regularizers later.</p>
<h2 id="prediction-with-svm">Prediction with SVM<a class="headerlink" href="#prediction-with-svm" title="Permanent link">&para;</a></h2>
<p>Once the SVM is trained, make predictions with</p>
<div class="arithmatex">\[
\operatorname{sign}\left(f_{a, b}(x)\right)=\operatorname{sign}\left(a^{\top} x+b\right)
\]</div>
<p>when <span class="arithmatex">\(f_{a, b}(x)=0\)</span>, we assign <span class="arithmatex">\(\operatorname{sign}\left(f_{a, b}(x)\right)\)</span> arbitrarily.</p>
<p>Note that the prediction is discontinuous, but predictions are in <span class="arithmatex">\(\{-1,+1\}\)</span> so it must be discontinuous.</p>
<p>If <span class="arithmatex">\(\sum_{i=1}^{N} \max \left\{0,1-Y_{i} f_{a, b}\left(X_{i}\right)\right\}=0\)</span>, then <span class="arithmatex">\(\operatorname{sign}\left(f_{a, b}\left(X_{i}\right)\right)=Y_{i}\)</span> for <span class="arithmatex">\(i=1, \ldots, N\)</span>, i.e., the neural network predicts the known labels perfectly. (Make sure you understand this.) Of course, it is a priori not clear how accurate the prediction will be for new unseen data.</p>
<h2 id="svm-is-a-relaxation">SVM is a relaxation<a class="headerlink" href="#svm-is-a-relaxation" title="Permanent link">&para;</a></h2>
<p>Directly minimizing the prediction error on the data is</p>
<div class="arithmatex">\[
\operatorname{minimize}_{a \in \mathbb{R}^{P}, b \in \mathbb{R}} \frac{1}{N} \sum_{i=1}^{N} \frac{1}{2}\left|1-Y_{i} \operatorname{sign}\left(f_{a, b}\left(X_{i}\right)\right)\right|
\]</div>
<p>The optimization we instead solve is</p>
<div class="arithmatex">\[
\operatorname{minimize}_{a \in \mathbb{R}^{p}, b \in \mathbb{R}} \frac{1}{N} \sum_{i=1}^{N} \max \left\{0,1-Y_{i} f_{a, b}\left(X_{i}\right)\right\}
\]</div>
<p>Let the optimal values be <span class="arithmatex">\(p_{1}^{\star}\)</span> and <span class="arithmatex">\(p_{2}^{\star}\)</span>. Again, SVM is of as a relaxation of the first. The two are not equivalent. (An equivalent formulation is not referred to as a relaxation.)</p>
<ul>
<li>It is possible to show <span class="arithmatex">\({ }^{\star}\)</span> that <span class="arithmatex">\(p_{1}^{\star}=0\)</span> if and only if <span class="arithmatex">\(p_{2}^{\star}=0\)</span>.</li>
<li>If <span class="arithmatex">\(p_{1}^{\star}&gt;0\)</span> and <span class="arithmatex">\(p_{2}^{\star}&gt;0\)</span>, a solution to the first problem need not correspond to a solution to the second problem, i.e., there solutions may be completely different.</li>
</ul>
<h2 id="relaxed-supervised-learning-setup">Relaxed supervised learning setup<a class="headerlink" href="#relaxed-supervised-learning-setup" title="Permanent link">&para;</a></h2>
<p>We relax the supervised learning setup to predict probabilities, rather than make point predictions*. So, labels are generated based on data, perhaps randomly. Consider data <span class="arithmatex">\(X_{1}, \ldots, X_{N} \in \mathcal{X}\)</span> and labels <span class="arithmatex">\(Y_{1}, \ldots, Y_{N} \in \mathcal{Y}\)</span>. Assume there exists a function</p>
<div class="arithmatex">\[
f_{\star}: \mathcal{X} \rightarrow \mathcal{P}(\mathcal{Y})
\]</div>
<p>where <span class="arithmatex">\(\mathcal{P}(\mathcal{Y})\)</span> denotes the set of probability distributions on <span class="arithmatex">\(\mathcal{Y}\)</span>.
Assume the generation of <span class="arithmatex">\(Y_{i}\)</span> given <span class="arithmatex">\(X_{i}\)</span> is independent of <span class="arithmatex">\(Y_{j}\)</span> and <span class="arithmatex">\(X_{j}\)</span> for <span class="arithmatex">\(j \neq i\)</span>.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-059.jpg?height=545&amp;width=567&amp;top_left_y=650&amp;top_left_x=2693" /></p>
<p>Example) <span class="arithmatex">\(f(X)=\left[\begin{array}{l}0.8 \\ 0.2\end{array}\right]\)</span> in dog vs. cat classifier.
Example) An email saying "Buy this thing at our store!" may be spam to some people, but it may not be spam to others.</p>
<p>The relaxed SL setup is more general and further realistic.</p>
<h2 id="kl-divergence">KL-divergence<a class="headerlink" href="#kl-divergence" title="Permanent link">&para;</a></h2>
<p>Let <span class="arithmatex">\(p, q \in \mathbb{R}^{n}\)</span> represent probability masses, i.e., <span class="arithmatex">\(p_{i} \geq 0\)</span> for <span class="arithmatex">\(i=1, \ldots, n\)</span> and <span class="arithmatex">\(\sum_{i=1}^{n} p_{i}=1\)</span> and the same for <span class="arithmatex">\(q\)</span>. The Kullback-Leibler-divergence (KL-divergence) from <span class="arithmatex">\(q\)</span> to <span class="arithmatex">\(p\)</span> is</p>
<div class="arithmatex">\[
D_{\mathrm{KL}}(p \| q)=\sum_{i=1}^{n} p_{i} \log \left(\frac{p_{i}}{q_{i}}\right)=-\sum_{i=1}^{n} p_{i} \log \left(q_{i}\right)+\sum_{i=1}^{n} p_{i} \log \left(p_{i}\right)
\]</div>
<p>Properties:</p>
<div class="arithmatex">\[
\begin{array}{ll}
\quad=H(p, q) &amp; =-H(p) \\
\text { cross entropy of } q &amp; =-H \\
\text { relative to } p &amp; \text { entropy of } p
\end{array}
\]</div>
<ul>
<li>Not symmetric, i.e., <span class="arithmatex">\(D_{\mathrm{KL}}(p \| q) \neq D_{\mathrm{KL}}(q \| p)\)</span>.</li>
<li><span class="arithmatex">\(D_{\mathrm{KL}}(p \| q)&gt;0\)</span> if <span class="arithmatex">\(p \neq q\)</span> and <span class="arithmatex">\(D_{\mathrm{KL}}(p \| q)=0\)</span> if <span class="arithmatex">\(p=q\)</span>.</li>
<li><span class="arithmatex">\(D_{\mathrm{KL}}(p \| q)=\infty\)</span> is possible. (Further detail on the next slide.)</li>
</ul>
<p>Often used as a "distance" between <span class="arithmatex">\(p\)</span> and <span class="arithmatex">\(q\)</span> despite not being a metric.</p>
<h2 id="kl-divergence_1">KL-divergence<a class="headerlink" href="#kl-divergence_1" title="Permanent link">&para;</a></h2>
<div class="arithmatex">\[
D_{\mathrm{KL}}(p \| q)=\sum_{i=1}^{n} p_{i} \log \left(\frac{p_{i}}{q_{i}}\right)
\]</div>
<p>Clarification: Use the convention</p>
<ul>
<li><span class="arithmatex">\(0 \log \left(\frac{0}{0}\right)=0\left(\right.\)</span> when <span class="arithmatex">\(\left.p_{i}=q_{i}=0\right)\)</span></li>
<li><span class="arithmatex">\(0 \log \left(\frac{0}{q_{i}}\right)=0\)</span> if <span class="arithmatex">\(q_{i}&gt;0\)</span></li>
<li><span class="arithmatex">\(p_{i} \log \left(\frac{p_{i}}{0}\right)=\infty\)</span> if <span class="arithmatex">\(p_{i}&gt;0\)</span></li>
</ul>
<p>Probabilistic interpretation:</p>
<div class="arithmatex">\[
D_{\mathrm{KL}}(p \| q)=\mathbb{E}_{I}\left[\log \left(\frac{p_{I}}{q_{I}}\right)\right]
\]</div>
<p>with the random variable <span class="arithmatex">\(I\)</span> such that <span class="arithmatex">\(\mathbb{P}(I=i)=p_{i}\)</span>.</p>
<h2 id="empirical-distribution-for-binary-classification">Empirical distribution for binary classification<a class="headerlink" href="#empirical-distribution-for-binary-classification" title="Permanent link">&para;</a></h2>
<p>In basic binary classification, define the empirical distribution</p>
<div class="arithmatex">\[
\mathcal{P}(y)= \begin{cases}{\left[\begin{array}{l}
1 \\
0
\end{array}\right]} &amp; \text { if } y=-1 \\
{\left[\begin{array}{l}
0 \\
1
\end{array}\right]} &amp; \text { if } y=+1\end{cases}
\]</div>
<p>More generally, the empirical distribution describes the data we have seen. In this context, we have only seen one label per datapoint, so our empirical distributions are one-hot vectors.
(If there are multiple annotations per data point <span class="arithmatex">\(x\)</span> and they don't agree, then the empirical distribution may not be one-hot vectors. For example, given the same email, some users may flag it as spam while others consider it useful information.)</p>
<h2 id="logistic-regression">Logistic regression<a class="headerlink" href="#logistic-regression" title="Permanent link">&para;</a></h2>
<p>Logistic regression (LR), is another model for binary classification:</p>
<ol>
<li>Use the model</li>
</ol>
<div class="arithmatex">\[
f_{a, b}(x)=\left[\begin{array}{c}
\frac{1}{1+e^{a^{\top} x+b}} \\
\frac{e^{a^{\top} x+b}}{1+e^{a^{\top} x+b}}
\end{array}\right]=\left[\begin{array}{c}
\frac{1}{1+e^{a^{\top} x+b}} \\
\frac{1}{1+e^{-\left(a^{\top} x+b\right)}}
\end{array}\right]=\mathbb{P}(y=-1)
\]</div>
<ol>
<li>Minimize KL-Divergence (or cross entropy) from the model <span class="arithmatex">\(f_{a, b}\left(X_{i}\right)\)</span> output probabilities to the empirical distribution <span class="arithmatex">\(\mathcal{P}\left(Y_{i}\right)\)</span>.</li>
</ol>
<div class="arithmatex">\[
\operatorname{minimize}_{a \in \mathbb{R}^{p}, b \in \mathbb{R}} \sum_{i=1}^{N} D_{\mathrm{KL}}\left(\mathcal{P}\left(Y_{i}\right) \| f_{a, b}\left(X_{i}\right)\right)
\]</div>
<h2 id="logistic-regression_1">Logistic regression<a class="headerlink" href="#logistic-regression_1" title="Permanent link">&para;</a></h2>
<p>Note:</p>
<div class="arithmatex">\[
\begin{gathered}
\operatorname{minimize}_{a \in \mathbb{R}^{p}, b \in \mathbb{R}} \sum_{i=1}^{N} D_{\mathrm{KL}}\left(\mathcal{P}\left(Y_{i}\right) \| f_{a, b}\left(X_{i}\right)\right) \\
\mathbb{\Downarrow} \\
\operatorname{minimize}_{a \in \mathbb{R}^{p}, b \in \mathbb{R}} \sum_{i=1}^{N} H\left(\mathcal{P}\left(Y_{i}\right), f_{a, b}\left(X_{i}\right)\right)+(\text { terms independent of } a, b) \\
\operatorname{minimize}_{a \in \mathbb{R}^{p}, b \in \mathbb{R}} \sum_{i=1}^{N} \log \left(1+\exp \left(-Y_{i}\left(a^{\top} X_{i}+b\right)\right)\right) \\
\operatorname{minimize}_{a \in \mathbb{R}^{p}, b \in \mathbb{R}} \frac{1}{N} \sum_{i=1}^{N} \ell\left(Y_{i}\left(a^{\top} X_{i}+b\right)\right)
\end{gathered}
\]</div>
<p>where <span class="arithmatex">\(\ell(z)=\log \left(1+e^{-z}\right)\)</span>.</p>
<h2 id="point-prediction-with-logistic-regression">Point prediction with logistic regression<a class="headerlink" href="#point-prediction-with-logistic-regression" title="Permanent link">&para;</a></h2>
<p>When performing point prediction with <span class="arithmatex">\(\mathrm{LR}, a^{\top} x+b&gt;0\)</span> means <span class="arithmatex">\(\mathbb{P}(y=+1)&gt;0.5\)</span> and vice versa.</p>
<p>Once the LR is trained, make predictions with</p>
<div class="arithmatex">\[
\operatorname{sign}\left(a^{\top} x+b\right)
\]</div>
<p>when <span class="arithmatex">\(a^{\top} x+b=0\)</span>, we assign <span class="arithmatex">\(\operatorname{sign}\left(a^{\top} x+b\right)\)</span> arbitrarily. This is the same as SVM.</p>
<p>Again, it is a priori not clear how accurate the prediction will be for new unseen data.</p>
<h2 id="svm-vs-lr">SVM vs. LR<a class="headerlink" href="#svm-vs-lr" title="Permanent link">&para;</a></h2>
<p>Both support vector machine and logistic regression can be written as</p>
<div class="arithmatex">\[
\operatorname{minimize}_{a \in \mathbb{R}^{p}, b \in \mathbb{R}} \frac{1}{N} \sum_{i=1}^{N} \ell\left(Y_{i}\left(a^{\top} X_{i}+b\right)\right)
\]</div>
<ul>
<li>SVM uses <span class="arithmatex">\(\ell(z)=\max \{0,1-z\}\)</span>. Obtained from relaxing the discontinuous prediction loss.</li>
<li>LR uses <span class="arithmatex">\(\ell(z)=\log \left(1+e^{-z}\right)\)</span>. Obtained from relaxing the supervised learning setup from predicting the label to predicting the label probabilities.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-066.jpg?height=609&amp;width=1013&amp;top_left_y=1243&amp;top_left_x=2007" /></li>
</ul>
<h2 id="svm-vs-lr_1">SVM vs. LR<a class="headerlink" href="#svm-vs-lr_1" title="Permanent link">&para;</a></h2>
<p>SVM and LR are both "linear" classifiers:</p>
<ul>
<li>Decision boundary <span class="arithmatex">\(a^{\top} x+b=0\)</span> is linear.</li>
<li>Model completely ignores information perpendicular to <span class="arithmatex">\(a\)</span>.</li>
</ul>
<p>LR naturally generalizes to multi-class classification via softmax regression. Generalizing SVM to multi-class classification is trickier and less common.</p>
<h2 id="estimation-vs-prediction">Estimation vs. Prediction<a class="headerlink" href="#estimation-vs-prediction" title="Permanent link">&para;</a></h2>
<p>Finding <span class="arithmatex">\(f \approx f_{\star}\)</span> for unknown</p>
<div class="arithmatex">\[
f_{\star}: \mathcal{X} \rightarrow \mathcal{P}(\mathcal{Y})
\]</div>
<p>is called estimation*. When we consider a parameterized model <span class="arithmatex">\(f_{\theta}\)</span>, finding <span class="arithmatex">\(\theta\)</span> is the estimation. However, estimation is usually not the end goal.</p>
<p>The end goal is prediction. It is to use <span class="arithmatex">\(f_{\theta} \approx f_{\star}\)</span> on new data <span class="arithmatex">\(X_{1}^{\prime}, \ldots, X_{M}^{\prime} \in X\)</span> to find labels <span class="arithmatex">\(Y_{1}^{\prime}, \ldots, Y_{M}^{\prime} \in \mathcal{Y}\)</span>.</p>
<h2 id="is-prediction-possible">Is prediction possible?<a class="headerlink" href="#is-prediction-possible" title="Permanent link">&para;</a></h2>
<p>In the worst hypotheticals, prediction is impossible.</p>
<ul>
<li>Even though smoking is harmful for every other human being, how can we be <span class="arithmatex">\(100 \%\)</span> sure that this one person is not a mutant who benefits from the chemicals of a cigarette?</li>
<li>Water freezes at <span class="arithmatex">\(0^{\circ}\)</span>, but will the same be true tomorrow? How can we be <span class="arithmatex">\(100 \%\)</span> sure that the laws of physics will not suddenly change tomorrow?</li>
</ul>
<p>Of course, prediction is possible in practice.</p>
<p>Theoretically, prediction requires assumptions on the distribution of <span class="arithmatex">\(X\)</span> and the model of <span class="arithmatex">\(f_{\star}\)</span> is needed. This is in the realm of statistics of statistical learning theory.</p>
<p>For now, we will take the view that if we predict known labels of the training data, we can reasonably hope to do well on the new data. (We will discuss the issue of generalization and overfitting later.)</p>
<h2 id="training-data-vs-test-data">Training data vs. test data<a class="headerlink" href="#training-data-vs-test-data" title="Permanent link">&para;</a></h2>
<p>When testing a machine learning model, it is essential that one separates the training data with the test data.</p>
<p>In other classical disciplines using data, one performs a statistical hypothesis test to obtain a <span class="arithmatex">\(p\)</span>-value. In ML, people do not do that.</p>
<p>The only sure way to ensure that the model is doing well is to assess its performance on new data.</p>
<p>Usually, training data and test data is collected together. This ensures that they have the same statistical properties. The assumption is that this test data will be representative of the actual data one intends to use machine learning on.</p>
<h2 id="aside-maximum-likelihood-estimation-cong-minimizing-kl-divergence">Aside: Maximum likelihood estimation <span class="arithmatex">\(\cong\)</span> minimizing KL divergence<a class="headerlink" href="#aside-maximum-likelihood-estimation-cong-minimizing-kl-divergence" title="Permanent link">&para;</a></h2>
<p>Consider the setup where you have IID discrete random variables <span class="arithmatex">\(X_{1}, \ldots, X_{N}\)</span> that can take values <span class="arithmatex">\(1, \ldots, k\)</span>. We model the probability masses with <span class="arithmatex">\(\mathbb{P}_{\theta}(X=1), \ldots, \mathbb{P}_{\theta}(X=k)\)</span>. The maximum likelihood estimation (MLE) is obtained by solving</p>
<div class="arithmatex">\[
\underset{\theta}{\operatorname{maximize}} \frac{1}{N} \sum_{i=1}^{N} \log \left(\mathbb{P}_{\theta}\left(X_{i}\right)\right)
\]</div>
<p>Next, define</p>
<div class="arithmatex">\[
f_{\theta}=\left[\begin{array}{c}
\mathbb{P}_{\theta}(X=1) \\
\vdots \\
\mathbb{P}_{\theta}(X=k)
\end{array}\right], \quad \mathcal{P}\left(X_{1}, \ldots, X_{N}\right)=\frac{1}{N}\left[\begin{array}{c}
\#\left(X_{i}=1\right) \\
\vdots \\
\#\left(X_{i}=k\right)
\end{array}\right] .
\]</div>
<p>Then MLE is equivalent to minimizing the KL divergence from the model to the empirical distribution.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">MLE</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><span class="arithmatex">\(\underset{\theta}{\operatorname{minimize}}\)</span></td>
<td style="text-align: center;">$\mathbb{\</td>
</tr>
<tr>
<td style="text-align: center;"><span class="arithmatex">\(\left.\underset{\theta}{\operatorname{minimize}}\left(X_{1}, \ldots, X_{N}\right), f_{\theta}\right)\)</span></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$D_{\mathrm{KL}}\left(\mathcal{P}\left(X_{1}, \ldots, X_{N}\right) \</td>
</tr>
</tbody>
</table>
<h2 id="aside-maximum-likelihood-estimation-cong-minimizing-kl-divergence_1">Aside: Maximum likelihood estimation <span class="arithmatex">\(\cong\)</span> minimizing KL divergence<a class="headerlink" href="#aside-maximum-likelihood-estimation-cong-minimizing-kl-divergence_1" title="Permanent link">&para;</a></h2>
<p>One can also derive LR equivalently as the MLE.</p>
<p>Generally, one can view the MLE as minimizing the KL divergence between the model and the empirical distribution. (For continuous random variables like the Gaussian, this requires extra work, since we haven't defined the KL divergence for continuous random variables.)</p>
<p>In deep learning, the distance measure need not be KL divergence.</p>
<p>Dataset: MNIST</p>
<p>Images of hand-written digits with <span class="arithmatex">\(28 \times 28=784\)</span> pixels and integervalued intensity between 0 and 255 . Every digit has a label in <span class="arithmatex">\(\{0,1, \ldots, 8,9\}\)</span>.</p>
<p>70,000 images (60,000 for training 10,000 testing) of 10 almost balanced classes.</p>
<p>One of the simplest data set used in machine learning.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">0</th>
<th style="text-align: left;">0</th>
<th style="text-align: left;">0</th>
<th style="text-align: left;">0</th>
<th style="text-align: left;">0</th>
<th style="text-align: left;">0</th>
<th style="text-align: left;">0</th>
<th style="text-align: left;">0</th>
<th style="text-align: left;">0</th>
<th style="text-align: left;">0</th>
<th style="text-align: left;">0</th>
<th style="text-align: left;">0</th>
<th style="text-align: left;">0</th>
<th style="text-align: left;">0</th>
<th style="text-align: left;">0</th>
<th style="text-align: left;">0</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
</tr>
<tr>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
</tr>
<tr>
<td style="text-align: left;">3</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">3</td>
</tr>
<tr>
<td style="text-align: left;">4</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">4</td>
</tr>
<tr>
<td style="text-align: left;">5</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">5</td>
</tr>
<tr>
<td style="text-align: left;">6</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">6</td>
</tr>
<tr>
<td style="text-align: left;">7</td>
<td style="text-align: left;">7</td>
<td style="text-align: left;">7</td>
<td style="text-align: left;">7</td>
<td style="text-align: left;">7</td>
<td style="text-align: left;">7</td>
<td style="text-align: left;">7</td>
<td style="text-align: left;">7</td>
<td style="text-align: left;">7</td>
<td style="text-align: left;">7</td>
<td style="text-align: left;">7</td>
<td style="text-align: left;">7</td>
<td style="text-align: left;">7</td>
<td style="text-align: left;">7</td>
<td style="text-align: left;">7</td>
<td style="text-align: left;">7</td>
</tr>
<tr>
<td style="text-align: left;">8</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">8</td>
</tr>
<tr>
<td style="text-align: left;">9</td>
<td style="text-align: left;">9</td>
<td style="text-align: left;">9</td>
<td style="text-align: left;">9</td>
<td style="text-align: left;">9</td>
<td style="text-align: left;">9</td>
<td style="text-align: left;">9</td>
<td style="text-align: left;">9</td>
<td style="text-align: left;">9</td>
<td style="text-align: left;">9</td>
<td style="text-align: left;">9</td>
<td style="text-align: left;">9</td>
<td style="text-align: left;">9</td>
<td style="text-align: left;">9</td>
<td style="text-align: left;">9</td>
<td style="text-align: left;">9</td>
</tr>
</tbody>
</table>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-074.jpg?height=1405&amp;width=1204&amp;top_left_y=301&amp;top_left_x=1099" />
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-075.jpg?height=1874&amp;width=2484&amp;top_left_y=0&amp;top_left_x=731" /></p>
<h2 id="dataset-mnist">Dataset: MNIST<a class="headerlink" href="#dataset-mnist" title="Permanent link">&para;</a></h2>
<p>The USA government needed a standardized test to assess handwriting recognition software being sold to the government. So the NIST (National Institute of Standards and Technology) created the dataset in the 1990s. In 1990, NIST Special Database 1 distributed on CD-ROMs by mail. NIST SD 3 (1992) and SD 19 (1995) were improvements.</p>
<p>Humans were instructed to fill out handwriting sample forms.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-076.jpg?height=1520&amp;width=1230&amp;top_left_y=99&amp;top_left_x=2081" /></p>
<h2 id="dataset-mnist_1">Dataset: MNIST<a class="headerlink" href="#dataset-mnist_1" title="Permanent link">&para;</a></h2>
<p>However, humans cannot be trusted to follow instructions, so a lab technician performed "human ground truth adjudication".</p>
<p>In 1998, Man LeCun, Corinna Cortes, Christopher J. C. Barges took the NIST dataset and modified it to create the MNIST dataset.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-077.jpg?height=1721&amp;width=1719&amp;top_left_y=0&amp;top_left_x=1611" /></p>
<h2 id="role-of-datasets-in-ml-research">Role of Datasets in ML Research<a class="headerlink" href="#role-of-datasets-in-ml-research" title="Permanent link">&para;</a></h2>
<p>An often underappreciated contribution.</p>
<p>Good datasets play a crucial role in driving progress in ML research.</p>
<p>Thinking about the dataset is the essential first step of understanding the feasibility of a ML task.</p>
<p>Accounting for the cost of producing datasets and leveraging freely available data as much as possible (semi-supervised learning) is a recent trend in machine learning.</p>
<h2 id="dataset-cifar10">Dataset: CIFAR10<a class="headerlink" href="#dataset-cifar10" title="Permanent link">&para;</a></h2>
<p><span class="arithmatex">\(60,00032 \times 32\)</span> color images in 10 (perfectly) balanced classes.
airplane
automobile
bird
cat
deer
dog
frog
horse
ship
truck
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-079.jpg?height=1460&amp;width=1451&amp;top_left_y=299&amp;top_left_x=1877" /></p>
<h2 id="dataset-cifar10_1">Dataset: CIFAR10<a class="headerlink" href="#dataset-cifar10_1" title="Permanent link">&para;</a></h2>
<p>In 2008, a MIT and NYU team created the 80 million tiny images data set by searching on Google, Flickr, and Altavista for every non-abstract English noun and downscaled the images to <span class="arithmatex">\(32 \times 32\)</span>. The search term provided an unreliable label for the image. This dataset was not very easy to use since the classes were too numerous.</p>
<p>In 2009, Alex Krizhevsky published the CIFAR10, by distilling just a few classes and cleaning up the labels. Students were paid to verify the labels.</p>
<p>The dataset was named CIFAR-10 after the funding agency Canadian Institute For Advanced Research.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-080.jpg?height=1281&amp;width=1465&amp;top_left_y=295&amp;top_left_x=1869" /> There is also a CIFAR-100 with 100 classes.</p>
<h2 id="shallow-learning-with-pytorch">Shallow learning with PyTorch<a class="headerlink" href="#shallow-learning-with-pytorch" title="Permanent link">&para;</a></h2>
<p>PyTorch demo</p>
<p>We follow the following steps</p>
<ol>
<li>Load data</li>
<li>Define model</li>
<li>
<p>Miscellaneous setup</p>
</li>
<li>
<p>Instantiate model</p>
</li>
<li>Choose loss function</li>
<li>
<p>Choose optimizer</p>
</li>
<li>
<p>Train with SGD</p>
</li>
<li>
<p>Clear previously computed gradients</p>
</li>
<li>Compute forward pass</li>
<li>Compute gradient via backprop</li>
<li>
<p>SGD update</p>
</li>
<li>
<p>Evaluate trained model</p>
</li>
<li>Visualize results of trained model</li>
</ol>
<h2 id="lr-as-a-1-layer-neural-network">LR as a 1-layer neural network<a class="headerlink" href="#lr-as-a-1-layer-neural-network" title="Permanent link">&para;</a></h2>
<p>In LR, we solve</p>
<div class="arithmatex">\[
\operatorname{minimize}_{a \in \mathbb{R}^{p}, b \in \mathbb{R}} \frac{1}{N} \sum_{i=1}^{N} \ell\left(f_{\theta}\left(X_{i}\right), Y_{i}\right)
\]</div>
<p>where <span class="arithmatex">\(\ell\left(y_{1}, y_{2}\right)=\log \left(1+e^{-y_{1} y_{2}}\right)\)</span> and <span class="arithmatex">\(f_{\theta}\)</span> is linear.</p>
<p>We can view <span class="arithmatex">\(f_{\theta}(x)=0=a^{\top} x+b\)</span> as a 1-layer (shallow) neural network.</p>
<p>Output
layer
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-082.jpg?height=736&amp;width=958&amp;top_left_y=610&amp;top_left_x=2187" /></p>
<h2 id="linear-deep-networks-make-no-sense">Linear deep networks make no sense<a class="headerlink" href="#linear-deep-networks-make-no-sense" title="Permanent link">&para;</a></h2>
<p>What happens if we stack multiple linear layers?
Problem: This is pointless because composition of linear functions is linear.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-083.jpg?height=915&amp;width=2702&amp;top_left_y=746&amp;top_left_x=316" /></p>
<h2 id="deep-neural-networks-with-nonlinearities">Deep neural networks with nonlinearities<a class="headerlink" href="#deep-neural-networks-with-nonlinearities" title="Permanent link">&para;</a></h2>
<p>Solution: use a nonlinear activation function <span class="arithmatex">\(\sigma\)</span> to inject nonlinearities.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-084.jpg?height=924&amp;width=2965&amp;top_left_y=746&amp;top_left_x=304" /></p>
<h2 id="common-activation-functions">Common activation functions<a class="headerlink" href="#common-activation-functions" title="Permanent link">&para;</a></h2>
<p>Rectified Linear Unit (ReLU)
<span class="arithmatex">\(\operatorname{ReLU}(z)=\max (z, 0)\)</span></p>
<p>Sigmoid
<span class="arithmatex">\(\operatorname{Sigmoid}(z)=\frac{1}{1+e^{-z}}\)</span></p>
<p>Hyperbolic tangent
<span class="arithmatex">\(\tanh (z)=\frac{1-e^{-2 z}}{1+e^{-2 z}}\)</span></p>
<h2 id="multilayer-perceptron-mlp">Multilayer perceptron (MLP)<a class="headerlink" href="#multilayer-perceptron-mlp" title="Permanent link">&para;</a></h2>
<p>The multilayer perceptron, also called fully connected neural network, has the form</p>
<div class="arithmatex">\[
\begin{aligned}
y_{L}= &amp; W_{L} y_{L-1}+b_{L} \\
y_{L-1}= &amp; \sigma\left(W_{L-1} y_{L-2}+b_{L-1}\right) \\
&amp; \vdots \\
y_{2}= &amp; \sigma\left(W_{2} y_{1}+b_{2}\right) \\
y_{1}= &amp; \sigma\left(W_{1} x+b_{1}\right),
\end{aligned}
\]</div>
<p>where <span class="arithmatex">\(x \in \mathbb{R}^{n_{0}}, W_{\ell} \in \mathbb{R}^{n_{\ell} \times n_{\ell-1}}, b_{\ell} \in \mathbb{R}^{n_{\ell}}\)</span>, and <span class="arithmatex">\(n_{L}=1\)</span>. To clarify, <span class="arithmatex">\(\sigma\)</span> is applied element-wise.</p>
<h2 id="mlp-for-cifar10-binary-classification">MLP for CIFAR10 binary classification<a class="headerlink" href="#mlp-for-cifar10-binary-classification" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-087.jpg?height=866&amp;width=2096&amp;top_left_y=469&amp;top_left_x=296" />
activation function <span class="arithmatex">\(\sigma=\operatorname{ReLU}\)</span></p>
<p>PyTorch demo</p>
<h2 id="linear-layer-formal-definition">Linear layer: Formal definition<a class="headerlink" href="#linear-layer-formal-definition" title="Permanent link">&para;</a></h2>
<p>Input tensor: <span class="arithmatex">\(X \in \mathbb{R}^{B \times n}, B\)</span> batch size, <span class="arithmatex">\(n\)</span> number of indices.
Output tensor: <span class="arithmatex">\(Y \in \mathbb{R}^{B \times m}, B\)</span> batch size, <span class="arithmatex">\(m\)</span> number of indices.</p>
<p>With weight <span class="arithmatex">\(A \in \mathbb{R}^{m \times n}\)</span>, bias <span class="arithmatex">\(b \in \mathbb{R}^{m}, k=1, \ldots B\)</span>, and <span class="arithmatex">\(i=1, \ldots, m\)</span> :</p>
<div class="arithmatex">\[
Y_{k, i}=\sum_{j=1}^{n} A_{i, j} X_{k, j}+b_{i}
\]</div>
<p>Operation is independent across elements of the batch.</p>
<p>If bias=False, then <span class="arithmatex">\(b=0\)</span>.</p>
<h2 id="weight-initialization">Weight initialization<a class="headerlink" href="#weight-initialization" title="Permanent link">&para;</a></h2>
<p>Remember, SGD is</p>
<div class="arithmatex">\[
\theta^{k+1}=\theta^{k}-\alpha g^{k}
\]</div>
<p>where <span class="arithmatex">\(\theta^{0} \in \mathbb{R}^{p}\)</span> is an initial point.</p>
<p>In nice (convex) optimization problems, the initial point <span class="arithmatex">\(\theta^{0}\)</span> is not important; you converge to the global solution no matter how you initialize.</p>
<p>In deep learning, it is very important to initialize <span class="arithmatex">\(\theta^{0}\)</span> well. In fact, <span class="arithmatex">\(\theta^{0}=0\)</span> is a terrible idea.</p>
<p>Example) With an MLP with ReLU activations functions, if all weights and biases are initialized to be zero, then only the output layer's bias is trained and all other parameters do not move. So the training is stuck at a trivial network setting with <span class="arithmatex">\(f_{\theta}(x)=\)</span> constant.</p>
<h2 id="weight-initialization_1">Weight initialization<a class="headerlink" href="#weight-initialization_1" title="Permanent link">&para;</a></h2>
<p>PyTorch layers have default initialization schemes. (The default is not to initialize everything to 0 .) Sometimes this default initialization scheme is sufficient (eg. Chapter 2 code.ipynb) sometimes it is not sufficient (eg. Hw3 problem 1).</p>
<p>How to initialize weights is tricky. More on this later.</p>
<h2 id="gradient-computation-via-backprop">Gradient computation via backprop<a class="headerlink" href="#gradient-computation-via-backprop" title="Permanent link">&para;</a></h2>
<p>PyTorch and other deep learning libraries allows users to specify how to evaluate a function then compute derivatives (gradients) automatically.</p>
<p>No need to work out gradient computation by hand (even though I make you do it in homework assignments).
This feature is called, automatic differentiation, back propagation, or just the chain rule. This is implemented in the torch. autograd module.</p>
<p>More on this later.</p>
<h2 id="multi-class-classification-problem">Multi-class classification problem<a class="headerlink" href="#multi-class-classification-problem" title="Permanent link">&para;</a></h2>
<p>Consider supervised learning with data <span class="arithmatex">\(X_{1}, \ldots, X_{N} \in \mathbb{R}^{n}\)</span> and labels <span class="arithmatex">\(Y_{1}, \ldots, Y_{N} \in\{1, \ldots, k\}\)</span>. (A <span class="arithmatex">\(k\)</span> class classification problem.) Assume there exists a function <span class="arithmatex">\(f_{\star}: \mathbb{R}^{n} \rightarrow \Delta^{k}\)</span> mapping from data to label probabilities. Here, <span class="arithmatex">\(\Delta^{k} \subset \mathbb{R}^{k}\)</span> denotes the set of probability mass functions on <span class="arithmatex">\(\{1, \ldots, k\}\)</span>.</p>
<p>Define the empirical distribution <span class="arithmatex">\(\mathcal{P}(y) \in \mathbb{R}^{k}\)</span> as the one-hot vector:</p>
<div class="arithmatex">\[
(\mathcal{P}(y))_{i}=\left\{\begin{array}{cc}
1 &amp; \text { if } y=i \\
0 &amp; \text { otherwise }
\end{array}\right.
\]</div>
<p>for <span class="arithmatex">\(i=1, \ldots, k\)</span>.</p>
<h2 id="softmax-function">Softmax function<a class="headerlink" href="#softmax-function" title="Permanent link">&para;</a></h2>
<h2 id="examples">Examples:<a class="headerlink" href="#examples" title="Permanent link">&para;</a></h2>
<p>Softmax function <span class="arithmatex">\(\mu: \mathbb{R}^{k} \rightarrow \Delta^{k}\)</span> is defined by</p>
<div class="arithmatex">\[
\mu_{i}(z)=(\mu(z))_{i}=\frac{e^{z_{i}}}{\sum_{j=1}^{k} e^{z_{j}}}
\]</div>
<p>for <span class="arithmatex">\(i=1, \ldots, k\)</span>, where <span class="arithmatex">\(z=\left(z_{1}, \ldots, z_{k}\right) \in \mathbb{R}^{k}\)</span>. Since</p>
<div class="arithmatex">\[
\sum_{i=1}^{k} \mu_{i}(z)=1, \quad \mu&gt;0
\]</div>
<div class="arithmatex">\[
\begin{aligned}
&amp; \mu\left(\left[\begin{array}{l}
1 \\
2 \\
3
\end{array}\right]\right)=\left[\begin{array}{l}
0.09 \\
0.24 \\
0.6
\end{array}\right] \\
&amp; \mu\left(\left[\begin{array}{c}
999 \\
0 \\
-2
\end{array}\right]\right) \approx\left[\begin{array}{l}
1 \\
0 \\
0
\end{array}\right] \\
&amp; \mu\left(\left[\begin{array}{c}
-2 \\
-2 \\
-99
\end{array}\right]\right) \approx\left[\begin{array}{c}
0.5 \\
0.5 \\
0
\end{array}\right]
\end{aligned}
\]</div>
<p>Name "softmax" is a misnomer. "Softargmax" would be more accurate</p>
<ul>
<li><span class="arithmatex">\(\mu(z) \not \approx \max (z)\)</span></li>
<li><span class="arithmatex">\(\mu(z) \approx \operatorname{argmax}(z)\)</span></li>
</ul>
<h2 id="softmax-regression">Softmax regression<a class="headerlink" href="#softmax-regression" title="Permanent link">&para;</a></h2>
<p>In softmax regression (SR):</p>
<ol>
<li>Choose the model</li>
</ol>
<div class="arithmatex">\[
\mu\left(f_{A, b}(x)\right)=\frac{1}{\sum_{i=1}^{k} e^{a_{i}^{\top} x+b_{i}}}\left[\begin{array}{c}
e^{a_{1}^{\top} x+b_{1}} \\
e^{a_{2}^{\top} x+b_{2}} \\
\vdots \\
e^{a_{k}^{\top} x+b_{k}}
\end{array}\right], \quad f_{A, b}(x)=A x+b, A=\left[\begin{array}{c}
a_{1}^{\top} \\
a_{2}^{\top} \\
\vdots \\
a_{k}^{\top}
\end{array}\right] \in \mathbb{R}^{k \times n}, \quad b=\left[\begin{array}{c}
b_{1} \\
b_{2} \\
\vdots \\
b_{k}
\end{array}\right] \in \mathbb{R}^{k} .
\]</div>
<ol>
<li>Minimize KL-Divergence (or cross entropy) from the model <span class="arithmatex">\(\mu\left(f_{A, b}\left(X_{i}\right)\right)\)</span> output probabilities to the empirical distribution <span class="arithmatex">\(\mathcal{P}\left(Y_{i}\right)\)</span>.
<span class="arithmatex">\(\operatorname{minimize}_{A \in \mathbb{R}^{k \times n}, b \in \mathbb{R}^{k}} \sum_{i=1}^{N} D_{\mathrm{KL}}\left(\mathcal{P}\left(Y_{i}\right) \| \mu\left(f_{A, b}\left(X_{i}\right)\right)\right) \Leftrightarrow \operatorname{minimize}_{A \in \mathbb{R}^{k \times n}, b \in \mathbb{R}^{k}} \sum_{i=1}^{N} H\left(\mathcal{P}\left(Y_{i}\right), \mu\left(f_{A, b}\left(X_{i}\right)\right)\right)\)</span></li>
</ol>
<h2 id="softmax-regression_1">Softmax regression<a class="headerlink" href="#softmax-regression_1" title="Permanent link">&para;</a></h2>
<div class="arithmatex">\[
\begin{aligned}
&amp; \operatorname{minimize}_{A \in \mathbb{R}^{k \times n}, b \in \mathbb{R}^{k}} \sum_{i=1}^{N} H\left(\mathcal{P}\left(Y_{i}\right), \mu\left(f_{A, b}\left(X_{i}\right)\right)\right) \\
&amp; \operatorname{minimize}_{A \in \mathbb{R}^{k \times n}, b \in \mathbb{R}^{k}} \frac{1}{N} \sum_{i=1}^{N}-\log \left(\mu_{Y_{i}}\left(f_{A, b}\left(X_{i}\right)\right)\right) \\
&amp; \operatorname{minimize}_{A \in \mathbb{R}^{k \times n}, b \in \mathbb{R}^{k}} \frac{1}{N} \sum_{i=1}^{N}-\log \left(\frac{\exp \left(a_{Y_{i}}^{\top} X_{i}+b_{Y_{i}}\right)}{\sum_{j=1}^{k} \exp \left(a_{j}^{\top} X_{i}+b_{j}\right)}\right) \\
&amp; \operatorname{minimize}_{A \in \mathbb{R}^{k \times n}, b \in \mathbb{R}^{k}} \frac{1}{N} \sum_{i=1}^{N}\left(-\left(a_{Y_{i}}^{\top} X_{i}+b_{Y_{i}}\right)+\log \left(\sum_{j=1}^{k} \exp \left(a_{j}^{\top} X_{i}+b_{j}\right)\right)\right)
\end{aligned}
\]</div>
<h2 id="cross-entropy-loss">Cross entropy loss<a class="headerlink" href="#cross-entropy-loss" title="Permanent link">&para;</a></h2>
<p>So</p>
<div class="arithmatex">\[
\begin{array}{cc}
\underset{A \in \mathbb{R}^{k \times n}, b \in \mathbb{R}^{k}}{\operatorname{minimize}} &amp; \sum_{i=1}^{N} H\left(\mathcal{P}\left(Y_{i}\right), \mu\left(f_{A, b}\left(X_{i}\right)\right)\right) \\
\operatorname{minimize}_{A \in \mathbb{R}^{k \times n}, b \in \mathbb{R}^{k}} &amp; \frac{1}{N} \sum_{i=1}^{N} \ell^{\mathrm{CE}}\left(f_{A, b}\left(X_{i}\right), Y_{i}\right)
\end{array}
\]</div>
<p>where</p>
<div class="arithmatex">\[
\ell^{\mathrm{CE}}(f, y)=-\log \left(\frac{\exp \left(f_{y}\right)}{\sum_{j=1}^{k} \exp \left(f_{j}\right)}\right)
\]</div>
<p>is the cross entropy loss.</p>
<h2 id="classification-with-deep-networks">Classification with deep networks<a class="headerlink" href="#classification-with-deep-networks" title="Permanent link">&para;</a></h2>
<p><span class="arithmatex">\(\mathrm{SR}=\)</span> linear model <span class="arithmatex">\(f_{A, b}\)</span> with cross entropy loss:</p>
<div class="arithmatex">\[
\operatorname{minimize}_{A \in \mathbb{R}^{k \times n}, b \in \mathbb{R}^{k}} \frac{1}{N} \sum_{i=1}^{N} \ell^{\mathrm{CE}}\left(f_{A, b}\left(X_{i}\right), Y_{i}\right) \Leftrightarrow \operatorname{minimize}_{A \in \mathbb{R}^{k \times n}, b \in \mathbb{R}^{k}} \sum_{i=1}^{N} D_{\mathrm{KL}}\left(\mathcal{P}\left(Y_{i}\right) \| \mu\left(f_{A, b}\left(X_{i}\right)\right)\right)
\]</div>
<p>(Note <span class="arithmatex">\(e^{\mathrm{CE}}(f, y)&gt;0\)</span>. More on homework 3.)</p>
<p>The natural extension of <span class="arithmatex">\(S R\)</span> is to consider</p>
<div class="arithmatex">\[
\underset{\theta \in \mathbb{R}^{P}}{\operatorname{minimize}} \frac{1}{N} \sum_{i=1}^{N} \ell^{\mathrm{CE}}\left(f_{\theta}\left(X_{i}\right), Y_{i}\right) \Leftrightarrow \underset{\theta \in \mathbb{R}^{\boldsymbol{P}}}{\operatorname{minimize}} \quad \sum_{i=1}^{N} D_{\mathrm{KL}}\left(\mathcal{P}\left(Y_{i}\right) \| \mu\left(f_{\theta}\left(X_{i}\right)\right)\right)
\]</div>
<p>where <span class="arithmatex">\(f_{\theta}\)</span> is a deep neural network.</p>
<h2 id="history-of-gpu-computing">History of GPU Computing<a class="headerlink" href="#history-of-gpu-computing" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-098.jpg?height=624&amp;width=3216&amp;top_left_y=376&amp;top_left_x=46" /></p>
<p>Rendering graphics involves computing many small tasks in parallel. Graphics cards provide many small processors to render graphics.
In 1999, Nvidia released GeForce 256 and introduced programmability in the form of vertex and pixel shaders. Marketed as the first 'Graphical Processing Unit (GPU)'.
Researchers quickly learned how to implement linear algebra by mapping matrix data into textures and applying shaders.</p>
<h2 id="general-purpose-gpus-gpgpu">General Purpose GPUs (GPGPU)<a class="headerlink" href="#general-purpose-gpus-gpgpu" title="Permanent link">&para;</a></h2>
<p>In 2007, Nvidia released 'Compute Unified Device Architecture (CUDA)', which enabled general purpose computing on a CUDA-enabled GPUs.</p>
<p>Unlike CPUs which provide fast serial processing, GPUs provide massive parallel computing with its numerous slower processors.
The 2008 financial crisis hit Nvidia very hard as GPUs were luxury items used for games. This encouraged Nvidia to invest further in GPGPUs and create a more stable consumer base.</p>
<h2 id="cpu-computing-model">CPU computing model<a class="headerlink" href="#cpu-computing-model" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-100.jpg?height=1230&amp;width=1800&amp;top_left_y=435&amp;top_left_x=797" /></p>
<h2 id="gpu-computing-model">GPU computing model<a class="headerlink" href="#gpu-computing-model" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-101.jpg?height=1060&amp;width=3279&amp;top_left_y=448&amp;top_left_x=19" /></p>
<h2 id="gpus-for-machine-learning">GPUs for machine learning<a class="headerlink" href="#gpus-for-machine-learning" title="Permanent link">&para;</a></h2>
<p>Raina et al.'s 2009* paper demonstrated that GPUs can be used to train large neural networks. (This was not the first to use of GPUs in machine learning, but it was one of the most influential.)
Modern deep learning is driven by big data and big compute, respectively provided by the internet and GPUs.</p>
<p>Krizhevsky et al.'s 2012* landmark paper introduced AlexNet trained on GPUs and kickstarted the modern deep learning boom.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-102.jpg?height=544&amp;width=1662&amp;top_left_y=1157&amp;top_left_x=1624" /></p>
<h2 id="example-power-iteration-with-gpus">Example: Power iteration with GPUs<a class="headerlink" href="#example-power-iteration-with-gpus" title="Permanent link">&para;</a></h2>
<p>Computing <span class="arithmatex">\(x^{100}=A^{100} x^{0}\)</span> with a GPU:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>send A from host (CPU) to device (GPU)
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>send x=x0 from host (CPU) to device (GPU)
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>for _ in range(100):
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>    tell GPU to compute x=A*x
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>send x from device (GPU) to host (CPU)
</span></code></pre></div>
<p>In this example and deep learning, GPU accelerates computation since:
Amount of computation &gt; data communication.
Large information resides in the GPU, and CPU issues commands to perform computation on the data. ( <span class="arithmatex">\(A\)</span> in this example, neural network architecture in deep learning.)</p>
<p>PyTorch demo</p>
<h2 id="deep-learning-on-gpus">Deep learning on GPUs<a class="headerlink" href="#deep-learning-on-gpus" title="Permanent link">&para;</a></h2>
<p>Steps for training neural network on GPU:</p>
<ol>
<li>
<p>Create the neural network on CPU and send it to GPU. Neural network parameters stay on GPU.</p>
</li>
<li>
<p>Sometimes you load parameters from CPU to GPU.</p>
</li>
<li>
<p>Select data batch (image, label) and send it to GPU every iteration</p>
</li>
<li>
<p>Data for real-world setups is large, so keeping all data on GPU is infeasible.</p>
</li>
<li>
<p>On GPU, compute network output (forward pass)</p>
</li>
<li>On GPU, compute gradients (backward pass)</li>
<li>On GPU, perform gradient update</li>
<li>
<p>Once trained, perform prediction on GPU.</p>
</li>
<li>
<p>Send test data to GPU.</p>
</li>
<li>Compute network output.</li>
<li>Retrieve output on CPU.</li>
<li>Alternatively, neural network can be loaded on CPU and prediction can be done on CPU.</li>
</ol>
<p>PyTorch demo</p>
<h1 id="chapter-3-convolutional-neural-networks">Chapter 3: Convolutional Neural Networks<a class="headerlink" href="#chapter-3-convolutional-neural-networks" title="Permanent link">&para;</a></h1>
<p>Mathematical Foundations of Deep Neural Networks
Spring 2024
Department of Mathematical Sciences
Ernest K. Ryu
Seoul National University</p>
<h2 id="fully-connected-layers">Fully connected layers<a class="headerlink" href="#fully-connected-layers" title="Permanent link">&para;</a></h2>
<p>Advantages of fully connected layers:</p>
<ul>
<li>Simple.</li>
<li>Very general, in theory. (Sufficiently large MLPs can learn any function, in theory.)</li>
</ul>
<p>Disadvantage of fully connected layers:</p>
<ul>
<li>Too many trainable parameters.</li>
<li>Does not encode shift equivariance/invariance and therefore has poor inductive bias. (More on this later.)</li>
</ul>
<h2 id="shift-equivarianceinvariance-in-vision">Shift equivariance/invariance in vision<a class="headerlink" href="#shift-equivarianceinvariance-in-vision" title="Permanent link">&para;</a></h2>
<p>Many tasks in vision are equivariant/invariant with respect shifts/translations.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-107.jpg?height=333&amp;width=770&amp;top_left_y=684&amp;top_left_x=644" /></p>
<p>Cat
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-107.jpg?height=337&amp;width=779&amp;top_left_y=682&amp;top_left_x=1592" /></p>
<p>Still a Cat</p>
<p>Roughly speaking, equivariance/invariance means shifting the object does not change the meaning (it only changes the position).</p>
<h2 id="shift-equivarianceinvariance-in-vision_1">Shift equivariance/invariance in vision<a class="headerlink" href="#shift-equivarianceinvariance-in-vision_1" title="Permanent link">&para;</a></h2>
<p>Logistic regression (with a single fully connected layer) does not encode shift invariance.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-108.jpg?height=696&amp;width=3056&amp;top_left_y=634&amp;top_left_x=173" /></p>
<p>Since convolution is equivariant with respect to translations, constructing neural network layers with them is a natural choice.</p>
<h2 id="convolution">Convolution<a class="headerlink" href="#convolution" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-109.jpg?height=1409&amp;width=3207&amp;top_left_y=418&amp;top_left_x=68" /></p>
<h2 id="multiple-filters">Multiple filters<a class="headerlink" href="#multiple-filters" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-110.jpg?height=1498&amp;width=3156&amp;top_left_y=374&amp;top_left_x=38" /></p>
<h2 id="2d-convolutional-layer-formal-definition">2D convolutional layer: Formal definition<a class="headerlink" href="#2d-convolutional-layer-formal-definition" title="Permanent link">&para;</a></h2>
<p>Input tensor: <span class="arithmatex">\(X \in \mathbb{R}^{B \times C_{\text {in }} \times m \times n}, B\)</span> batch size, <span class="arithmatex">\(C_{\text {in }} \#\)</span> of input channels, <span class="arithmatex">\(m, n \#\)</span> of vertical and horizontal indices.
Output tensor: <span class="arithmatex">\(Y \in \mathbb{R}^{B \times C_{\text {out }} \times\left(m-f_{1}+1\right) \times\left(n-f_{2}+1\right)}, B\)</span> batch size, <span class="arithmatex">\(C_{\text {out }} \#\)</span> of output channels.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-111.jpg?height=108&amp;width=2799&amp;top_left_y=907&amp;top_left_x=238" /> and <span class="arithmatex">\(j=1, \ldots, n-f_{2}+1\)</span> :</p>
<div class="arithmatex">\[
Y_{k, \ell, i, j}=\sum_{\gamma=1}^{c_{\text {in }}} \sum_{\alpha=1}^{f_{1}} \sum_{\beta=1}^{f_{2}} w_{\ell, \gamma, \alpha, \beta} X_{k, \gamma, i+\alpha-1, j+\beta-1}+b_{\ell}
\]</div>
<p>Operation is independent across elements of the batch. The vertical and horizontal indices are referred to as spatial dimensions. If bias=False, then <span class="arithmatex">\(b=0\)</span>.</p>
<h2 id="notes-on-convolution">Notes on convolution<a class="headerlink" href="#notes-on-convolution" title="Permanent link">&para;</a></h2>
<p>Mind the indexing. In math, indices start at 1. In Python, indices start at 0.</p>
<p>1D conv is commonly used with 1D data, such as audio.</p>
<p>3D conv is commonly used with 3D data, such as video.</p>
<p>1D and 3D conv are defined analogously.</p>
<h2 id="zero-padding">Zero padding<a class="headerlink" href="#zero-padding" title="Permanent link">&para;</a></h2>
<p><span class="arithmatex">\((C \times 7 \times 7\)</span> image <span class="arithmatex">\() \circledast(C \times 5 \times 5\)</span> filter <span class="arithmatex">\()=(1 \times 3 \times 3\)</span> feature map <span class="arithmatex">\()\)</span>.
Spatial dimension 7 reduced to 3 .
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-113.jpg?height=869&amp;width=2359&amp;top_left_y=824&amp;top_left_x=412" /></p>
<h2 id="zero-padding_1">Zero padding<a class="headerlink" href="#zero-padding_1" title="Permanent link">&para;</a></h2>
<p><span class="arithmatex">\((C \times 7 \times 7\)</span> image with zero padding <span class="arithmatex">\(=2) \circledast(C \times 5 \times 5\)</span> filter <span class="arithmatex">\()=(1 \times 7 \times 7\)</span> feature map <span class="arithmatex">\()\)</span>.
Spatial dimension is preserved.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-114.jpg?height=1085&amp;width=3156&amp;top_left_y=640&amp;top_left_x=51" /></p>
<h2 id="stride">Stride<a class="headerlink" href="#stride" title="Permanent link">&para;</a></h2>
<p><span class="arithmatex">\((7 x 7\)</span> image <span class="arithmatex">\() \circledast(3 x 3\)</span> filter with stride 2<span class="arithmatex">\()=(\)</span> output <span class="arithmatex">\(3 x 3)\)</span>.
(With stride 1 , output is <span class="arithmatex">\(5 \times 5\)</span>.)
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-115.jpg?height=1018&amp;width=2239&amp;top_left_y=603&amp;top_left_x=0" /></p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>If stride 3, dimensions don't fit.
<span class="arithmatex">\(7 \times 7\)</span> image with zero padding of 1 becomes <span class="arithmatex">\(9 \times 9\)</span> image.
<span class="arithmatex">\((7 \times 7\)</span> image, padding of 1<span class="arithmatex">\() \circledast(3 x 3\)</span> filter <span class="arithmatex">\()\)</span> with stride 3 does fit.</p>
<h2 id="convolution-summary">Convolution summary<a class="headerlink" href="#convolution-summary" title="Permanent link">&para;</a></h2>
<p>Input <span class="arithmatex">\(C_{\text {in }} \times W_{\text {in }} \times H_{\text {in }}\)</span>
Conv layer parameters</p>
<ul>
<li><span class="arithmatex">\(C_{\text {out }}\)</span> filters</li>
<li><span class="arithmatex">\(F\)</span> spatial extent ( <span class="arithmatex">\(C_{\mathrm{in}} \times F \times F\)</span> filters)</li>
<li><span class="arithmatex">\(S\)</span> stride</li>
<li><span class="arithmatex">\(\quad P\)</span> padding</li>
</ul>
<p>Output <span class="arithmatex">\(C_{\text {out }} \times W_{\text {out }} \times H_{\text {out }}\)</span></p>
<div class="arithmatex">\[
\begin{aligned}
&amp; W_{\mathrm{out}}=\left\lfloor\frac{W_{\mathrm{in}}-F+2 P}{S}+1\right\rfloor \\
&amp; H_{\mathrm{out}}=\left\lfloor\frac{H_{\mathrm{in}}-F+2 P}{S}+1\right\rfloor
\end{aligned}
\]</div>
<p><span class="arithmatex">\(\lfloor\cdot\rfloor\)</span> denotes the floor (rounding down) operation. To avoid the complication of this floor operation, it is best to ensure the formula inside evaluates to an integer.</p>
<p>Number of trainable parameters:
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-116.jpg?height=354&amp;width=588&amp;top_left_y=1014&amp;top_left_x=2164" /></p>
<p>Make sure you are able to derive these formulae yourself.</p>
<h2 id="aside-geometric-deep-learning">Aside: Geometric deep learning<a class="headerlink" href="#aside-geometric-deep-learning" title="Permanent link">&para;</a></h2>
<p>More generally, given a group <span class="arithmatex">\(\mathcal{G}\)</span> encoding a symmetry or invariance, one can define operations "equivariant" with respect <span class="arithmatex">\(\mathcal{G}\)</span> and construct equivariant neural networks.</p>
<p>This is the subject of geometric deep learning, and its formulation utilizes graph theory and group theory.</p>
<p>Geometric deep learning is particularly useful for non-Euclidean data. Examples include as protein molecule data and social network service connections.</p>
<h2 id="pooling">Pooling<a class="headerlink" href="#pooling" title="Permanent link">&para;</a></h2>
<p>Primarily used to reduce spatial dimension. Similar to conv.
Operates over each channel independently.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-118.jpg?height=878&amp;width=1539&amp;top_left_y=811&amp;top_left_x=902" /></p>
<h2 id="pooling_1">Pooling<a class="headerlink" href="#pooling_1" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-119.jpg?height=1370&amp;width=3292&amp;top_left_y=489&amp;top_left_x=38" /></p>
<h2 id="lenet5">LeNet5<a class="headerlink" href="#lenet5" title="Permanent link">&para;</a></h2>
<h2 id="modern-instances-of-lenet5-use">Modern instances of LeNet5 use<a class="headerlink" href="#modern-instances-of-lenet5-use" title="Permanent link">&para;</a></h2>
<ul>
<li><span class="arithmatex">\(\sigma=\)</span> ReLu</li>
<li>MaxPool instead of AvgPool</li>
<li>No <span class="arithmatex">\(\sigma\)</span> after S2, S4 (Why?)</li>
<li>Full connection instead of Gaussian connections
<span class="arithmatex">\(1 \times 28 \times 28\)</span> MNIST image</li>
<li>Complete C3 connections
with <span class="arithmatex">\(p=2 \Rightarrow 1 \times 32 \times 32\)</span>
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-120.jpg?height=886&amp;width=2970&amp;top_left_y=650&amp;top_left_x=284" /></li>
</ul>
<div class="arithmatex">\[
\begin{aligned}
&amp; \text { Something like } \\
&amp; \text { average pool } \\
&amp; f=2, s=2
\end{aligned}
\]</div>
<h2 id="lenet5_1">LeNet5<a class="headerlink" href="#lenet5_1" title="Permanent link">&para;</a></h2>
<p>PyTorch demo</p>
<h2 id="architectural-contribution-lenet">Architectural contribution: LeNet<a class="headerlink" href="#architectural-contribution-lenet" title="Permanent link">&para;</a></h2>
<p>One of the earliest demonstration of using a deep CNN to learn a nontrivial task.</p>
<p>Laid the foundation of the modern CNN architecture.</p>
<h2 id="weight-sharing">Weight sharing<a class="headerlink" href="#weight-sharing" title="Permanent link">&para;</a></h2>
<p>In neural networks, weight sharing is a way to reduce the number of parameters by reusing the same parameter in multiple operations. Convolutional layers are the primary example.</p>
<div class="arithmatex">\[
A_{w}=\left[\begin{array}{cccccccc}
w_{1} &amp; \cdots &amp; w_{r} &amp; 0 &amp; \cdots &amp; &amp; &amp; 0 \\
0 &amp; w_{1} &amp; \cdots &amp; w_{r} &amp; 0 &amp; \cdots &amp; &amp; 0 \\
0 &amp; 0 &amp; w_{1} &amp; \cdots &amp; w_{r} &amp; 0 &amp; \cdots &amp; 0 \\
\vdots &amp; &amp; &amp; \ddots &amp; &amp; \ddots &amp; &amp; \vdots \\
0 &amp; &amp; \cdots &amp; 0 &amp; w_{1} &amp; \cdots &amp; w_{r} &amp; 0 \\
0 &amp; &amp; \cdots &amp; 0 &amp; 0 &amp; w_{1} &amp; \cdots &amp; w_{r}
\end{array}\right]
\]</div>
<p>If we consider convolution with filter <span class="arithmatex">\(w\)</span> as a linear operator, the components of <span class="arithmatex">\(w\)</span> appear may times in the matrix representation. This is because the same <span class="arithmatex">\(w\)</span> is reused for every patch in the convolution. Weight sharing in convolution may now seem obvious, but it was a key contribution back when the LeNet architecture was presented.
Some models (not studied in this course) use weight sharing more explicitly in other ways.</p>
<h2 id="data-augmentation">Data augmentation<a class="headerlink" href="#data-augmentation" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-124.jpg?height=567&amp;width=1589&amp;top_left_y=412&amp;top_left_x=253" /></p>
<p>Invariances</p>
<ul>
<li>Translation</li>
<li>Horizontal flip</li>
<li>Vertical flip</li>
<li>Color change (?)
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-124.jpg?height=450&amp;width=1551&amp;top_left_y=1041&amp;top_left_x=265" /></li>
</ul>
<p>Invariances</p>
<ul>
<li>Translation</li>
<li>Horizontal flip</li>
<li>Vertical flip</li>
<li>Color change</li>
</ul>
<p>Translation invariance encoded in convolution, but other invariances are harder to encode (unless one uses geometric deep learning). Therefore encode invariances in data and have neural networks learn the invariance.</p>
<h2 id="data-augmentation_1">Data augmentation<a class="headerlink" href="#data-augmentation_1" title="Permanent link">&para;</a></h2>
<p>Data augmentation (DA) applies transforms to the data while preserving meaning and label.</p>
<p>Option 1: Enlarge dataset itself.</p>
<ul>
<li>Usually cumbersome and unnecessary.</li>
</ul>
<p>Option 2: Use randomly transformed data in training loop.</p>
<ul>
<li>In PyTorch, we use Torchvision.transforms.</li>
</ul>
<p>PyTorch demo</p>
<h2 id="spurious-correlation">Spurious correlation<a class="headerlink" href="#spurious-correlation" title="Permanent link">&para;</a></h2>
<p>Hypothetical: A photographer prefers to take pictures with cats looking to the left and dogs looking to the right. Neural network learns to distinguish cats from dogs by which direction it is facing. This learned correlation will not be useful for pictures taken by another photographer.</p>
<p>This is a spurious correlation, a correlation between the data and labels that does not capture the "true" meaning. Spurious correlations are not robust in the sense that the spurious correlation will not be a useful predictor when the data changes slightly.</p>
<p>Removing spurious correlations is another purpose of DA.</p>
<h2 id="data-augmentation_2">Data augmentation<a class="headerlink" href="#data-augmentation_2" title="Permanent link">&para;</a></h2>
<h2 id="we-use-da-to">We use DA to:<a class="headerlink" href="#we-use-da-to" title="Permanent link">&para;</a></h2>
<ul>
<li>Inject our prior knowledge of the structure of the data and force the neural network to learn it.</li>
<li>Remove spurious correlations.</li>
<li>Increase the effective data size. In particular, we ensure neural network never encounters the exact same data again and thereby prevent the neural network from performing exact memorization. (Neural network can memorize quite well.)</li>
</ul>
<h2 id="effects-of-da">Effects of DA:<a class="headerlink" href="#effects-of-da" title="Permanent link">&para;</a></h2>
<ul>
<li>DA usually worsens the training error (but we don't care about training error).</li>
<li>DA often, but not always, improves the test error.</li>
<li>If DA removes a spurious correlation, then the test error can be worsened.</li>
<li>DA usually improves robustness.</li>
</ul>
<h2 id="data-augmentation-on-test-data">Data augmentation on test data?<a class="headerlink" href="#data-augmentation-on-test-data" title="Permanent link">&para;</a></h2>
<p>DA is usually applied only on training data.</p>
<p>DA is usually not applied on test data, because we want to ensure test scores are comparable. (There are many different DAs, and applying different DAs on test data will make the metric different.)</p>
<p>However, one can perform "test-time data augmentation" to improve predictions without changing the test. More on this later.</p>
<h2 id="imagenet-dataset">ImageNet dataset<a class="headerlink" href="#imagenet-dataset" title="Permanent link">&para;</a></h2>
<p>ImageNet contains more 14 million hand-annotated images in more than 20,000 categories.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-129.jpg?height=707&amp;width=1421&amp;top_left_y=659&amp;top_left_x=863" /></p>
<p>Many classes, higher resolution, non-uniform image size, multiple objects per image.</p>
<h2 id="history">History<a class="headerlink" href="#history" title="Permanent link">&para;</a></h2>
<ul>
<li>Fei-Fei Li started the ImageNet project in 2006 with the goal of expanding and improving the data available for training Al algorithms.</li>
<li>Images were annotated with Amazon Mechanical Turk.</li>
<li>The ImageNet team first presented their dataset in the 2009 Conference on Computer Vision and Pattern Recognition (CVPR).</li>
<li>From 2010 to 2017, the ImageNet project ran the ImageNet Large Scale Visual Recognition Challenge (ILSVRC).</li>
<li>In the 2012 ILSVRC challenge, 150,000 images of 1000 classes were used.</li>
<li>In 2017, 29 teams achieved above 95\% accuracy. The organizers deemed task complete and ended the ILSVRC competition.</li>
</ul>
<h2 id="imagenet-1k">ImageNet-1k<a class="headerlink" href="#imagenet-1k" title="Permanent link">&para;</a></h2>
<p>Commonly referred to as "the ImageNet dataset". Also called ImageNet2012</p>
<p>However, ImageNet-1k is really a subset of full ImageNet dataset.</p>
<p>ImageNet-1k has 150,000 images of 1000 roughly balanced classes.</p>
<h2 id="list-of-categories">List of categories:<a class="headerlink" href="#list-of-categories" title="Permanent link">&para;</a></h2>
<p>https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-131.jpg?height=1404&amp;width=2067&amp;top_left_y=229&amp;top_left_x=1263" /></p>
<h2 id="imagenet-1k_1">ImageNet-1k<a class="headerlink" href="#imagenet-1k_1" title="Permanent link">&para;</a></h2>
<p>Data has been removed from the ImageNet website. Downloading peer-to-peer via torrent is now the most convenient way to access the data.</p>
<p>Privacy concerns: Although dataset is about recognizing objects, rather than humans, many human faces are in the images. Troublingly, identifying personal information is possible.</p>
<p>NSFW concerns: Sexual and non-consensual content.</p>
<p>Creating datasets while protecting privacy and other social values is an important challenge going forward.</p>
<h2 id="top-1-vs-top-5-accuracy">Top-1 vs. top-5 accuracy<a class="headerlink" href="#top-1-vs-top-5-accuracy" title="Permanent link">&para;</a></h2>
<p>Classifiers on ImageNet-1k are often assessed by their top-5 accuracy, which requires the 5 categories with the highest confidence to contain the label.</p>
<p>In contrast, the top-1 accuracy simply measures whether the network's single prediction is the label.</p>
<p>For example, AlexNet had a top-5 accuracy of <span class="arithmatex">\(84.6 \%\)</span> and a top- 1 accuracy of <span class="arithmatex">\(63.3 \%\)</span>.</p>
<p>Nowadays, accuracies of classifiers has improved, so the top 1 accuracy is becoming the more common metric.</p>
<h2 id="classical-statistics-over-vs-underfitting">Classical statistics: Over vs. underfitting<a class="headerlink" href="#classical-statistics-over-vs-underfitting" title="Permanent link">&para;</a></h2>
<p>Given separate train and test data</p>
<ul>
<li>When (training loss) &lt;&lt; (testing loss) you are overfitting. What you have learned from the training data does not carry over to test data.</li>
<li>When (training loss) <span class="arithmatex">\(\approx\)</span> (testing loss) you are underfitting. You have the potential to learn more from the training data.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-134.jpg?height=1205&amp;width=1829&amp;top_left_y=401&amp;top_left_x=1501" /></li>
</ul>
<h2 id="classical-statistics-over-vs-underfitting_1">Classical statistics: Over vs. underfitting<a class="headerlink" href="#classical-statistics-over-vs-underfitting_1" title="Permanent link">&para;</a></h2>
<p>The goal of ML is to learn patterns that generalize to data you have not seen. From each datapoint, you want to learn enough (don't underfit) but if you learn too much you overcompensate for an observation specific to the single experience.</p>
<p>In classical statistics, underfitting vs. overfitting (bias vs. variance tradeoff) is characterized rigorously.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-135.jpg?height=911&amp;width=1511&amp;top_left_y=799&amp;top_left_x=767" /></p>
<h2 id="modern-deep-learning-double-descent">Modern deep learning: Double descent<a class="headerlink" href="#modern-deep-learning-double-descent" title="Permanent link">&para;</a></h2>
<p>In modern deep learning, you can overfit, but the state-of-the art neural networks do not overfit (or "benignly overfit") despite having more model parameters than training data.</p>
<p>We do not yet have clarity with this new phenomenon.</p>
<p>When overfitting happens and when it does not is unclear.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-136.jpg?height=886&amp;width=2459&amp;top_left_y=807&amp;top_left_x=786" /></p>
<h2 id="double-descent-on-2-layer-neural-network-on-mnist-belkin-et-al-experimentally-demonstrates-the-double-descent-phenomenon-with-an-mlp-trained-on-the-mnist-dataset">Double descent on 2-layer neural network on MNIST <br> Belkin et al. experimentally demonstrates the double descent phenomenon with an MLP trained on the MNIST dataset. <br> <img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-137.jpg?height=524&amp;width=1123&amp;top_left_y=299&amp;top_left_x=1718" /> <br> <img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-137.jpg?height=604&amp;width=1120&amp;top_left_y=842&amp;top_left_x=1728" /><a class="headerlink" href="#double-descent-on-2-layer-neural-network-on-mnist-belkin-et-al-experimentally-demonstrates-the-double-descent-phenomenon-with-an-mlp-trained-on-the-mnist-dataset" title="Permanent link">&para;</a></h2>
<p>Fig. 3. Double-descent risk curve for a fully connected neural network on MNIST. Shown are training and test risks of a network with a single layer of <span class="arithmatex">\(H\)</span> hidden units, learned on a subset of MNIST ( <span class="arithmatex">\(n=4 \cdot 10^{3}, d=784\)</span>, <span class="arithmatex">\(K=10\)</span> classes). The number of parameters is <span class="arithmatex">\((d+1) \cdot H+(H+1) \cdot K\)</span>. The interpolation threshold (black dashed line) is observed at <span class="arithmatex">\(n \cdot K\)</span>.</p>
<h2 id="double-descent-example-2-layer-relu-nn-with-fixed-hidden-layer-weights">Double descent example: 2-layer ReLU NN with fixed hidden layer weights<a class="headerlink" href="#double-descent-example-2-layer-relu-nn-with-fixed-hidden-layer-weights" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-138.jpg?height=1234&amp;width=2880&amp;top_left_y=506&amp;top_left_x=227" /></p>
<h2 id="how-to-avoid-overfitting">How to avoid overfitting<a class="headerlink" href="#how-to-avoid-overfitting" title="Permanent link">&para;</a></h2>
<p>Regularization is loosely defined as mechanisms to prevent overfitting.</p>
<p>When you are overfitting, regularize with:</p>
<ul>
<li>Smaller NN (fewer parameters) or larger NN (more parameters).</li>
<li>Improve data by:</li>
<li>using data augmentation</li>
<li>acquiring better, more diverse, data</li>
<li>acquiring more of the same data</li>
<li>Weight decay</li>
<li>Dropout</li>
<li>Early stopping on SGD or late stopping on SGD</li>
</ul>
<h2 id="how-to-avoid-underfitting">How to avoid underfitting<a class="headerlink" href="#how-to-avoid-underfitting" title="Permanent link">&para;</a></h2>
<p>When you are underfitting, use:</p>
<ul>
<li>Larger NN (if computationally feasible)</li>
<li>Less weight decay</li>
<li>Less dropout</li>
<li>Run SGD longer (if computationally feasible)</li>
</ul>
<h2 id="weight-decay-cong-ell2-regularization">Weight decay <span class="arithmatex">\(\cong \ell^{2}\)</span>-regularization<a class="headerlink" href="#weight-decay-cong-ell2-regularization" title="Permanent link">&para;</a></h2>
<p><span class="arithmatex">\(\ell^{2}\)</span>-regularization augments the loss function with</p>
<div class="arithmatex">\[
\operatorname{minimize}_{\theta \in \mathbb{R}^{p}} \frac{1}{N} \sum_{i=1}^{N} \ell\left(f_{\theta}\left(x_{i}\right), y_{i}\right)+\frac{\lambda}{2}\|\theta\|^{2}
\]</div>
<p>SGD on the augmented loss is usually implemented by changing SGD update rather than explicitly changing the loss since</p>
<div class="arithmatex">\[
\begin{gathered}
\theta^{k+1}=\theta^{k}-\alpha\left(g^{k}+\lambda \theta^{k}\right) \\
=(1-\alpha \lambda) \theta^{k}-\alpha g^{k}
\end{gathered}
\]</div>
<p>Where <span class="arithmatex">\(g^{k}\)</span> is stochastic gradient of original (unaugmented) loss.
In classical statistics, this is called ridge regression or maximum a posteriori (MAP) estimation with Gaussian prior.</p>
<h2 id="weight-decay-cong-ell2-regularization_1">Weight decay <span class="arithmatex">\(\cong \ell^{2}\)</span>-regularization<a class="headerlink" href="#weight-decay-cong-ell2-regularization_1" title="Permanent link">&para;</a></h2>
<p>In Pytorch, you can use SGD + weight decay by:
augmenting the loss function</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>for param in model.parameters():
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>    loss += (lamda/2)*param.pow(2.0).sum()
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a>torch.optim.SGD(model.parameters(), lr=... , weight_decay=0)
</span></code></pre></div>
<p>or by using weight_decay in the optimizer
torch.optim.SGD(model.parameters(), lr=... , weight_decay=lamda)</p>
<p>For plain SGD, weight decay and <span class="arithmatex">\(\ell^{2}\)</span>-regularization are equivalent. For other optimizers, the two are similar but not the same. More on this later.</p>
<h2 id="dropout">Dropout<a class="headerlink" href="#dropout" title="Permanent link">&para;</a></h2>
<p>Dropout is a regularization technique that randomly disables neurons.</p>
<p>Standard layer,</p>
<div class="arithmatex">\[
h_{2}=\sigma\left(W_{1} h_{1}+b_{1}\right)
\]</div>
<p>Dropout with drop probability <span class="arithmatex">\(p\)</span> defines</p>
<div class="arithmatex">\[
h_{2}=\sigma\left(W_{1} h_{1}^{\prime}+b_{1}\right)
\]</div>
<p>with</p>
<div class="arithmatex">\[
\left(h_{1}^{\prime}\right)_{j}= \begin{cases}0 &amp; \text { with probability } p \\ \frac{\left(h_{1}\right)_{j}}{1-p} &amp; \text { otherwise }\end{cases}
\]</div>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-143.jpg?height=639&amp;width=571&amp;top_left_y=790&amp;top_left_x=1760" />
(a) Standard Neural Net
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-143.jpg?height=631&amp;width=566&amp;top_left_y=790&amp;top_left_x=2477" />
(b) After applying dropout.</p>
<p>Figure 1: Dropout Neural Net Model. Left: A standard neural net with 2 hidden layers. Right: An example of a thinned net produced by applying dropout to the network on the left. Crossed units have been dropped.</p>
<h2 id="why-is-dropout-helpful">Why is dropout helpful?<a class="headerlink" href="#why-is-dropout-helpful" title="Permanent link">&para;</a></h2>
<p>"A motivation for dropout comes from a theory of the role of sex in evolution (Livnat et al., 2010)."</p>
<p>Sexual reproduction, compared to asexual reproduction, creates the criterion for natural selection mix-ability of genes rather than individual fitness, since genes are mixed in a more haphazard manner.
"Since a gene cannot rely on a large set of partners to be present at all times, it must learn to do something useful on its own or in collaboration with a small number of other genes. ... Similarly, each hidden unit in a neural network trained with dropout must learn to work with a randomly chosen sample of other units. This should make each hidden unit more robust and drive it towards creating useful features on its own without relying on other hidden units to correct its mistakes.</p>
<h2 id="why-is-dropout-helpful_1">Why is dropout helpful?<a class="headerlink" href="#why-is-dropout-helpful_1" title="Permanent link">&para;</a></h2>
<p>The analogy to evolution is very interesting, but it is ultimately a heuristic argument. It also shifts the burden to the question: "why is sexual evolution more powerful than asexual evolution?"</p>
<p>However, dropout can be shown to be loosely equivalent to <span class="arithmatex">\(\ell^{2}\)</span>-regularization. However, we do not yet have a complete understanding of the mathematical reason behind dropout's performance.</p>
<h2 id="dropout-in-pytorch">Dropout in PyTorch<a class="headerlink" href="#dropout-in-pytorch" title="Permanent link">&para;</a></h2>
<p>Dropout simply multiplies the neurons with a random <span class="arithmatex">\(0-\frac{1}{1-p_{\text {drop }}}\)</span> mask.</p>
<p>A direct implementation in PyTorch:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>def dropout_layer(X, p_drop):
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>    mask = (torch.rand(X.shape) &gt; p_drop).float()
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>    return mask * X / (1.0 - p_drop)
</span></code></pre></div>
<p>PyTorch provides an implementation of dropout through torch.nn. Dropout.</p>
<h2 id="dropout-in-training-vs-test">Dropout in training vs. test<a class="headerlink" href="#dropout-in-training-vs-test" title="Permanent link">&para;</a></h2>
<p>Typically, dropout is used during training and turned off during prediction/testing.
(Dropout should be viewed as an additional onus imposed during training to make training more difficult and thereby effective, but it is something that should be turned off later.)</p>
<p>In PyTorch, activate the training mode with
model.train()
and activate evaluation mode with
model.eval()
dropout (and batchnorm) will behave differently in these two modes.</p>
<h2 id="when-to-use-dropout">When to use dropout<a class="headerlink" href="#when-to-use-dropout" title="Permanent link">&para;</a></h2>
<p>Dropout is usually used on linear layers but not on convolutional layers.</p>
<ul>
<li>Linear layers have many weights and each weight is used only once per forward pass. (If <span class="arithmatex">\(y=\operatorname{Linear}_{A, b}(x)\)</span>, then <span class="arithmatex">\(A_{i j}\)</span> only affect <span class="arithmatex">\(y_{i}\)</span>.) So regularization seems more necessary.</li>
<li>A convolutional filter has fewer weights and each weight is used multiple times in each forward pass. (If <span class="arithmatex">\(y=\operatorname{Conv} 2 \mathrm{D}_{w, b}(x)\)</span>, then <span class="arithmatex">\(w_{i j k t}\)</span> affects <span class="arithmatex">\(\left.y_{i, .,:}.\right)\)</span> So regularization seems less necessary.</li>
</ul>
<p>Dropout seems to be going out of fashion:</p>
<ul>
<li>Dropout's effect is somehow subsumed by batchnorm. (This is poorly understood.)</li>
<li>Linear layers are less common due to their large number of trainable parameters.</li>
</ul>
<p>There is no consensus on whether dropout should be applied before or after the activation function. However, Dropout- <span class="arithmatex">\(\sigma\)</span> and <span class="arithmatex">\(\sigma\)</span>-Dropout are equivalent when <span class="arithmatex">\(\sigma\)</span> is <span class="arithmatex">\(\operatorname{ReLU}\)</span> or leaky <span class="arithmatex">\(\operatorname{ReLU}\)</span>, or, more generally, when <span class="arithmatex">\(\sigma\)</span> is nonnegative homogeneous.</p>
<h2 id="sgd-early-stopping">SGD early stopping<a class="headerlink" href="#sgd-early-stopping" title="Permanent link">&para;</a></h2>
<p>Early stopping of SGD refers to stopping the training early even if you have time for more iterations.</p>
<p>The rationale is that SGD fits data, so too many iterations lead to overfitting.</p>
<p>A similar phenomenon (too many iterations hurt) is observed in classical algorithms for inverse problems.</p>
<p>Typical training and testing loss Us. iterations
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-149.jpg?height=797&amp;width=1612&amp;top_left_y=669&amp;top_left_x=1722" /></p>
<h2 id="epochwise-double-descent">Epochwise double descent<a class="headerlink" href="#epochwise-double-descent" title="Permanent link">&para;</a></h2>
<p>Recently, however, an epochwise double descent has been observed.</p>
<p>So perhaps one should stop SGD early or very late.</p>
<p>We do not yet have clarity with this new phenomenon.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-150.jpg?height=983&amp;width=1672&amp;top_left_y=593&amp;top_left_x=1656" /></p>
<h2 id="more-data-by-data-auagmentation">More data (by data auagmentation)<a class="headerlink" href="#more-data-by-data-auagmentation" title="Permanent link">&para;</a></h2>
<p>With all else fixed, using more data usually* leads to less overfitting.</p>
<p>However, collecting more data is often expansive.</p>
<p>Think of data augmentation (DA) as a mechanism to create more data for free. You can view DA as a form of regularization.</p>
<h2 id="summary-of-over-vs-underfitting">Summary of over vs. underfitting<a class="headerlink" href="#summary-of-over-vs-underfitting" title="Permanent link">&para;</a></h2>
<p>In modern deep learning, the double descent phenomenon has brought a conceptual and theoretical crisis regarding over and underfitting. Much of the machine learning practice is informed by classical statistics and learning theory, which do not take the double descent phenomenon into account.</p>
<p>Double descent will bring fundamental changes to statistics, and researchers need more time to figure things out. Most researchers, practitioners and theoreticians, agree that not all classical wisdom is invalid, but what part do we keep, and what part do we replace?</p>
<p>In the meantime, we will have to keep in mind the two contradictory viewpoints and move forward in the absence of clarity.</p>
<h2 id="alexnet">AlexNet<a class="headerlink" href="#alexnet" title="Permanent link">&para;</a></h2>
<p>Won the 2012 ImageNet challenge by a large margin: top-5 error rate <span class="arithmatex">\(15.3 \%\)</span> vs. <span class="arithmatex">\(26.2 \%\)</span> second place.</p>
<p>Started the era of deep neural networks and their training via GPU computing.
AlexNet was split into 2 as GPU memory was limited. (A single modern GPU can easily hold AlexNet.)
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-153.jpg?height=707&amp;width=2200&amp;top_left_y=982&amp;top_left_x=958" /></p>
<h2 id="alexnet-for-imagenet">AlexNet for ImageNet<a class="headerlink" href="#alexnet-for-imagenet" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-154.jpg?height=1179&amp;width=3101&amp;top_left_y=201&amp;top_left_x=142" /></p>
<p><a href="Convolution+ReLU">^0</a></p>
<h2 id="alexnet-cifar10">AlexNet CIFAR10<a class="headerlink" href="#alexnet-cifar10" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-155.jpg?height=682&amp;width=3254&amp;top_left_y=433&amp;top_left_x=23" /></p>
<p>Conv.-ReLU
Max pool <span class="arithmatex">\(f=3, s=2\)</span> (overlapping max pool)
Network not split into 2
No local response normalization</p>
<h2 id="architectural-contribution-alexnet">Architectural contribution: AlexNet<a class="headerlink" href="#architectural-contribution-alexnet" title="Permanent link">&para;</a></h2>
<p>A scaled-up version of LeNet.</p>
<p>Demonstrated that deep CNNs can learn significantly complex tasks. (Some thought CNNs could only learn simple, toy tasks like MNIST.)</p>
<p>Demonstrated GPU computing to be an essential component of deep learning.</p>
<p>Demonstrated effectiveness of ReLU over sigmoid or tanh in deep CNNs for classification.</p>
<h2 id="sgd-type-optimizers">SGD-type optimizers<a class="headerlink" href="#sgd-type-optimizers" title="Permanent link">&para;</a></h2>
<p>In modern NN training, SGD and variants of SGD are usually used. There are many variants of SGD.</p>
<p>The variants are compared mostly on an experimental basis. There is some limited theoretical basis in their comparisons. (Cf. Adam story.)</p>
<p>So far, all efforts to completely replace SGD have failed.</p>
<h2 id="sgd-with-momentum">SGD with momentum<a class="headerlink" href="#sgd-with-momentum" title="Permanent link">&para;</a></h2>
<p>SGD:</p>
<div class="arithmatex">\[
\theta^{k+1}=\theta^{k}-\alpha g^{k}
\]</div>
<p>SGD with momentum:</p>
<div class="arithmatex">\[
\begin{gathered}
v^{k+1}=g^{k}+\beta v^{k} \\
\theta^{k+1}=\theta^{k}-\alpha v^{k+1}
\end{gathered}
\]</div>
<p><span class="arithmatex">\(\beta=0.9\)</span> is a common choice.</p>
<p>When different coordinates (parameters) have very different scalings (i.e., when the problem is ill-conditioned, momentum can help find a good direction of progress.</p>
<h2 id="rmsprop">RMSProp<a class="headerlink" href="#rmsprop" title="Permanent link">&para;</a></h2>
<p>RMSProp:</p>
<div class="arithmatex">\[
\begin{gathered}
m_{2}^{k+1}=\beta_{2} m_{2}^{k}+\left(1-\beta_{2}\right)\left(g^{k} \circledast g^{k}\right) \\
\theta^{k+1}=\theta^{k}-\alpha g^{k} \oslash \sqrt{m_{2}^{k+1}+\epsilon}
\end{gathered}
\]</div>
<p><span class="arithmatex">\(\beta_{2}=0.99\)</span> and <span class="arithmatex">\(\epsilon=10^{-8}\)</span> are common values. <span class="arithmatex">\(\circledast\)</span> and <span class="arithmatex">\(\oslash\)</span> are elementwise mult. and div.
<span class="arithmatex">\(m_{2}^{k}\)</span> is a running estimate of the <span class="arithmatex">\(2^{\text {nd }}\)</span> moment of the stochastic gradients, i.e., <span class="arithmatex">\(\left(m_{2}^{k}\right)_{i} \approx \mathbb{E}\left(g^{k}\right)_{i}^{2}\)</span>.
<span class="arithmatex">\(\alpha \oslash \sqrt{m_{2}^{k+1}+\epsilon}\)</span> is the learning rate scaled elementwise. Progress along steep and noisy directions are dampened while progress along flat and non-noisy directions are accelerated.</p>
<h2 id="adam-adaptive-moment-estimation">Adam (Adaptive moment estimation)<a class="headerlink" href="#adam-adaptive-moment-estimation" title="Permanent link">&para;</a></h2>
<p>Adam:</p>
<div class="arithmatex">\[
\begin{gathered}
m_{1}^{k+1}=\beta_{1} m_{1}^{k}+\left(1-\beta_{1}\right) g^{k}, m_{2}^{k+1}=\beta_{2} m_{2}^{k}+\left(1-\beta_{2}\right)\left(g^{k} \circledast g^{k}\right) \\
\tilde{m}_{1}^{k+1}=\frac{m_{1}^{k+1}}{1-\beta_{1}^{k+1}}, \quad \widetilde{m}_{2}^{k+1}=\frac{m_{2}^{k+1}}{1-\beta_{2}^{k+1}} \\
\theta^{k+1}=\theta^{k}-\alpha \widetilde{m}_{1}^{k+1} \oslash \sqrt{\widetilde{m}_{2}^{k+1}+\epsilon}
\end{gathered}
\]</div>
<ul>
<li><span class="arithmatex">\(\quad \beta_{1}^{k+1}\)</span> means <span class="arithmatex">\(\beta_{1}\)</span> to the <span class="arithmatex">\((k+1)\)</span> th power.</li>
<li><span class="arithmatex">\(\beta_{1}=0.9, \beta_{2}=0.999\)</span>, and <span class="arithmatex">\(\epsilon=10^{-8}\)</span> are common values. Initialize with <span class="arithmatex">\(m_{1}^{0}=m_{2}^{0}=0\)</span>.</li>
<li><span class="arithmatex">\(m_{1}^{k}\)</span> and <span class="arithmatex">\(m_{2}^{k}\)</span> are running estimates of the <span class="arithmatex">\(1^{\text {st }}\)</span> and <span class="arithmatex">\(2^{\text {nd }}\)</span> moments of <span class="arithmatex">\(g^{k}\)</span>.</li>
<li><span class="arithmatex">\(\tilde{m}_{1}^{k}\)</span> and <span class="arithmatex">\(\tilde{m}_{2}^{k}\)</span> are bias-corrected estimates of <span class="arithmatex">\(m_{1}^{k}\)</span> and <span class="arithmatex">\(m_{2}^{k}\)</span>.</li>
<li>Using <span class="arithmatex">\(\widetilde{m}_{1}^{k}\)</span> instead of <span class="arithmatex">\(g^{k}\)</span> adds the effect of momentum.</li>
</ul>
<h2 id="bias-correction-of-adam">Bias correction of Adam<a class="headerlink" href="#bias-correction-of-adam" title="Permanent link">&para;</a></h2>
<p>To understand the bias correction, consider the hypothetical <span class="arithmatex">\(g^{k}=g\)</span> for <span class="arithmatex">\(k=0,1, \ldots\)</span>. Then</p>
<div class="arithmatex">\[
m_{1}^{k}=\left(1-\beta_{1}^{k}\right) g
\]</div>
<p>and</p>
<div class="arithmatex">\[
m_{2}^{k}=\left(1-\beta_{2}^{k}\right)(g \circledast g)
\]</div>
<p>while <span class="arithmatex">\(m_{1}^{k} \rightarrow g\)</span> and <span class="arithmatex">\(m_{2}^{k} \rightarrow(g \circledast g)\)</span> as <span class="arithmatex">\(k \rightarrow \infty\)</span>, the estimators are not exact despite there being no variation in <span class="arithmatex">\(g^{k}\)</span>.</p>
<p>On the other hand, there is bias-corrected estimators are exact:</p>
<div class="arithmatex">\[
\widetilde{m}_{1}^{k}=g
\]</div>
<p>and</p>
<div class="arithmatex">\[
\widetilde{m}_{2}^{k}=(g \circledast g)
\]</div>
<h2 id="the-cautionary-tale-of-adam">The cautionary tale of Adam<a class="headerlink" href="#the-cautionary-tale-of-adam" title="Permanent link">&para;</a></h2>
<p>Adam's original 2015 paper justified the effectiveness of the algorithm through experiments training deep neural networks with Adam. After all, this non-convex optimization is what Adam was proposed to do.</p>
<p>However, the paper also provided a convergence proof under the assumption of convexity. This was perhaps unnecessary in an applied paper focusing on non-convex optimization.</p>
<p>The proof was later shown to be incorrect! Adam does not always converge in the convex setup, i.e., the algorithm, rather than the proof, is wrong.</p>
<p>Reddi and Kale presented the AMSGrad optimizer, which does come with a correct convergence proof, but AMSGrad tends to perform worse than Adam, empirically.</p>
<h2 id="how-to-choose-the-optimizer">How to choose the optimizer<a class="headerlink" href="#how-to-choose-the-optimizer" title="Permanent link">&para;</a></h2>
<p>Extensive research has gone into finding the "best" optimizer. Schmidt et al." reports that, roughly speaking, that Adam works well most of the time.</p>
<p>So, Adam is a good default choice. Currently, it seems to be the best default choice.</p>
<p>However, Adam does not always work. For example, it seems to be that the widely used EfficientNet model can only be trained <span class="arithmatex">\({ }^{\dagger}\)</span> with RMSProp.</p>
<p>However, there are some setups where the LR of SGD is harder to tune, but SGD outperforms Adam when properly tuned.#</p>
<p>[^1]</p>
<h2 id="how-to-tune-parameters">How to tune parameters<a class="headerlink" href="#how-to-tune-parameters" title="Permanent link">&para;</a></h2>
<p>Everything should be chosen by trial and error. The weight parameters and <span class="arithmatex">\(\beta, \beta_{1}, \beta_{2}\)</span> and the weight decay parameter <span class="arithmatex">\(\lambda\)</span>, and the optimizers should be chosen based on trial and error.</p>
<p>The LR (the stepsize <span class="arithmatex">\(\alpha\)</span> ) of different optimizers are not really comparable between the different optimizers. When you change the optimizer, the LR should be tuned again.</p>
<p>Roughly, large stepsize, large momentum, small weight decay is faster but less stable, while small stepsize, small momentum, and large weight decay is slower but more stable.</p>
<h2 id="using-different-optimizers-in-pytorch">Using different optimizers in PyTorch<a class="headerlink" href="#using-different-optimizers-in-pytorch" title="Permanent link">&para;</a></h2>
<p>In PyTorch, the torch. optim module implements the commonly used optimizers.</p>
<p>Using SGD:
torch.optim.SGD(model.parameters(), lr=X)
Using SGD with momentum:
torch.optim.SGD(model.parameters(), momentum=0.9, lr=X)
Using RMSprop:
torch.optim.RMSprop(model.parameters(), lr=X)
Using Adam:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>torch.optim.Adam(model.parameters(), lr=X)
</span></code></pre></div>
<p>Exercise: Try Homework 3 problem 1 with Adam but without the custom weight initialization.</p>
<h2 id="learning-rate-scheduler">Learning rate scheduler<a class="headerlink" href="#learning-rate-scheduler" title="Permanent link">&para;</a></h2>
<p>Sometimes, it is helpful to change (usually reduce) the learning rate as the training progresses. PyTorch provides learning rate schedulers to do this.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>optimizer = SGD(model.parameters(), lr=0.1)
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>scheduler = ExponentialLR(optimizer, gamma=0.9) # lr = 0.9*lr
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>for _ in range(...):
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a>    for input, target in dataset:
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>        optimizer.zero_grad()
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a>        output = model(input)
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a>        loss = loss_fn(output, target)
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a>        loss.backward()
</span><span id="__span-5-9"><a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a>        optimizer.step()
</span><span id="__span-5-10"><a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a>    scheduler.step() # .step() call updates (changes) the learning rate
</span></code></pre></div>
<h2 id="diminishing-learning-rate">Diminishing learning rate<a class="headerlink" href="#diminishing-learning-rate" title="Permanent link">&para;</a></h2>
<p>One common choice is to specify a diminishing learning rate via a function (a lambda expression). Choices like C/epoch or <span class="arithmatex">\(\mathrm{C} /\)</span> sqrt(iteration), where C is an appropriately chosen constant, are common.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a># lr_lambda allows us to set lr with a function
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>scheduler = LambdaLR(optimizer, lr_lambda = lambda ep: 1e-2/ep)
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a>for epoch in range(...):
</span><span id="__span-6-4"><a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a>    for input, target in dataset:
</span><span id="__span-6-5"><a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a>        optimizer.zero_grad()
</span><span id="__span-6-6"><a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a>        output = model(input)
</span><span id="__span-6-7"><a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a>        loss = loss_fn(output, target)
</span><span id="__span-6-8"><a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a>        loss.backward()
</span><span id="__span-6-9"><a id="__codelineno-6-9" name="__codelineno-6-9" href="#__codelineno-6-9"></a>        optimizer.step()
</span><span id="__span-6-10"><a id="__codelineno-6-10" name="__codelineno-6-10" href="#__codelineno-6-10"></a>    scheduler.step() # lr=0.01/epoch
</span></code></pre></div>
<h2 id="cosine-learning-rate">Cosine learning rate<a class="headerlink" href="#cosine-learning-rate" title="Permanent link">&para;</a></h2>
<p>The cosine learning rate scheduler, which sets the learning rate with the cosine function, is also commonly used.</p>
<p>The <span class="arithmatex">\(2^{\text {nd }}\)</span> case in the specification means <span class="arithmatex">\(k\)</span> and its purpose is to prevent the learning rate from becoming 0 .
It is also common to use only a half-period of the cosine rather than having the learning rate oscillate.</p>
<h2 id="cosineannealinglr">COSINEANNEALINGLR<a class="headerlink" href="#cosineannealinglr" title="Permanent link">&para;</a></h2>
<div class="arithmatex">\[
\begin{aligned}
&amp; \text { CLASS torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=0, } \\
&amp; \text { last_epoch=- 1, verbose=False) [SOURCE] } \\
&amp; \text { Set the learning rate of each parameter group using a cosine annealing schedule, where } \eta_{\max } \text { is set to the } \\
&amp; \text { initial Ir and } T_{\text {cur }} \text { is the number of epochs since the last restart in SGDR: } \\
&amp; \eta_{t}=\eta_{\min }+\frac{1}{2}\left(\eta_{\max }-\eta_{\min }\right)\left(1+\cos \left(\frac{T_{\text {cur }}}{T_{\max }} \pi\right)\right), \quad T_{\text {cur }} \neq(2 k+1) T_{\max } ; \\
&amp; \eta_{t+1}=\eta_{t}+\frac{1}{2}\left(\eta_{\max }-\eta_{\min }\right)\left(1-\cos \left(\frac{1}{T_{\max }} \pi\right)\right), \quad T_{\text {cur }}=(2 k+1) T_{\max } . \\
&amp; \text { When last_epoch=-1, sets initial Ir as Ir. Notice that because the schedule is defined recursively, the learning } \\
&amp; \text { rate can be simultaneously modified outside this scheduler by other operators. If the learning rate is set solely } \\
&amp; \text { by this scheduler, the learning rate at each step becomes: } \\
&amp; \eta_{t}=\eta_{\text {min }}+\frac{1}{2}\left(\eta_{\text {max }}-\eta_{\text {min }}\right)\left(1+\cos \left(\frac{T_{\text {cur }}}{T_{\text {max }}} \pi\right)\right) \\
&amp; \text { CLASS torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=0, } \\
&amp; \text { last_epoch=- 1, verbose=False) [SOURCE] } \\
&amp; \text { by this scheduler, the learning rate at each step becomes: } \\
&amp; \text { It has been proposed in SGDR: Stochastic Gradient Descent with Warm Restarts. Note that this only } \\
&amp; \text { implements the cosine annealing part of SGDR, and not the restarts. } \\
&amp; \text { nen }
\end{aligned}
\]</div>
<p>a</p>
<h2 id="wide-vs-sharp-minima">Wide vs. sharp minima<a class="headerlink" href="#wide-vs-sharp-minima" title="Permanent link">&para;</a></h2>
<p>As alluded to in hw1:</p>
<ul>
<li>Large step makes large and rough progress towards regions with small loss.</li>
<li>Small steps refines the model by finding sharper minima.</li>
</ul>
<p>Also small steps better suppress the effect of noise. Mathematically, one can show that SGD with small steps becomes very similar to GD with small steps.#</p>
<p>However, using small steps to converge to sharp minima may not always be optimal. There is some empirical evidence that wide minima have better test error than sharp minima.*</p>
<h2 id="weight-initialization_2">Weight initialization<a class="headerlink" href="#weight-initialization_2" title="Permanent link">&para;</a></h2>
<p>Remember, SGD is</p>
<div class="arithmatex">\[
\theta^{k+1}=\theta^{k}-\alpha g^{k}
\]</div>
<p>where <span class="arithmatex">\(\theta^{0} \in \mathbb{R}^{p}\)</span> is an initial point. Using a good initial point is important in NN training.
Prescription by LeCun et al.: "Weights should be chosen randomly but in such a way that the [tanh] is primarily activated in its linear region. If weights are all very large then the [tanh] will saturate resulting in small gradients that make learning slow. If weights are very small then gradients will also be very small." (Cf. Vanishing gradient homework problem.)
"Intermediate weights that range over the [tanh's] linear region have the advantage that (1) the gradients are large enough that learning can proceed and (2) the network will learn the linear part of the mapping before the more difficult nonlinear part."</p>
<h2 id="quick-math-review">Quick math review<a class="headerlink" href="#quick-math-review" title="Permanent link">&para;</a></h2>
<p>Using the <span class="arithmatex">\(1^{\text {st }}\)</span> order Taylor approximation,</p>
<div class="arithmatex">\[
\tanh (z) \approx z
\]</div>
<p>Write <span class="arithmatex">\(X \sim \mathcal{N}\left(\mu, \sigma^{2}\right)\)</span> to denote that <span class="arithmatex">\(X\)</span> is a Gaussian (normal) random variable with mean <span class="arithmatex">\(\mu\)</span> and standard deviation <span class="arithmatex">\(\sigma\)</span>.</p>
<p>If <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span> are independent mean-zero random variables, then</p>
<div class="arithmatex">\[
\begin{gathered}
\mathbb{E}[X Y]=0 \\
\operatorname{Var}(X Y)=\operatorname{Var}(X) \operatorname{Var}(Y)
\end{gathered}
\]</div>
<p>If <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span> are uncorrelated, i.e., if <span class="arithmatex">\(\mathbb{E}\left[\left(X-\mu_{X}\right)\left(Y-\mu_{Y}\right)\right]=0\)</span>, then <span class="arithmatex">\(\operatorname{Var}(X+Y)=\operatorname{Var}(X)+\)</span> <span class="arithmatex">\(\operatorname{Var}(Y)\)</span>. (Uncorrelated R.V. need not be independent.)</p>
<h2 id="weight-initialization_3">Weight initialization<a class="headerlink" href="#weight-initialization_3" title="Permanent link">&para;</a></h2>
<p>Consider
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-172.jpg?height=750&amp;width=877&amp;top_left_y=535&amp;top_left_x=1224" /></p>
<p>If <span class="arithmatex">\(w_{i} \sim \mathcal{N}\left(0, \sigma^{2}\right)\)</span> (zero-mean variance <span class="arithmatex">\(\sigma^{2}\)</span> Gaussian) then <span class="arithmatex">\(\operatorname{Var}(\mathrm{z})=3 \sigma^{2}\)</span>.
If <span class="arithmatex">\(\sigma=\frac{1}{\sqrt{3}}\)</span>, then <span class="arithmatex">\(\operatorname{Var}(\mathrm{z})=1\)</span>.</p>
<h2 id="lecun-initialization">LeCun initialization<a class="headerlink" href="#lecun-initialization" title="Permanent link">&para;</a></h2>
<p>Consider the layer</p>
<div class="arithmatex">\[
\begin{gathered}
y=\tanh (\tilde{y}) \\
\tilde{y}=A x+b
\end{gathered}
\]</div>
<p>where <span class="arithmatex">\(x \in \mathbb{R}^{n_{\text {in }}}\)</span> and <span class="arithmatex">\(y, \tilde{y} \in \mathbb{R}^{n_{\text {out }}}\)</span>. Assume <span class="arithmatex">\(x_{j}\)</span> have mean <span class="arithmatex">\(=0\)</span> variance <span class="arithmatex">\(=1\)</span> and are uncorrelated. If we initialize <span class="arithmatex">\(A_{i j} \sim \mathcal{N}\left(0, \sigma_{A}^{2}\right)\)</span> and <span class="arithmatex">\(b_{i} \sim \mathcal{N}\left(0, \sigma_{b}^{2}\right)\)</span>, IID, then</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \tilde{y}_{i}=\sum_{j=1}^{n_{\mathrm{in}}} A_{i j} x_{j}+b_{i} \quad \text { has mean }=0 \text { variance }=n_{\mathrm{in}} \sigma_{A}^{2}+\sigma_{b}^{2} \\
&amp; y_{i}=\tanh \left(\tilde{y}_{i}\right) \approx \tilde{y}_{i} \quad \text { has mean } \approx 0 \text { variance } \approx n_{\mathrm{in}} \sigma_{A}^{2}+\sigma_{b}^{2}
\end{aligned}
\]</div>
<p>If we choose</p>
<div class="arithmatex">\[
\sigma_{A}^{2}=\frac{1}{n_{\text {in }}}, \quad \sigma_{b}^{2}=0,
\]</div>
<p>(so <span class="arithmatex">\(b=0\)</span> ) then we have <span class="arithmatex">\(y_{i}\)</span> mean <span class="arithmatex">\(\approx 0\)</span> variance <span class="arithmatex">\(\approx 1\)</span> and are uncorrelated.</p>
<h2 id="lecun-initialization_1">LeCun initialization<a class="headerlink" href="#lecun-initialization_1" title="Permanent link">&para;</a></h2>
<p>By induction, with an <span class="arithmatex">\(L\)</span>-layer MLP,</p>
<ul>
<li>if the input to has mean <span class="arithmatex">\(=0\)</span> variance <span class="arithmatex">\(=1\)</span> and uncorrelated elements,</li>
<li>the weights and biases are initialized with <span class="arithmatex">\(A_{i j} \sim \mathcal{N}\left(0, \frac{1}{n_{\text {in }}}\right)\)</span> and <span class="arithmatex">\(b_{i}=0\)</span>, and</li>
<li>the linear approximations <span class="arithmatex">\(\tanh (z) \approx z\)</span> are valid,
then we can expect the output layer to have mean <span class="arithmatex">\(\approx 0\)</span> variance <span class="arithmatex">\(\approx 1\)</span>.</li>
</ul>
<h2 id="xavier-initialization">Xavier initialization<a class="headerlink" href="#xavier-initialization" title="Permanent link">&para;</a></h2>
<p>Consider the layer</p>
<div class="arithmatex">\[
\begin{gathered}
y=\tanh (\tilde{y}) \\
\tilde{y}=A x+b
\end{gathered}
\]</div>
<p>where <span class="arithmatex">\(x \in \mathbb{R}^{n_{\text {in }}}\)</span> and <span class="arithmatex">\(y, \tilde{y} \in \mathbb{R}^{n_{\text {out }}}\)</span>. Consider the gradient with respect to some loss <span class="arithmatex">\(\ell(y)\)</span>. Assume <span class="arithmatex">\(\left(\frac{\partial \ell}{\partial y}\right)_{i}\)</span> have mean <span class="arithmatex">\(=0\)</span> variance <span class="arithmatex">\(=1\)</span> and are uncorrelated. Then</p>
<div class="arithmatex">\[
\frac{\partial y}{\partial x}=\operatorname{diag}\left(\tanh ^{\prime}(A x+b)\right) A \approx A
\]</div>
<p>if <span class="arithmatex">\(\tanh (\tilde{y}) \approx \tilde{y}\)</span> and</p>
<div class="arithmatex">\[
\frac{\partial \ell}{\partial x}=\frac{\partial \ell}{\partial y} A
\]</div>
<p>If we initialize <span class="arithmatex">\(A_{i j} \sim \mathcal{N}\left(0, \sigma_{A}^{2}\right)\)</span> and <span class="arithmatex">\(b_{i} \sim \mathcal{N}\left(0, \sigma_{b}^{2}\right)\)</span>, IID, and assume that <span class="arithmatex">\(\frac{\partial \ell}{\partial y}\)</span> and <span class="arithmatex">\(A\)</span> are independent <span class="arithmatex">\({ }^{*}\)</span>, then</p>
<div class="arithmatex">\[
\left(\frac{\partial \ell}{\partial x}\right)_{j}=\sum_{i=1}^{n_{\text {out }}}\left(\frac{\partial \ell}{\partial y}\right)_{i} A_{i j} \text { has mean } \approx 0 \text { and variance } \approx n_{\text {out }} \sigma_{A}^{2}
\]</div>
<p>If we choose</p>
<div class="arithmatex">\[
\sigma_{A}^{2}=\frac{1}{n_{\mathrm{out}}}
\]</div>
<p>then <span class="arithmatex">\(\left(\frac{\partial \ell}{\partial x}\right)_{j}\)</span> have mean <span class="arithmatex">\(\approx 0\)</span> variance <span class="arithmatex">\(\approx 1\)</span> and are uncorrelated.</p>
<h2 id="xavier-initialization_1">Xavier initialization<a class="headerlink" href="#xavier-initialization_1" title="Permanent link">&para;</a></h2>
<p><span class="arithmatex">\(\frac{\partial \ell}{\partial y}\)</span> and <span class="arithmatex">\(A\)</span> are not independent; <span class="arithmatex">\(\frac{\partial \ell}{\partial y}\)</span> depends on the forward evaluation, which in turn depends on <span class="arithmatex">\(A\)</span>. Nevertheless, the calculation is an informative exercise and its result seems to be representative of common behavior.</p>
<p>If <span class="arithmatex">\(y=\tanh (A x+b)\)</span> is an early layer (close to input) in a deep neural network, then the randomness of <span class="arithmatex">\(A\)</span> is diluted through the forward and backward propagation and <span class="arithmatex">\(\frac{\partial \ell}{\partial y}\)</span> and <span class="arithmatex">\(A\)</span> will be nearly independent.</p>
<p>If <span class="arithmatex">\(y=\tanh (A x+b)\)</span> is an later layer (close to output) in a deep neural network, then <span class="arithmatex">\(\frac{\partial \ell}{\partial y}\)</span> and <span class="arithmatex">\(A\)</span> will have strong dependency.</p>
<h2 id="xavier-initialization_2">Xavier initialization<a class="headerlink" href="#xavier-initialization_2" title="Permanent link">&para;</a></h2>
<p>Consideration of forward and backward passes result in different prescriptions.
The Xavier initialization uses the harmonic mean of the two:</p>
<div class="arithmatex">\[
\sigma_{A}^{2}=\frac{2}{n_{\mathrm{in}}+n_{\mathrm{out}}}, \quad \sigma_{b}^{2}=0
\]</div>
<p>In the literature, the alternate notation fan <span class="arithmatex">\(_{\text {in }}\)</span> and fan out <span class="arithmatex">\(_{\text {out }}\)</span> are often used instead of <span class="arithmatex">\(n_{\text {in }}\)</span> and <span class="arithmatex">\(n_{\text {out }}\)</span>. The fan-in and fan-out terminology originally refers to the number of electric connections entering and exiting a circuit or an electronic device.</p>
<h2 id="kaiming-he-initialization">(Kaiming) He initialization<a class="headerlink" href="#kaiming-he-initialization" title="Permanent link">&para;</a></h2>
<p>Consider the layer</p>
<div class="arithmatex">\[
y=\operatorname{ReLU}(A x+b)
\]</div>
<p>We cannot use the Taylor expansion with ReLU.</p>
<p>However, a similar line of reasoning with the forward pass gives rise to</p>
<div class="arithmatex">\[
\sigma_{A}^{2}=\frac{2}{n_{\mathrm{in}}}
\]</div>
<p>And a similar consideration with backprop gives rise to</p>
<div class="arithmatex">\[
\sigma_{A}^{2}=\frac{2}{n_{\text {out }}}
\]</div>
<p>In PyTorch, use mode='fan_in' and mode='fan_out' to toggle between the two modes.</p>
<h2 id="discussions-on-initializations">Discussions on initializations<a class="headerlink" href="#discussions-on-initializations" title="Permanent link">&para;</a></h2>
<p>In the original description of the Xavier and He initializations, the biases are all initialized to 0 . However, the default initialization of Linear* and Conv2d <span class="arithmatex">\({ }^{\#}\)</span> layers in PyTorch uses initialize the biases randomly. A documented reasoning behind this choice (in the form of papers or GitHub discussions) do not seem to exist.</p>
<p>Initializing weights with the proper scaling is sometimes necessary to get the network to train, as you will see with the VGG network. However, so long as the network gets trained, the choice of initialization does not seem to affect the final performance.</p>
<p>Since initializations rely on the assumption that the input to each layer has roughly unit variance, it is important that the data is scaled properly. This is why PyTorch dataloader scales pixel intensity values to be in <span class="arithmatex">\([0,1]\)</span>, rather than <span class="arithmatex">\([0,255]\)</span>.</p>
<h2 id="initialization-for-conv">Initialization for conv<a class="headerlink" href="#initialization-for-conv" title="Permanent link">&para;</a></h2>
<p>Consider the layer</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; y=\tanh (\tilde{y}) \\
&amp; \tilde{y}=\operatorname{Conv} 2 \mathrm{D}_{w, b}(x)
\end{aligned}
\]</div>
<p>where <span class="arithmatex">\(w \in \mathbb{R}^{C_{\text {out }} \times C_{\text {in }} \times f_{1} \times f_{2}}\)</span> and <span class="arithmatex">\(b \in \mathbb{R}^{C_{\text {out }}}\)</span>. Assume <span class="arithmatex">\(x_{j}\)</span> have mean <span class="arithmatex">\(=0\)</span> variance <span class="arithmatex">\(=1\)</span> and are uncorrelated*. If we initialize <span class="arithmatex">\(w_{i j k \ell} \sim \mathcal{N}\left(0, \sigma_{w}^{2}\right)\)</span> and <span class="arithmatex">\(b_{i} \sim \mathcal{N}\left(0, \sigma_{b}^{2}\right)\)</span>, IID, then</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \tilde{y}_{i} \quad \text { has mean }=0 \text { variance }=\left(C_{\text {in }} f_{1} f_{2}\right) \sigma_{w}^{2}+\sigma_{b}^{2} \\
&amp; y_{i} \approx \tilde{y}_{i} \text { has mean } \approx 0 \text { variance } \approx\left(C_{\text {in }} f_{1} f_{2}\right) \sigma_{w}^{2}+\sigma_{b}^{2}
\end{aligned}
\]</div>
<p>If we choose</p>
<div class="arithmatex">\[
\sigma_{w}^{2}=\frac{1}{c_{\text {in }} f_{1} f_{2}}, \quad \sigma_{b}^{2}=0
\]</div>
<p>(so <span class="arithmatex">\(b=0\)</span> ) then we have <span class="arithmatex">\(y_{i}\)</span> mean <span class="arithmatex">\(\approx 0\)</span> variance <span class="arithmatex">\(\approx 1\)</span> and are correlated.</p>
<h2 id="initialization-for-conv_1">Initialization for conv<a class="headerlink" href="#initialization-for-conv_1" title="Permanent link">&para;</a></h2>
<p>Outputs from a convolutional layer are correlated. The uncorrelated assumption is false. Nevertheless, the calculation is an informative exercise and its result seems to be representative of common behavior.</p>
<p>Xavier and He initialization is usually used with</p>
<div class="arithmatex">\[
n_{\mathrm{in}}=C_{\mathrm{in}} f_{1} f_{2}
\]</div>
<p>and</p>
<div class="arithmatex">\[
n_{\text {out }}=C_{\text {out }} f_{1} f_{2}
\]</div>
<p>Justification of <span class="arithmatex">\(n_{\text {out }}=C_{\text {out }} f_{1} f_{2}\)</span> requires working through the complex indexing or considering the "transpose convolution". We will return to it later.</p>
<h2 id="imagenet-after-alexnet">ImageNet after AlexNet<a class="headerlink" href="#imagenet-after-alexnet" title="Permanent link">&para;</a></h2>
<p>AlexNet won the 2012 ImageNet challenge with 8 layers.
ZFNet won the 2013 ImageNet challenge also with 8 layers but with better parameter tuning.</p>
<p>Research since AlexNet indicated that depth is more important than width.
VGGNet ranked 2nd in the 2014 ImagNet challenge with 19 layers.
GoogLeNet ranked 1st in the 2014 ImageNet challenge with 22 layers.</p>
<p>VGG16</p>
<ul>
<li>16 layers with trainable parameters</li>
</ul>
<h2 id="vggnet">VGGNet<a class="headerlink" href="#vggnet" title="Permanent link">&para;</a></h2>
<ul>
<li><span class="arithmatex">\(3 \times 3\)</span> conv. <span class="arithmatex">\(p=1\)</span> (spatial dimension preserved)</li>
<li>No local response normalization</li>
<li>Weight decay <span class="arithmatex">\(5 \times 10^{-4}\)</span></li>
</ul>
<h2 id="by-the-oxford-visual-geometry-group">By the Oxford Visual Geometry Group<a class="headerlink" href="#by-the-oxford-visual-geometry-group" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-183.jpg?height=1121&amp;width=1399&amp;top_left_y=643&amp;top_left_x=31" /></p>
<ul>
<li>Dropout(0.5) used</li>
<li>Max pool <span class="arithmatex">\(f=2, s=2\)</span></li>
<li>ReLU activation function (except after pool and FC1000)</li>
</ul>
<h2 id="vggnet_1">VGGNet<a class="headerlink" href="#vggnet_1" title="Permanent link">&para;</a></h2>
<p>VGG19</p>
<ul>
<li>19 layers with trainable parameters</li>
<li>Slightly better than VGG16
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-184.jpg?height=1025&amp;width=1940&amp;top_left_y=742&amp;top_left_x=29" /></li>
</ul>
<h2 id="vggnet-cifar10">VGGNet-CIFAR10<a class="headerlink" href="#vggnet-cifar10" title="Permanent link">&para;</a></h2>
<h2 id="13-layer-modification-of-vggnet-for-cifar10">13-layer modification of VGGNet for CIFAR10<a class="headerlink" href="#13-layer-modification-of-vggnet-for-cifar10" title="Permanent link">&para;</a></h2>
<ul>
<li><span class="arithmatex">\(3 \times 3\)</span> conv. <span class="arithmatex">\(p=1\)</span></li>
<li>Max pool <span class="arithmatex">\(f=2, s=2\)</span>
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-185.jpg?height=1196&amp;width=3067&amp;top_left_y=661&amp;top_left_x=31" /></li>
</ul>
<h2 id="vggnet-training">VGGNet training<a class="headerlink" href="#vggnet-training" title="Permanent link">&para;</a></h2>
<p>Training VGGNet was tricky. A shallower version was first trained and then additional layers were gradually added.</p>
<p>Our VGGNet-CIFAR10 is much easier to train since there are fewer layers and the task is simpler. However, good weight initialization is still necessary</p>
<p>Batchnorm (not available when VGGNet was published) makes training VGGNet much easier. With Batchnorm, the complicated initialization scheme of training a smaller version first becomes unnecessary.</p>
<p>PyTorch demo</p>
<h2 id="architectural-contribution-vggnet">Architectural contribution: VGGNet<a class="headerlink" href="#architectural-contribution-vggnet" title="Permanent link">&para;</a></h2>
<p>Demonstrated simple deep CNNs can significantly improve upon AlexNet.</p>
<p>In a sense, VGGNet represents the upper limit of the simple CNN architecture. (It is the best simple model.) Future architectures make gains through more complex constructions.</p>
<p>Demonstrated effectiveness of stacked <span class="arithmatex">\(3 \times 3\)</span> convolutions over larger <span class="arithmatex">\(5 \times 5\)</span> or 11x11 convolutions. Large convolutions (larger than <span class="arithmatex">\(5 \times 5\)</span> ) are now uncommon.</p>
<p>Due to its simplicity, VGGNet is one of the most common test subjects for testing something on deep CNNs.</p>
<h2 id="backprop-subseteq-autodiff">Backprop <span class="arithmatex">\(\subseteq\)</span> autodiff<a class="headerlink" href="#backprop-subseteq-autodiff" title="Permanent link">&para;</a></h2>
<p>Autodiff (automatic differentiation) is an algorithm that automates gradient computation. In deep learning libraries, you only need to specify how to evaluate the function. Backprop (back propagation) is an instance of autodiff.</p>
<p>Gradient computation costs roughly <span class="arithmatex">\(5 \times\)</span> the computation cost <span class="arithmatex">\(^{*}\)</span> of forward evaluation.</p>
<p>To clarify, backprop and autodiff are not</p>
<ul>
<li>finite difference or</li>
<li>symbolic differentiation.</li>
</ul>
<p>Autodiff <span class="arithmatex">\(\approx\)</span> chain rule of vector calculus</p>
<h2 id="autodiff-example">Autodiff example<a class="headerlink" href="#autodiff-example" title="Permanent link">&para;</a></h2>
<p>This complicated gradient computation is simplified by autodiff.</p>
<p>PyTorch demo
<span class="arithmatex">\(\operatorname{In}[\cdot]:=\mathrm{fn}=\frac{\operatorname{Sin}\left[\operatorname{Cosh}\left[y^{2}+\frac{x}{z}\right]+\operatorname{Tanh}[x y z]\right]}{\log [1+\operatorname{Exp}[x]]}\)</span>;
<span class="arithmatex">\(D[f n, x]\)</span>
<span class="arithmatex">\(\% / .\{x \rightarrow 3.3, y \rightarrow 1.1, z \rightarrow 2.3\} / / N\)</span>
D[fn, <span class="arithmatex">\(y\)</span> ]
<span class="arithmatex">\(\% / .\{x \rightarrow 3.3, y \rightarrow 1.1, z \rightarrow 2.3\} / / N\)</span>
D[fn, z]
<span class="arithmatex">\(\% / .\{x \rightarrow 3.3, y \rightarrow 1.1, z \rightarrow 2.3\} / / N\)</span></p>
<div class="arithmatex">\[
\text { Out }[\cdot]=-\frac{e^{x} \operatorname{Sin}\left[\operatorname{Cosh}\left[y^{2}+\frac{x}{z}\right]+\operatorname{Tanh}[x y z]\right]}{\left(1+e^{x}\right) \log \left[1+\mathbb{e}^{x}\right]^{2}}+\frac{\operatorname{Cos}\left[\operatorname{Cosh}\left[y^{2}+\frac{x}{z}\right]+\operatorname{Tanh}[x y z]\right]\left(y z \operatorname{Sech}[x y z]^{2}+\frac{\sinh \left[y^{2}+\frac{x}{z}\right]}{z}\right)}{\log \left[1+\mathbb{e}^{x}\right]}
\]</div>
<p>Out <span class="arithmatex">\([0]=-0.285274\)</span>
<span class="arithmatex">\(\frac{\operatorname{Cos}\left[\operatorname{Cosh}\left[y^{2}+\frac{x}{z}\right]+\operatorname{Tanh}[x y z]\right]\left(x z \operatorname{Sech}[x y z]^{2}+2 y \operatorname{Sinh}\left[y^{2}+\frac{x}{z}\right]\right)}{\log \left[1+\mathbb{e}^{x}\right]}\)</span>
Out[ <span class="arithmatex">\([0]=-1.01578\)</span>
<span class="arithmatex">\(\frac{\operatorname{Cos}\left[\operatorname{Cosh}\left[y^{2}+\frac{x}{z}\right]+\operatorname{Tanh}[x y z]\right]\left(x y \operatorname{Sech}[x y z]^{2}-\frac{x \operatorname{Sinh}\left[y^{2}+\frac{x}{z}\right]}{z^{2}}\right)}{\log \left[1+\mathbb{e}^{x}\right]}\)</span>
Out[ <span class="arithmatex">\([=0.288027\)</span></p>
<h2 id="the-power-of-autodiff">The power of autodiff<a class="headerlink" href="#the-power-of-autodiff" title="Permanent link">&para;</a></h2>
<p>Autodiff is an essential yet often an underappreciated feature of the deep learning libraries. It allows deep learning researchers to use complicated neural networks, while avoiding the burden of performing derivative calculations by hand.</p>
<p>Most deep learning libraries support <span class="arithmatex">\(2^{\text {nd }}\)</span> and higher order derivative computation, but we will only use <span class="arithmatex">\(1^{\text {st }}\)</span> order derivatives (gradients) in this class.</p>
<p>Autodiff includes forward-mode, reverse-mode (backprop), and other orders. In deep learning, reverse-mode is most commonly used.</p>
<h2 id="autodiff-by-jacobian-multiplication">Autodiff by Jacobian multiplication<a class="headerlink" href="#autodiff-by-jacobian-multiplication" title="Permanent link">&para;</a></h2>
<p>Consider <span class="arithmatex">\(g=f_{L} \circ f_{L-1} \circ \cdots \circ f_{2} \circ f_{1}\)</span>, where <span class="arithmatex">\(f_{\ell}: \mathbb{R}^{n_{\ell-1}} \rightarrow \mathbb{R}^{n_{\ell}}\)</span> for <span class="arithmatex">\(\ell=1, \cdots, L\)</span>.</p>
<p>Chain rule: <span class="arithmatex">\(D g=D f_{L} \quad D f_{L-1} \quad \cdots \quad D f_{2} \quad D f_{1}\)</span></p>
<div class="arithmatex">\[
n_{L} \times n_{L-1} \quad n_{L-1} \times n_{L-2} \quad n_{2} \times n_{1} \quad n_{1} \times n_{0}
\]</div>
<p>Forward-mode: <span class="arithmatex">\(D f_{L}\left(D f_{L-1}\left(\cdots\left(D f_{2} D f_{1}\right) \cdots\right)\right)\)</span></p>
<p>Reverse-mode: <span class="arithmatex">\(\left(\left(\left(D f_{L} D f_{L-1}\right) D f_{L-2}\right) \cdots\right) D f_{1}\)</span></p>
<p>Reverse mode is optimal <span class="arithmatex">\({ }^{*}\)</span> when <span class="arithmatex">\(n_{L} \leq n_{L-1} \leq \cdots \leq n_{1} \leq n_{0}\)</span>. The number of neurons in each layer tends to decrease in deep neural networks for classification. So reverse-mode is often close to the most efficient mode of autodiff in deep learning.</p>
<h2 id="general-backprop">General backprop<a class="headerlink" href="#general-backprop" title="Permanent link">&para;</a></h2>
<h2 id="backprop-in-pytorch">Backprop in PyTorch:<a class="headerlink" href="#backprop-in-pytorch" title="Permanent link">&para;</a></h2>
<ol>
<li>When the loss function is evaluated, a computation graph is constructed.</li>
<li>The computation graph is a directed acyclic graph (DAG) that encodes dependencies of the individual computational components.</li>
<li>A topological sort is performed on the DAG and the backprop is performed on the reversed order of this topological sort. (The topological sort ensures that nodes ahead in the DAG are processed first.)</li>
</ol>
<p>The general form combines a graph theoretic formulation with the principles of backprop that you have seen in the homework assignments.</p>
<h2 id="computation-graph-example">Computation graph example<a class="headerlink" href="#computation-graph-example" title="Permanent link">&para;</a></h2>
<p>Consider <span class="arithmatex">\(f(x, y)=y \log x+\sqrt{y \log x}\)</span>. Evaluate <span class="arithmatex">\(f\)</span> with the computation graph:
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-193.jpg?height=392&amp;width=1923&amp;top_left_y=693&amp;top_left_x=552" /></p>
<p>The chain rule: <span class="arithmatex">\(\frac{\partial f}{\partial x}=\frac{\partial f}{\partial c} \frac{\partial c}{\partial b}\left(\frac{\partial b}{\partial a} \frac{\partial a}{\partial x} \frac{\partial x}{\partial x}+\frac{\partial b}{\partial y} \frac{\partial y}{\partial x}\right)+\frac{\partial f}{\partial b}\left(\frac{\partial b}{\partial a} \frac{\partial a}{\partial x} \frac{\partial x}{\partial x}+\frac{\partial b}{\partial y} \frac{\partial y}{\partial x}\right)\)</span></p>
<div class="arithmatex">\[
\frac{\partial f}{\partial y}=\frac{\partial f}{\partial c} \frac{\partial c}{\partial b}\left(\frac{\partial b}{\partial a} \frac{\partial a}{\partial x} \frac{\partial x}{\partial y}+\frac{\partial b}{\partial y} \frac{\partial y}{\partial y}\right)+\frac{\partial f}{\partial b}\left(\frac{\partial b}{\partial a} \frac{\partial a}{\partial x} \frac{\partial x}{\partial y}+\frac{\partial b}{\partial y} \frac{\partial y}{\partial y}\right)
\]</div>
<p>But in what order do you evaluate the chain rule expression?</p>
<h2 id="computation-graph">Computation graph<a class="headerlink" href="#computation-graph" title="Permanent link">&para;</a></h2>
<p>Let <span class="arithmatex">\(y_{1}, \ldots, y_{L}\)</span> be the output values (neurons) of the computational nodes. Assume <span class="arithmatex">\(y_{1}, \ldots, y_{L}\)</span> follow a linear topological ordering, i.e., the computation of <span class="arithmatex">\(y_{\ell}\)</span> depends on <span class="arithmatex">\(y_{1}, \ldots, y_{\ell-1}\)</span> and does not depend on <span class="arithmatex">\(y_{\ell+1}, \ldots, y_{L}\)</span>.</p>
<p>Define the graph <span class="arithmatex">\(G=(V, E)\)</span>, where <span class="arithmatex">\(V=\{1, \ldots, L\}\)</span> and <span class="arithmatex">\((i, \ell) \in E\)</span>, i.e., <span class="arithmatex">\(i \rightarrow \ell\)</span>, if the computation of <span class="arithmatex">\(y_{\ell}\)</span> directly depends on <span class="arithmatex">\(y_{i}\)</span>. Write the computation of <span class="arithmatex">\(y_{1}, \ldots, y_{L}\)</span> as</p>
<div class="arithmatex">\[
y_{\ell}=f_{\ell}\left(\left[y_{i}: \text { for } i \rightarrow \ell\right]\right)
\]</div>
<h2 id="forward-pass-on-computation-graph">Forward pass on computation graph<a class="headerlink" href="#forward-pass-on-computation-graph" title="Permanent link">&para;</a></h2>
<p>In the forward pass, sequentially compute <span class="arithmatex">\(y_{1}, \ldots, y_{L}\)</span> via</p>
<div class="arithmatex">\[
y_{\ell}=f_{\ell}\left(\left[y_{i}: \text { for } i \rightarrow \ell\right]\right)
\]</div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a># Use 1-based indexing
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a># y[1] given
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>for l = 2,...,L
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a>    inputs = [y[i] for j such that (i-&gt;l)]
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>    y[l] = f[l].eval(inputs)
</span><span id="__span-7-6"><a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a>end
</span></code></pre></div>
<h2 id="forward-mode-autodiff">Forward-mode autodiff<a class="headerlink" href="#forward-mode-autodiff" title="Permanent link">&para;</a></h2>
<p><span class="arithmatex">\(\begin{array}{lllll}\text { Step } 0 &amp; \text { Step } 1 &amp; \text { Step } 2 &amp; \text { Step } 3 &amp; \text { Step } 4\end{array}\)</span>
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-196.jpg?height=349&amp;width=2050&amp;top_left_y=506&amp;top_left_x=187" />
0. <span class="arithmatex">\(x=3, y=2, \frac{\partial x}{\partial x}=1, \frac{\partial x}{\partial y}=0, \frac{\partial y}{\partial x}=0, \frac{\partial y}{\partial y}=1\)</span></p>
<ol>
<li><span class="arithmatex">\(a=\log x=\log 3, \frac{\partial a}{\partial x}=\frac{1}{x} \cdot \frac{\partial x}{\partial x}=\frac{1}{3}, \frac{\partial a}{\partial y}=0\)</span></li>
<li><span class="arithmatex">\(b=y a=2 \log 3, \frac{\partial b}{\partial x}=\frac{\partial y}{\partial x} a+y \frac{\partial a}{\partial x}=\frac{2}{3}, \frac{\partial b}{\partial y}=\frac{\partial y}{\partial y} a+y \frac{\partial a}{\partial y}=a=\log 3\)</span></li>
<li><span class="arithmatex">\(c=\sqrt{b}=\sqrt{2 \log 3}, \frac{\partial c}{\partial x}=\frac{1}{2 \sqrt{b}} \frac{\partial b}{\partial x}=\frac{1}{3 \sqrt{2 \log 3}}, \frac{\partial c}{\partial y}=\frac{1}{\sqrt{b}} \frac{\partial b}{\partial y}=\frac{1}{2} \sqrt{\frac{\log 3}{2}} \longleftarrow \quad\)</span> Computation only depends on node b</li>
<li><span class="arithmatex">\(f=c+b=\sqrt{2 \log 3}+2 \log 3, \frac{\partial f}{\partial x}=\frac{\partial c}{\partial x}+\frac{\partial b}{\partial x}=\frac{1}{3}\left(2+\frac{1}{3 \sqrt{2 \log 3}}\right), \frac{\partial f}{\partial y}=\frac{\partial c}{\partial y}+\frac{\partial b}{\partial y}=\frac{1}{2} \sqrt{\frac{\log 3}{2}}+\log 3\)</span></li>
</ol>
<h2 id="backprop-on-computation-graph">Backprop on computation graph<a class="headerlink" href="#backprop-on-computation-graph" title="Permanent link">&para;</a></h2>
<div class="language-text highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a># Use 1-based indexing
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a># y[1],...,y[L] already computed
</span><span id="__span-8-3"><a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a>g[:] = 0 // .zero_grad()
</span><span id="__span-8-4"><a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a>g[L] = 1 // dy[L]/dy[L]=1
</span><span id="__span-8-5"><a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a>for l = L,...,2
</span><span id="__span-8-6"><a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a>    for i such that (i-&gt;l)
</span><span id="__span-8-7"><a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a>        g[i] += g[l]*f[l].grad(i)
</span><span id="__span-8-8"><a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a>    end
</span><span id="__span-8-9"><a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a>end
</span></code></pre></div>
<p>To perform backprop#, use</p>
<div class="arithmatex">\[
\frac{\partial y_{L}}{\partial y_{i}}=\sum_{\ell: i \rightarrow \ell} \frac{\partial y_{L}}{\partial y_{\ell}} \frac{\partial f_{\ell}}{\partial y_{i}}
\]</div>
<p>to sequentially compute <span class="arithmatex">\(\frac{\partial y_{L}}{\partial y_{L}}, \frac{\partial y_{L}}{\partial y_{L-1}}, \ldots, \frac{\partial y_{L}}{\partial y_{1}}\)</span>.</p>
<h2 id="reverse-mode-autodiff-backprop">Reverse-mode autodiff (backprop)<a class="headerlink" href="#reverse-mode-autodiff-backprop" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-198.jpg?height=665&amp;width=2591&amp;top_left_y=386&amp;top_left_x=176" />
0. <span class="arithmatex">\(x=3, y=2\)</span></p>
<ol>
<li><span class="arithmatex">\(a=\log 3\)</span></li>
<li><span class="arithmatex">\(b=2 \log 3\)</span></li>
<li><span class="arithmatex">\(c=\sqrt{2 \log 3}\)</span></li>
<li><span class="arithmatex">\(f=\sqrt{2 \log 3}+2 \log 3\)</span>
<span class="arithmatex">\(0^{\prime} \cdot \frac{\partial f}{\partial f}=1\)</span>
1'. <span class="arithmatex">\(\frac{\partial f}{\partial c}=\frac{\partial f}{\partial f} \frac{\partial f}{\partial c}=\frac{\partial f}{\partial f} 1=1\)</span>
2'. <span class="arithmatex">\(\frac{\partial f}{\partial b}=\frac{\partial f}{\partial c} \frac{\partial c}{\partial b}+\frac{\partial f}{\partial f} \frac{\partial f}{\partial c}=\frac{1}{2 \sqrt{b}} 1+1=\frac{1}{2 \sqrt{2 \log 3}}+1\)</span>
3'. <span class="arithmatex">\(\frac{\partial f}{\partial a}=\frac{\partial f}{\partial b} \frac{\partial b}{\partial a}=\frac{\partial f}{\partial b} y=2+\frac{1}{\sqrt{2 \log 3}}\)</span>
4'. <span class="arithmatex">\(\frac{\partial f}{\partial x}=\frac{\partial f}{\partial a} \frac{\partial a}{\partial x}=\frac{\partial f}{\partial a} \frac{1}{x}=\frac{1}{3}\left(2+\frac{1}{\sqrt{2 \log 3}}\right)\)</span>
<span class="arithmatex">\(\frac{\partial f}{\partial y}=\frac{\partial f}{\partial b} \frac{\partial b}{\partial y}=\frac{\partial f}{\partial b} a=\frac{1}{2} \sqrt{\frac{\log 3}{2}}+\log 3\)</span></li>
</ol>
<h2 id="backprop-in-pytorch_1">Backprop in PyTorch<a class="headerlink" href="#backprop-in-pytorch_1" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-199.jpg?height=630&amp;width=2221&amp;top_left_y=327&amp;top_left_x=501" /></p>
<p>In NN training, parameters and fixed inputs are distinguished. In PyTorch, you (1) clear the existing gradient with .zero_grad() (2) forward-evaluate the loss function by providing the input and label and (3) perform backprop with . backward().</p>
<p>The forward pass stores the intermediate neuron values so that they can later be used in backprop. In the test loop, however, we don't compute gradients so the intermediate neuron values are unnecessary. The torch. no_grad() context manager allows intermediate node values to discarded or not be stored. This saves memory and can accelerate the test loop.</p>
<h2 id="linear-layers-have-too-may-parameters">Linear layers have too may parameters<a class="headerlink" href="#linear-layers-have-too-may-parameters" title="Permanent link">&para;</a></h2>
<p>AlexNet: Conv layer params: 2,469,696 (4\%)
Linear layer params: 58,631,144 (96\%)
Total params: 61,100,840
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-200.jpg?height=1039&amp;width=2733&amp;top_left_y=833&amp;top_left_x=598" /></p>
<h2 id="linear-layers-have-too-may-parameters_1">Linear layers have too may parameters<a class="headerlink" href="#linear-layers-have-too-may-parameters_1" title="Permanent link">&para;</a></h2>
<p>VGG19: Conv layer params: 20,024,384 (14\%)
Linear layer params: 123,642,856 (86\%)
Total params: 143,667,240
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-201.jpg?height=1005&amp;width=1949&amp;top_left_y=850&amp;top_left_x=25" />
fc8</p>
<h2 id="network-in-network-nin-network">Network in Network (NiN) Network<a class="headerlink" href="#network-in-network-nin-network" title="Permanent link">&para;</a></h2>
<p>NiN for CIFAR10.</p>
<ul>
<li>Remove linear layers to reduce parameters. Use global average pool instead.</li>
<li>Weight decay <span class="arithmatex">\(1 \times 10^{-5}\)</span>.</li>
<li>Dropout(0.5). (dropout after pool is not consistent with modern practice.)</li>
<li>Maxpool <span class="arithmatex">\(f=3, s=2\)</span>. Use ceil_mode=True so that <span class="arithmatex">\(\frac{32-3}{2}+1=15.5\)</span> is rounded up to 16 . Default behavior of PyTorch is to round down.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-202.jpg?height=614&amp;width=3187&amp;top_left_y=1198&amp;top_left_x=0" /></li>
</ul>
<h2 id="1x1-convolution">1x1 convolution<a class="headerlink" href="#1x1-convolution" title="Permanent link">&para;</a></h2>
<p>A <span class="arithmatex">\(1 \times 1\)</span> convolution is like a fully connected layer acting independently and identically on each spatial location.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-203.jpg?height=473&amp;width=1753&amp;top_left_y=691&amp;top_left_x=212" /></p>
<h2 id="192x32x32-96x32x32">192x32x32 <br> 96x32x32<a class="headerlink" href="#192x32x32-96x32x32" title="Permanent link">&para;</a></h2>
<ul>
<li>96 filters act on 192 channels separately for each pixel</li>
<li><span class="arithmatex">\(96 \times 192+96\)</span> parameters for weights and biases</li>
</ul>
<h2 id="regular-conv-layer">Regular conv. layer<a class="headerlink" href="#regular-conv-layer" title="Permanent link">&para;</a></h2>
<p>Input: <span class="arithmatex">\(X \in \mathbb{R}^{C_{0} \times m \times n}\)</span></p>
<ul>
<li>Select an <span class="arithmatex">\(f \times f\)</span> patch <span class="arithmatex">\(\tilde{X}=X[:, i: i+f, j: j+f]\)</span>.</li>
<li>Inner product <span class="arithmatex">\(\tilde{X}\)</span> and <span class="arithmatex">\(w_{1}, \ldots, w_{C_{1}} \in \mathbb{R}^{C_{0} \times f \times f}\)</span> and add bias <span class="arithmatex">\(b_{1} \in \mathbb{R}^{C_{1}}\)</span>.</li>
<li>Apply <span class="arithmatex">\(\sigma\)</span>. (Output in <span class="arithmatex">\(\mathbb{R}^{C_{1}}\)</span>.)</li>
</ul>
<p>Repeat this for all patches. Output in <span class="arithmatex">\(X \in \mathbb{R}^{C_{1} \times(m-f+1) \times(n-f+1)}\)</span>.
Repeat this for all batch elements.</p>
<h2 id="network-in-network">"Network in Network"<a class="headerlink" href="#network-in-network" title="Permanent link">&para;</a></h2>
<p>Input: <span class="arithmatex">\(X \in \mathbb{R}^{c_{0} \times m \times n}\)</span></p>
<ul>
<li>Select an <span class="arithmatex">\(f \times f\)</span> patch <span class="arithmatex">\(\tilde{X}=X[i: i+f, j: j+f]\)</span>.</li>
<li>Inner product <span class="arithmatex">\(\tilde{X}\)</span> and <span class="arithmatex">\(w_{1}, \ldots, w_{C_{1}} \in \mathbb{R}^{C_{0} \times f \times f}\)</span> and add bias <span class="arithmatex">\(b_{1} \in \mathbb{R}^{C_{1}}\)</span>.</li>
<li>Apply <span class="arithmatex">\(\sigma\)</span>. (Output in <span class="arithmatex">\(\mathbb{R}^{C_{1}}\)</span>.)</li>
<li>Apply Linear <span class="arithmatex">\(A_{A_{2}, b_{2}}(x)\)</span> where <span class="arithmatex">\(A_{2} \in \mathbb{R}^{C_{2} \times C_{1}}\)</span> and <span class="arithmatex">\(b_{2} \in \mathbb{R}^{C_{2}}\)</span>.</li>
<li>Apply <span class="arithmatex">\(\sigma\)</span>. (Output in <span class="arithmatex">\(\mathbb{R}^{C_{2}}\)</span>.)</li>
<li>Apply Linear <span class="arithmatex">\(A_{A_{3}, b_{3}}(x)\)</span> where <span class="arithmatex">\(A_{3} \in \mathbb{R}^{C_{3} \times C_{2}}\)</span> and <span class="arithmatex">\(b_{3} \in \mathbb{R}^{C_{3}}\)</span>.</li>
<li>Apply <span class="arithmatex">\(\sigma\)</span>. (Output in <span class="arithmatex">\(\mathbb{R}^{C_{3}}\)</span>.)</li>
</ul>
<p>Repeat this for all patches. Output in <span class="arithmatex">\(X \in \mathbb{R}^{C_{3} \times(m-f+1) \times(n-f+1)}\)</span>. Repeat this for all batch elements.
Why is this equivalent to ( <span class="arithmatex">\(3 \times 3\)</span> conv)-( <span class="arithmatex">\(1 \times 1\)</span> conv)-( <span class="arithmatex">\(1 \times 1\)</span> conv)?</p>
<h2 id="global-average-pool">Global average pool<a class="headerlink" href="#global-average-pool" title="Permanent link">&para;</a></h2>
<p>When using CNNs for classification, position of object is not important.</p>
<p>The global average pool has no trainable parameters (linear layers have many) and it is translation invariant. Global average pool removes the spatial dependency.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-206.jpg?height=554&amp;width=3184&amp;top_left_y=1216&amp;top_left_x=0" /></p>
<h2 id="architectural-contribution-nin-network">Architectural contribution: NiN Network<a class="headerlink" href="#architectural-contribution-nin-network" title="Permanent link">&para;</a></h2>
<p>Used <span class="arithmatex">\(1 \times 1\)</span> convolutions to increase the representation power of the convolutional modules.</p>
<p>Replaced linear layer with average pool to reduce number of trainable parameters.</p>
<p>First step in the trend of architectures becoming more abstract. Modern CNNs are built with smaller building blocks.</p>
<h2 id="googlenet-inception-v1">GoogLeNet (Inception v1)<a class="headerlink" href="#googlenet-inception-v1" title="Permanent link">&para;</a></h2>
<p>Utilizes the inception module. Structure inspired by NiN and name inspired by 2010 Inception movie meme.</p>
<p>Used <span class="arithmatex">\(1 \times 1\)</span> convolutions.</p>
<ul>
<li>Increased depth adds representation power (improves ability to represent nonlinear functions).</li>
<li>Reduce the number of channels before the expensive <span class="arithmatex">\(3 \times 3\)</span> and <span class="arithmatex">\(5 \times 5\)</span> convolutions, and thereby reduce number of trainable weights and computation time. (Cf. hw5)</li>
</ul>
<p>The name GoogLeNet is a reference to the authors' Google affiliation and is an homage to LeNet.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-208.jpg?height=513&amp;width=915&amp;top_left_y=0&amp;top_left_x=2417" /></p>
<p>Inception module
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-208.jpg?height=239&amp;width=809&amp;top_left_y=608&amp;top_left_x=2453" />
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-208.jpg?height=970&amp;width=669&amp;top_left_y=880&amp;top_left_x=2642" /></p>
<h2 id="googlenet">GoogLeNet<a class="headerlink" href="#googlenet" title="Permanent link">&para;</a></h2>
<h2 id="cl">Cl! ! ! ! !<a class="headerlink" href="#cl" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-209.jpg?height=1293&amp;width=3330&amp;top_left_y=153&amp;top_left_x=2" /></p>
<p>Two auxiliary classifiers used to slightly improve training. No longer necessary with batch norm.</p>
<h2 id="googlenet-for-cifar10">GoogLeNet for CIFAR10<a class="headerlink" href="#googlenet-for-cifar10" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-210.jpg?height=782&amp;width=2248&amp;top_left_y=467&amp;top_left_x=2" /></p>
<h2 id="1024x7x7-1024x1x1">1024x7x7 1024x1x1<a class="headerlink" href="#1024x7x7-1024x1x1" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-210.jpg?height=239&amp;width=516&amp;top_left_y=748&amp;top_left_x=2736" /></p>
<table>
<thead>
<tr>
<th style="text-align: center;"><span class="arithmatex">\(2 \mathbf{x}\)</span></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><span class="arithmatex">\(k=256480\)</span></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"><span class="arithmatex">\(k=64\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(k=128\)</span></td>
</tr>
<tr>
<td style="text-align: center;">96128</td>
<td style="text-align: center;">128256</td>
</tr>
<tr>
<td style="text-align: center;">1632</td>
<td style="text-align: center;">2464</td>
</tr>
<tr>
<td style="text-align: center;">32</td>
<td style="text-align: center;">64</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: center;">512</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">512</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><span class="arithmatex">\(k=192\)</span></td>
<td style="text-align: center;">512</td>
<td style="text-align: center;">528</td>
<td style="text-align: center;">832</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"><span class="arithmatex">\(96=160\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(k=128\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(k=112\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(k=256\)</span></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">96</td>
<td style="text-align: center;">208112</td>
<td style="text-align: center;">224128</td>
<td style="text-align: center;">256144</td>
<td style="text-align: center;">288160</td>
<td style="text-align: center;">320</td>
</tr>
<tr>
<td style="text-align: center;">1648</td>
<td style="text-align: center;">2464</td>
<td style="text-align: center;">2464</td>
<td style="text-align: center;">3264</td>
<td style="text-align: center;">32</td>
<td style="text-align: center;">128</td>
</tr>
<tr>
<td style="text-align: center;">64</td>
<td style="text-align: center;">64</td>
<td style="text-align: center;">64</td>
<td style="text-align: center;">64</td>
<td style="text-align: center;">128</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: center;"><span class="arithmatex">\(\mathbf{2 x}\)</span></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">832</td>
<td style="text-align: center;">1024</td>
</tr>
<tr>
<td style="text-align: center;"><span class="arithmatex">\(k=256\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(k=384\)</span></td>
</tr>
<tr>
<td style="text-align: center;">160320</td>
<td style="text-align: center;">192384</td>
</tr>
<tr>
<td style="text-align: center;">32128</td>
<td style="text-align: center;">48128</td>
</tr>
<tr>
<td style="text-align: center;">128</td>
<td style="text-align: center;">128</td>
</tr>
</tbody>
</table>
<h2 id="architectural-contribution-googlenet">Architectural contribution: GoogLeNet<a class="headerlink" href="#architectural-contribution-googlenet" title="Permanent link">&para;</a></h2>
<p>Demonstrated that more complex modular neural network designs can outperform VGGNet's straightforward design.</p>
<p>Together with VGGNet, demonstrated the importance of depth.</p>
<p>Kickstarted the research into deep neural network architecture design.</p>
<h2 id="batch-normalization">Batch normalization<a class="headerlink" href="#batch-normalization" title="Permanent link">&para;</a></h2>
<p>The first step of many data processing algorithms is often to normalize data to have zero mean and unit variance.</p>
<ul>
<li>Step 1. Compute <span class="arithmatex">\(\hat{\mu}=\frac{1}{N} \sum_{i=1}^{N} X_{i}, \widehat{\sigma^{2}}=\frac{1}{N} \sum_{i=1}^{N}\left(X_{i}-\hat{\mu}\right)^{2}\)</span></li>
</ul>
<div class="arithmatex">\[
\hat{X}_{i}=\frac{X_{i}-\widehat{\mu}}{\sqrt{\sigma^{2}}+\varepsilon}
\]</div>
<ul>
<li>Step 2. Run method with data <span class="arithmatex">\(\hat{X}_{1}, \ldots, \hat{X}_{N}\)</span></li>
</ul>
<p>Batch normalization (BN) (sort of) enforces this normalization layer-by-layer. BN is an indispensable tool for training very deep neural networks. Theoretical justification is weak.</p>
<h2 id="bn-for-linear-layers">BN for linear layers<a class="headerlink" href="#bn-for-linear-layers" title="Permanent link">&para;</a></h2>
<p>Underlying assumption: Each element of the batch is an IID sample.
Input: <span class="arithmatex">\(X\)</span> (batch size) <span class="arithmatex">\(\times(\#\)</span> entries)
output: <span class="arithmatex">\(\mathrm{BN}_{\beta, \gamma}(X)\)</span>. shape <span class="arithmatex">\(\left(\mathrm{BN}_{\beta, \gamma}(X)\right)=\operatorname{shape}(X)\)</span>
<span class="arithmatex">\(\mathrm{BN}_{\beta, \gamma}\)</span> for linear layers acts independently over neurons.</p>
<div class="arithmatex">\[
\begin{gathered}
\hat{\mu}[:]=\frac{1}{B} \sum_{b=1}^{B} X[b,:] \quad \text { FC } \\
\hat{\sigma}^{2}[:]=\frac{1}{B} \sum_{b=1}^{B}(X[b,:]-\hat{\mu}[:])^{2} \\
\mathrm{BN}_{\gamma, \beta}(X)[b,:]=\gamma[:] \frac{X[b,:]-\hat{\mu}[:]}{\sqrt{\hat{\sigma}^{2}[:]+\varepsilon}}+\beta[:] \quad b=1, \ldots, B
\end{gathered}
\]</div>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-213.jpg?height=341&amp;width=1145&amp;top_left_y=578&amp;top_left_x=2149" /></p>
<p>Batch Norm
<span class="arithmatex">\(\beta, \gamma\)</span>
where operations are elementwise. BN normalizes each output neuron. The mean and variance are explicitly controlled through learned parameters <span class="arithmatex">\(\beta\)</span> and <span class="arithmatex">\(\gamma\)</span>. In Pytorch, nn.BatchNorm1d.</p>
<h2 id="bn-for-convolutional-layers">BN for convolutional layers<a class="headerlink" href="#bn-for-convolutional-layers" title="Permanent link">&para;</a></h2>
<p>Underlying assumption: Each element of the batch, horizontal pixel, and vertical pixel is an IID sample.* Input: <span class="arithmatex">\(X\)</span> (batch size <span class="arithmatex">\() \times(\)</span> channels <span class="arithmatex">\() \times(\)</span> vertical dim <span class="arithmatex">\() \times(\)</span> horizontal dim <span class="arithmatex">\()\)</span> output: <span class="arithmatex">\(\mathrm{BN}_{\beta, \gamma}(X)\)</span>. shape <span class="arithmatex">\(\left(\mathrm{BN}_{\beta, \gamma}(X)\right)=\operatorname{shape}(X)\)</span> <span class="arithmatex">\(\mathrm{BN}_{\beta, \gamma}\)</span> for conv. layers acts independently over channels.</p>
<div class="arithmatex">\[
\begin{gathered}
\hat{\mu}[:]=\frac{1}{B P Q} \sum_{b=1}^{B} \sum_{i=1}^{P} \sum_{j=1}^{Q} X[b,:, i, j] \\
\hat{\sigma}^{2}[:]=\frac{1}{B P Q} \sum_{b=1}^{B} \sum_{i=1}^{P} \sum_{j=1}^{Q}(X[b,:, i, j]-\hat{\mu}[:])^{2} \\
\operatorname{BN}_{\gamma, \beta}(X)[b,:, i, j]=\gamma[:] \frac{X[b,:, i, j]-\hat{\mu}[:]}{\sqrt{\hat{\sigma}^{2}[:]+\varepsilon}}+\beta[:] \quad \begin{array}{l}
b=1, \ldots, B \\
i=1, \ldots, P \\
j=1, \ldots, Q
\end{array}
\end{gathered}
\]</div>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-214.jpg?height=384&amp;width=1161&amp;top_left_y=565&amp;top_left_x=2154" />
Batch Norm</p>
<div class="arithmatex">\[
\beta, \gamma
\]</div>
<p>BN normalizes over each convolutional filter. The mean and variance are explicitly controlled through learned parameters <span class="arithmatex">\(\beta\)</span> and <span class="arithmatex">\(\gamma\)</span>. In Pytorch, nn. BatchNorm2d.</p>
<h2 id="bn-during-testing">BN during testing<a class="headerlink" href="#bn-during-testing" title="Permanent link">&para;</a></h2>
<p><span class="arithmatex">\(\hat{\mu}\)</span> and <span class="arithmatex">\(\hat{\sigma}\)</span> are estimated from batches during training. During testing, we don't update the NN, and we may only have a single input (so no batch).
There are 2 strategies for computing final values of <span class="arithmatex">\(\hat{\mu}\)</span> and <span class="arithmatex">\(\hat{\sigma}\)</span> :</p>
<ol>
<li>After training, fix all parameters and evaluate NN on full training set to compute <span class="arithmatex">\(\hat{\mu}\)</span> and <span class="arithmatex">\(\hat{\sigma}\)</span> layer-by-layer. Store this computed value. (Computation of <span class="arithmatex">\(\hat{\mu}\)</span> and <span class="arithmatex">\(\hat{\sigma}\)</span> must be done sequentially layer-by-layer. Why?)</li>
<li>During training, compute running average of <span class="arithmatex">\(\hat{\mu}\)</span> and <span class="arithmatex">\(\hat{\sigma}\)</span>. This is the default behavior of PyTorch.
In PyTorch, use model.train() and model.eval() to switch BN behavior between training and testing.</li>
</ol>
<h2 id="discussion-of-bn">Discussion of BN<a class="headerlink" href="#discussion-of-bn" title="Permanent link">&para;</a></h2>
<p>BN does not change the representation power of NN ; since <span class="arithmatex">\(\beta\)</span> and <span class="arithmatex">\(\gamma\)</span> are trained, the output of each layer can have any mean and variance. However, controlling the mean and variance as explicit trainable parameters makes training easier.</p>
<p>With BN, the choice of batch size becomes a more important hyperparameter to tune.</p>
<p>BN is indispensable in practice. Training of VGGNet and GoogLeNet becomes much easier with BN. Training of ResNet requires BN.</p>
<h2 id="bn-and-internal-covariate-shift">BN and internal covariate shift<a class="headerlink" href="#bn-and-internal-covariate-shift" title="Permanent link">&para;</a></h2>
<p>BN has insufficient theoretical justification.
The original paper by loffe and Szegedy hypothesized that BN mitigates internal covariate shift (ICS), the shift in the mean and variance of the intermediate layer neurons throughout the training, and that this mitigation leads to improved training.</p>
<div class="arithmatex">\[
\mathrm{BN} \Rightarrow(\text { reduced ICS }) \Rightarrow \text { (improved training })
\]</div>
<p>However, Santukar et al. demonstrated that when experimentally measured, BN does not mitigate ICS, but nevertheless improves the training.</p>
<div class="arithmatex">\[
\mathrm{BN} \nRightarrow \text { (reduced ICS) }
\]</div>
<p>Nevertheless</p>
<div class="arithmatex">\[
\mathrm{BN} \Rightarrow \text { (improved training performance) }
\]</div>
<h2 id="bn-and-internal-covariate-shift_1">BN and internal covariate shift<a class="headerlink" href="#bn-and-internal-covariate-shift_1" title="Permanent link">&para;</a></h2>
<p>Santukar et al. argues that</p>
<div class="arithmatex">\[
\mathrm{BN} \Rightarrow \text { (smoother loss landscape) } \Rightarrow \text { (improved training performance) }
\]</div>
<p>While this claim is more evidence-based than that of loffe and Szegedy, it is still not conclusive. It is also unclear why BN makes the loss landscape smoother, and it is not clear whether the smoother loss landscape fully explains the improved training performance.</p>
<p>This story is a cautionary tale: we should carefully distinguish between speculative hypotheses and evidence-based claims, even in a primarily empirical subject.</p>
<h2 id="bn-has-trainable-parameters">BN has trainable parameters<a class="headerlink" href="#bn-has-trainable-parameters" title="Permanent link">&para;</a></h2>
<p>BN is usually not considered a trainable layer, much like pooling or dropout, and they are usually excluded when counting the "depth" of a NN. However, BN does have trainable parameters. Interestingly, if one randomly initializes a CNN, freezes all other parameters, and only train BN parameters, the performance is surprisingly good.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-219.jpg?height=724&amp;width=1702&amp;top_left_y=901&amp;top_left_x=731" /></p>
<p>Figure 2: Accuracy of ResNets for CIFAR-10 (top left, deep; top right, wide) and ImageNet (bottom left, top-1 accuracy; bottom right, top-5 accuracy) with different sets of parameters trainable.</p>
<h2 id="discussion-of-bn_1">Discussion of BN<a class="headerlink" href="#discussion-of-bn_1" title="Permanent link">&para;</a></h2>
<p>BN seems to also act as a regularizer, and for some reason subsumes effect Dropout. (Using dropout together with BN seems to worsen performance.) Since BN has been popularized, Dropout is used less often.*</p>
<p>After training, functionality of BN can be absorbed into the previous layer when the previous layer is a linear layer or a conv layer. (Cf. homework 6.)</p>
<p>The use of batch norm makes the scaling of weight initialization less important irrelevant.</p>
<p>Use bias=false on layers preceding BN , since <span class="arithmatex">\(\beta\)</span> subsumes the bias.</p>
<h2 id="residual-network-resnet">Residual Network (ResNet)<a class="headerlink" href="#residual-network-resnet" title="Permanent link">&para;</a></h2>
<p>Winner of 2015 ImageNet Challenge
Observation: Excluding the issue of computation cost, more layers it not always better
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-221.jpg?height=634&amp;width=1430&amp;top_left_y=593&amp;top_left_x=297" />
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-221.jpg?height=456&amp;width=724&amp;top_left_y=635&amp;top_left_x=1828" />
aeneric function classes
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-221.jpg?height=447&amp;width=647&amp;top_left_y=644&amp;top_left_x=2683" />
nested function classes</p>
<p>Hypothesis 1: Deeper networks are harder to train.
Is there a way to train a shallow network and embed it in a deeper network?
Hypothesis 2: The deeper networks may be worse approximations of the true unknown function. Find an architecture representing a strictly increasing function class as a function of depth.</p>
<h2 id="residual-blocks">Residual blocks<a class="headerlink" href="#residual-blocks" title="Permanent link">&para;</a></h2>
<p>Use a residual connection so that [all weights=0] correspond to [block=identity] <span class="arithmatex">\({ }^{*}\)</span>
regular residual block
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-222.jpg?height=733&amp;width=1452&amp;top_left_y=684&amp;top_left_x=133" />
downsampling residual block
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-222.jpg?height=711&amp;width=1315&amp;top_left_y=716&amp;top_left_x=1877" /></p>
<p>Regular block must preserve spatial dimension and number of channels.
Downsampling block halves the spatial dimension and changes the number of channels.</p>
<h2 id="resnet18">ResNet18<a class="headerlink" href="#resnet18" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-223.jpg?height=677&amp;width=3041&amp;top_left_y=614&amp;top_left_x=223" /></p>
<p>Layer count excludes BN even though BN has trainable parameters.</p>
<h2 id="resnet34">ResNet34<a class="headerlink" href="#resnet34" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-224.jpg?height=1116&amp;width=1902&amp;top_left_y=216&amp;top_left_x=1430" /></p>
<p>A trained ResNet18 architecture can be exactly fitted into a ResNet34: copy over the parameters and set parameters of the additional blocks to be 0 . The additional blocks with only serve to apply an additional ReLU, but this makes no difference as ReLU is idempotent.</p>
<h2 id="resnet-blocks-for-deeper-resnets">ResNet blocks for deeper ResNets<a class="headerlink" href="#resnet-blocks-for-deeper-resnets" title="Permanent link">&para;</a></h2>
<p>ResNet in fact goes deeper. For the deeper variants, computation cost becomes more significant. To remedy this cost, use <span class="arithmatex">\(1 \times 1\)</span> conv to reduce number of channels, perform costly <span class="arithmatex">\(3 \times 3\)</span> convolution, and use <span class="arithmatex">\(1 \times 1\)</span> conv to restore the number of channels. This bottleneck" structure is adapted from GoogLeNet.
regular residual block with bottleneck
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-225.jpg?height=635&amp;width=1588&amp;top_left_y=1026&amp;top_left_x=99" />
downsampling residual block with bottleneck
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-225.jpg?height=496&amp;width=1432&amp;top_left_y=1164&amp;top_left_x=1874" /></p>
<h2 id="resnet50-101-152">ResNet50, 101, 152<a class="headerlink" href="#resnet50-101-152" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-226.jpg?height=886&amp;width=2894&amp;top_left_y=607&amp;top_left_x=254" /></p>
<h2 id="resnet18-for-cifar10">ResNet18 for cifar10<a class="headerlink" href="#resnet18-for-cifar10" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-227.jpg?height=954&amp;width=3058&amp;top_left_y=403&amp;top_left_x=240" /></p>
<p>ResNet{34,50,101,152} for CIFAR10. The intermediate layers are the same as before.</p>
<h2 id="resnet-v15">ResNet v1.5<a class="headerlink" href="#resnet-v15" title="Permanent link">&para;</a></h2>
<p>In the bottleneck blocks performing downsampling, the use of <span class="arithmatex">\(1 \times 1\)</span> conv with stride 2 is suboptimal as the operation simply ignores <span class="arithmatex">\(75 \%\)</span> of the neurons. ResNet v 1.5 replaces them with <span class="arithmatex">\(3 \times 3\)</span> conv with stride 2 .
downsampling residual block v1
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-228.jpg?height=601&amp;width=1008&amp;top_left_y=1154&amp;top_left_x=440" />
downsampling residual block v1.5
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-228.jpg?height=827&amp;width=1493&amp;top_left_y=939&amp;top_left_x=1486" /></p>
<h2 id="resnet-v15_1">ResNet v1.5<a class="headerlink" href="#resnet-v15_1" title="Permanent link">&para;</a></h2>
<p>The fix is more important for the deeper downsampling residual blocks.
downsampling residual block with bottleneck v1
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-229.jpg?height=532&amp;width=1621&amp;top_left_y=474&amp;top_left_x=1639" />
downsampling residual block with bottleneck v1.5
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-229.jpg?height=516&amp;width=1581&amp;top_left_y=1218&amp;top_left_x=1676" /></p>
<h2 id="resnet-v2">ResNet v2<a class="headerlink" href="#resnet-v2" title="Permanent link">&para;</a></h2>
<p>Permutations of the ordering of conv, BN, and ReLU were tested. BN-ReLUconv had the best performance.</p>
<p>Perform all operations before the residual connection so that the identity mapping can be learned.
modifies residual block
BN-ReLU-conv
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-230.jpg?height=622&amp;width=1477&amp;top_left_y=1122&amp;top_left_x=1677" /></p>
<h2 id="architectural-contribution-resnet">Architectural contribution: ResNet<a class="headerlink" href="#architectural-contribution-resnet" title="Permanent link">&para;</a></h2>
<p>Introduced residual connections as a key architectural component.</p>
<p>Demonstrated that extremely deep neural networks can be trained with residual connections and BN. ResNet152 concluded the progression of depth. ImageNet challenge winners:</p>
<ul>
<li>
<ol>
<li>AlexNet with 8 layers.</li>
</ol>
</li>
<li>
<ol>
<li>ZFNet with 8 layers.</li>
</ol>
</li>
<li>
<ol>
<li>GoogLeNet with 22 layers.</li>
</ol>
</li>
<li>
<ol>
<li>ResNet152 with 152 layers.</li>
</ol>
</li>
<li>
<ol>
<li>Shao et al.. with 152 layers.</li>
</ol>
</li>
<li>
<ol>
<li>SENet with 152 layers.</li>
</ol>
</li>
</ul>
<p>Residual connections and BN are very common throughout all of deep learning.</p>
<h2 id="resnext">ResNext<a class="headerlink" href="#resnext" title="Permanent link">&para;</a></h2>
<p>2016 ImageNet challenge <span class="arithmatex">\(2^{\text {nd }}\)</span> place. Introduced cardinality as another network parameter, in addition to width (number of channels) and depth. Cardinality is the number of independent paths in the split-transform-merge structure.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-232.jpg?height=966&amp;width=3186&amp;top_left_y=784&amp;top_left_x=40" />
S. Xie, R. Girshick, P. Dollár, Z. Tu, and K. He, Aggregated residual transformations for deep neural networks, CVPR, 2017.</p>
<h2 id="resnext_1">ResNext<a class="headerlink" href="#resnext_1" title="Permanent link">&para;</a></h2>
<h2 id="equivalent">equivalent<a class="headerlink" href="#equivalent" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-233.jpg?height=622&amp;width=1021&amp;top_left_y=63&amp;top_left_x=1365" />
(a)
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-233.jpg?height=614&amp;width=911&amp;top_left_y=63&amp;top_left_x=2381" />
(b)</p>
<p>Blocks (a) and (b) almost equivalent due to the by the following observation.</p>
<p>Difference: Block (a) has 32 bias terms which are added to serve the role of the single bias term of block (b).
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-233.jpg?height=852&amp;width=1553&amp;top_left_y=854&amp;top_left_x=1605" /></p>
<h2 id="ensemble-learning">Ensemble learning<a class="headerlink" href="#ensemble-learning" title="Permanent link">&para;</a></h2>
<p>Let <span class="arithmatex">\((X, Y)\)</span> be a data-label pair. Let <span class="arithmatex">\(m_{1}, \ldots, m_{K}\)</span> be models estimating the <span class="arithmatex">\(Y\)</span> given <span class="arithmatex">\(X\)</span>.</p>
<p>An ensemble is a model</p>
<div class="arithmatex">\[
M=\theta_{1} m_{1}+\cdots+\theta_{K} m_{K}
\]</div>
<p>where <span class="arithmatex">\(\theta_{1}, \ldots, \theta_{K} \in \mathbb{R}\)</span>. Often <span class="arithmatex">\(\theta_{1}+\cdots+\theta_{K}=1\)</span> and <span class="arithmatex">\(\theta_{i} \geq 0\)</span> for <span class="arithmatex">\(i=1, \ldots, K\)</span>. (So <span class="arithmatex">\(M\)</span> is often a nonnegative weighted average <span class="arithmatex">\(m_{1}, \ldots, m_{K}\)</span>.)</p>
<p>If <span class="arithmatex">\(\theta_{1}, \ldots, \theta_{K}\)</span> is chosen well, then</p>
<div class="arithmatex">\[
\mathbb{E}_{(X, Y)}\left[\|M(X)-Y\|^{2}\right] \leq \min _{i=1, \ldots, K} \mathbb{E}_{(X, Y)}\left[\left\|m_{i}(X)-Y\right\|^{2}\right]
\]</div>
<p>(The ensemble can be worse if <span class="arithmatex">\(\theta_{1}, \ldots, \theta_{K}\)</span> is chosen poorly.)</p>
<h2 id="2016-imagenet-challenge-ensemble">2016 ImageNet Challenge ensemble<a class="headerlink" href="#2016-imagenet-challenge-ensemble" title="Permanent link">&para;</a></h2>
<p>Trimps-Soushen* won the 2016 ImageNet Challenge with an ensemble of</p>
<ul>
<li>Inception-v3[1]</li>
<li>Inception-v4 <span class="arithmatex">\({ }^{[2]}\)</span></li>
<li>Inception-Resnet-v2 <span class="arithmatex">\({ }^{[2]}\)</span></li>
<li>ResNet-200[3]</li>
<li>WRN-68-3 <span class="arithmatex">\({ }^{[4]}\)</span>
*J. Shao, X. Zhang, Z. Ding, Y. Zhao, Y. Chen, J. Zhou, W. Wang, L. Mei, and C. Hu, Trimps-Soushen, 2016.
<span class="arithmatex">\({ }^{[1]}\)</span> C. Szegedy, V. Vanhoucke, S. loffe, J. Shlens, and Z. Wojna, Rethinking the inception architecture for computer vision, CVPR, 2016.
<span class="arithmatex">\({ }^{[2]} \mathrm{C}\)</span>. Szegedy, S. loffe, V. Vanhoucke, and A. Alemi, Inception-v4, Inception-ResNet and the impact of residual connections on learning, AAAI, 2017.
<span class="arithmatex">\({ }^{[3]} \mathrm{K} . \mathrm{He}, \mathrm{X}\)</span>. Zhang, S. Ren, and J. Sun, Identity mappings in deep residual networks, ECCV, 2016.
<span class="arithmatex">\({ }^{[4]}\)</span> S. Zagoruyko and N. Komodakis, Wide residual networks, BMVC, 2016.</li>
</ul>
<h2 id="dropout-ensemble-interpretation">Dropout ensemble interpretation<a class="headerlink" href="#dropout-ensemble-interpretation" title="Permanent link">&para;</a></h2>
<p>Let <span class="arithmatex">\(m\)</span> be a model with dropout applied to <span class="arithmatex">\(K\)</span> neurons. The there are <span class="arithmatex">\(2^{K}\)</span> possible configurations, which we label <span class="arithmatex">\(m_{1}, \ldots, m_{2^{K}}\)</span>. These models share weights.</p>
<p>Dropout can be viewed as randomly selecting one of these models and updating it with an iteration of SGD.</p>
<p>Turning off dropout at test time can be interpreted and making predictions with an ensemble of these <span class="arithmatex">\(2^{K}\)</span>, since each neuron is scaled so that the neuron value has the same expectation as when dropout is applied.</p>
<p>However, this is not a very precise connection, and I am unsure as to how much to trust it.</p>
<h2 id="test-time-data-augmentation">Test-time data augmentation<a class="headerlink" href="#test-time-data-augmentation" title="Permanent link">&para;</a></h2>
<p>Test-time data augmentation is an ensemble technique to improve the prediction. (This is not a regularization or data augmentation technique)</p>
<p>Given a single model <span class="arithmatex">\(M\)</span> and input <span class="arithmatex">\(X\)</span>, make predictions with</p>
<div class="arithmatex">\[
\frac{1}{K} \sum_{i=1}^{K} M\left(T_{i}(X)\right)
\]</div>
<p>where <span class="arithmatex">\(T_{1}, \ldots, T_{K}\)</span> are random data augmentations.</p>
<p>The original AlexNet paper uses test-time data augmentation with random crops and horizontal reflections: "At test time, the network makes a prediction by extracting five ... patches ... as well as their horizontal reflections ..., and averaging the predictions made by the network's softmax layer on the ten patches." Most ImageNet classifiers use similar tricks.</p>
<h2 id="senet">SENet<a class="headerlink" href="#senet" title="Permanent link">&para;</a></h2>
<p>2017 ImageNet challenge <span class="arithmatex">\(1^{\text {st }}\)</span> place. Introduced the squeeze-and-excitation mechanism, which is referred to attention in more modern papers.</p>
<p>Attention multiplicatively reweighs channels.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-238.jpg?height=703&amp;width=3332&amp;top_left_y=1031&amp;top_left_x=1" /></p>
<h2 id="squeeze-and-excitation">Squeeze-and-excitation<a class="headerlink" href="#squeeze-and-excitation" title="Permanent link">&para;</a></h2>
<p>Squeeze is a global average pool. Excitation is a bottleneck structure with <span class="arithmatex">\(1 \times 1\)</span> convolutions and outputs weights in <span class="arithmatex">\((0,1)\)</span> by passing through sigmoid. Finally, scale each channel.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-239.jpg?height=1077&amp;width=2450&amp;top_left_y=712&amp;top_left_x=799" /></p>
<h2 id="conclusion">Conclusion<a class="headerlink" href="#conclusion" title="Permanent link">&para;</a></h2>
<p>We followed the ImageNet challenge from 2012 to 2017 and learned the foundations of the design and training of deep neural networks.</p>
<p>With the advent of deep learning, research in computer vision shifted from "feature engineering" to "network engineering". Loosely speaking, the transition was from what to learn to learn to how to learn.</p>
<p>A natural progression may be to continue studying the more recent neural network architectures, beyond the 2017 SENet. However, we will stop here to move on to learning about other machine learning tasks.</p>
<h1 id="chapter-4-cnns-for-other-supervised-learning-tasks">Chapter 4: <br> CNNs for Other Supervised Learning Tasks<a class="headerlink" href="#chapter-4-cnns-for-other-supervised-learning-tasks" title="Permanent link">&para;</a></h1>
<p>Mathematical Foundations of Deep Neural Networks
Spring 2024
Department of Mathematical Sciences
Ernest K. Ryu
Seoul National University</p>
<h2 id="inverse-problem-model">Inverse problem model<a class="headerlink" href="#inverse-problem-model" title="Permanent link">&para;</a></h2>
<p>In inverse problems, we wish to recover a signal <span class="arithmatex">\(X_{\text {true }}\)</span> given measurements <span class="arithmatex">\(Y\)</span>. The unknown and the measurements are related through</p>
<div class="arithmatex">\[
\mathcal{A}\left[X_{\text {true }}\right]+\varepsilon=Y,
\]</div>
<p>where <span class="arithmatex">\(\mathcal{A}\)</span> is often, but not always, linear, and <span class="arithmatex">\(\varepsilon\)</span> represents small error.</p>
<p>The forward model <span class="arithmatex">\(\mathcal{A}\)</span> may or may not be known. In other words, the goal of an inverse problem is to find an approximation of <span class="arithmatex">\(\mathcal{A}^{-1}\)</span>.</p>
<p>In many cases, <span class="arithmatex">\(\mathcal{A}\)</span> is not even be invertible. In such cases, we can still hope to find an mapping that serves as an approximate inverse in practice.</p>
<h2 id="gaussian-denoising">Gaussian denoising<a class="headerlink" href="#gaussian-denoising" title="Permanent link">&para;</a></h2>
<p>Given <span class="arithmatex">\(X_{\text {true }} \in \mathbb{R}^{w \times h}\)</span>, we measure</p>
<div class="arithmatex">\[
Y=X_{\text {true }}+\varepsilon
\]</div>
<p>where <span class="arithmatex">\(\varepsilon_{i j} \sim \mathcal{N}\left(0, \sigma^{2}\right)\)</span> is IID Gaussian noise. For the sake of simplicity, assume we know <span class="arithmatex">\(\sigma\)</span>. Goal is to recover <span class="arithmatex">\(X_{\text {true }}\)</span> from <span class="arithmatex">\(Y\)</span>.</p>
<p>Guassian denoising is the simplest setup in which the goal is to remove noise from the image. In more realistic setups, the noise model will be more complicated and the noise level <span class="arithmatex">\(\sigma\)</span> will be unknown.</p>
<h2 id="dncnn">DnCNN<a class="headerlink" href="#dncnn" title="Permanent link">&para;</a></h2>
<p>In 2017, Zhang et al. presented the denoising convolutional neural networks (DnCNNs). They trained a 17-layer CNN <span class="arithmatex">\(f_{\theta}\)</span> to learn the noise with the loss</p>
<div class="arithmatex">\[
\mathcal{L}(\theta)=\sum_{i=1}^{N}\left\|f_{\theta}\left(Y_{i}\right)-\left(Y_{i}-X_{i}\right)\right\|^{2}
\]</div>
<p>so that the clean recovery can be obtained with <span class="arithmatex">\(Y_{i}-f_{\theta}\left(Y_{i}\right)\)</span>. (This is equivalent to using a residual connection from beginning to end.)
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-244.jpg?height=626&amp;width=1502&amp;top_left_y=1141&amp;top_left_x=1520" /></p>
<h2 id="dncnn_1">DnCNN<a class="headerlink" href="#dncnn_1" title="Permanent link">&para;</a></h2>
<p>Image denoising is was an area with a large body of prior work. DnCNN dominated all prior approaches that were not based on deep learning.</p>
<p>Nowadays, all state-of-the-art denoising algorithms are based on deep learning.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-245.jpg?height=1690&amp;width=1663&amp;top_left_y=65&amp;top_left_x=1669" /></p>
<h2 id="inverse-problems-via-deep-learning">Inverse problems via deep learning<a class="headerlink" href="#inverse-problems-via-deep-learning" title="Permanent link">&para;</a></h2>
<p>In deep learning, we use a neural network to approximate the inverse mapping</p>
<div class="arithmatex">\[
f_{\theta} \approx \mathcal{A}^{-1}
\]</div>
<p>i.e., we want <span class="arithmatex">\(f_{\theta}(Y) \approx X_{\text {true }}\)</span> for the measurements <span class="arithmatex">\(X\)</span> that we care about.</p>
<p>If we have <span class="arithmatex">\(X_{1}, \ldots, X_{N}\)</span> and <span class="arithmatex">\(Y_{1}, \ldots, Y_{N}\)</span> (but no direct knowledge of <span class="arithmatex">\(\mathcal{A}\)</span> ), we can solve</p>
<div class="arithmatex">\[
\underset{\theta \in \mathbb{R}^{\boldsymbol{P}}}{\operatorname{minimize}} \sum_{i=1}^{N}\left\|f_{\theta}\left(Y_{i}\right)-X_{i}\right\|
\]</div>
<p>If we have <span class="arithmatex">\(X_{1}, \ldots, X_{N}\)</span> and knowledge of <span class="arithmatex">\(\mathcal{A}\)</span>, we can solve</p>
<div class="arithmatex">\[
\operatorname{minimize}_{\theta \in \mathbb{R}^{\mathfrak{P}}} \sum_{i=1}^{N}\left\|f_{\theta}\left[\mathcal{A}\left(X_{i}\right)\right]-X_{i}\right\|
\]</div>
<p>If we have <span class="arithmatex">\(Y_{1}, \ldots, Y_{N}\)</span> and knowledge of <span class="arithmatex">\(\mathcal{A}\)</span>, we can solve</p>
<div class="arithmatex">\[
\underset{\theta \in \mathbb{R}^{\mathcal{P}}}{\operatorname{minimize}} \sum_{i=1}^{N}\left\|\mathcal{A}\left[f_{\theta}\left(Y_{i}\right)\right]-Y_{i}\right\|
\]</div>
<h2 id="image-super-resolution">Image super-resolution<a class="headerlink" href="#image-super-resolution" title="Permanent link">&para;</a></h2>
<p>Given <span class="arithmatex">\(X_{\text {true }} \in \mathbb{R}^{w \times h}\)</span>, we measure</p>
<div class="arithmatex">\[
Y=\mathcal{A}\left(X_{\text {true }}\right)
\]</div>
<p>where <span class="arithmatex">\(\mathcal{A}\)</span> is a "downsampling" operator. So <span class="arithmatex">\(Y \in \mathbb{R}^{w_{2} \times h_{2}}\)</span> with <span class="arithmatex">\(w_{2}&lt;w\)</span> and <span class="arithmatex">\(h_{2}&lt;h\)</span>. Goal is to recover <span class="arithmatex">\(X_{\text {true }}\)</span> from <span class="arithmatex">\(Y\)</span>.</p>
<p>In the simplest setup, <span class="arithmatex">\(\mathcal{A}\)</span> is an average pool operator with <span class="arithmatex">\(r \times r\)</span> kernel and a stride <span class="arithmatex">\(r\)</span>.</p>
<h2 id="srcnn">SRCNN<a class="headerlink" href="#srcnn" title="Permanent link">&para;</a></h2>
<p>In 2015, Dong et al. presented super-resolution convolutional neural network (SRCNN). They trained a 3-layer <span class="arithmatex">\(\operatorname{CNN} f_{\theta}\)</span> to learn the high-resolution reconstruction with the loss</p>
<div class="arithmatex">\[
\mathcal{L}(\theta)=\sum_{i=1}^{N}\left\|f_{\theta}\left(\tilde{Y}_{i}\right)-X_{i}\right\|^{2}
\]</div>
<p>where <span class="arithmatex">\(\tilde{Y}_{i} \in \mathbb{R}^{w \times h}\)</span> is an upsampled version of <span class="arithmatex">\(Y_{i} \in \mathbb{R}^{(w / r) \times(h / r)}\)</span>, i.e., <span class="arithmatex">\(\tilde{Y}_{i}\)</span> has the same number of pixels as <span class="arithmatex">\(X_{i}\)</span>, but the image is pixelated or blurry. The goal is to have <span class="arithmatex">\(f_{\theta}\left(\tilde{Y}_{i}\right)\)</span> be a sharp reconstruction.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-248.jpg?height=630&amp;width=1697&amp;top_left_y=1131&amp;top_left_x=980" /></p>
<h2 id="srcnn_1">SRCNN<a class="headerlink" href="#srcnn_1" title="Permanent link">&para;</a></h2>
<p>SRCNN showed that simple learning based approaches can match the state-of theart performances of superresolution task.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-249.jpg?height=1205&amp;width=1201&amp;top_left_y=435&amp;top_left_x=2036" /></p>
<h2 id="vdsr">VDSR<a class="headerlink" href="#vdsr" title="Permanent link">&para;</a></h2>
<p>In 2016, Kim et al. presented VDSR. They trained a 20-layer CNN with a residual connection <span class="arithmatex">\(f_{\theta}\)</span> to learn the high-resolution reconstruction with the loss</p>
<div class="arithmatex">\[
\mathcal{L}(\theta)=\sum_{i=1}^{N}\left\|f_{\theta}\left(\tilde{Y}_{i}\right)-X_{i}\right\|^{2}
\]</div>
<p>The residual connection was the key insight that enabled the training of much deeper CNNs.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-250.jpg?height=734&amp;width=1420&amp;top_left_y=1015&amp;top_left_x=1511" /></p>
<h2 id="vdsr_1">VDSR<a class="headerlink" href="#vdsr_1" title="Permanent link">&para;</a></h2>
<p>VDSR dominated all prior approaches not based on deep learning.
showed that simple learning based approaches can batch the state-of theart performances of super-resolution task.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-251.jpg?height=1630&amp;width=1655&amp;top_left_y=27&amp;top_left_x=1673" /></p>
<h2 id="other-inverse-problem-tasks-and-results">Other inverse problem tasks and results<a class="headerlink" href="#other-inverse-problem-tasks-and-results" title="Permanent link">&para;</a></h2>
<p>There are many other inverse problems. Almost all of them now require deep neural networks to achieve state-of-the-art results.</p>
<p>We won't spend more time on inverse problems in this course, but let's have fun and see a few other tasks and results. (These results are based on much more complex architectures and loss functions.)</p>
<h2 id="srgan">SRGAN<a class="headerlink" href="#srgan" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-253.jpg?height=1366&amp;width=945&amp;top_left_y=363&amp;top_left_x=225" />
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-253.jpg?height=1320&amp;width=907&amp;top_left_y=369&amp;top_left_x=1171" /></p>
<p>SRGAN
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-253.jpg?height=1362&amp;width=920&amp;top_left_y=369&amp;top_left_x=2113" />
C. Ledig, L. Theis, F. Huszar, J. Caballero, A. Cunningham, A. Acosta, A. Aitken, A. Tejani, J. Totz, Z. Wang, and W. Shi, Photo-realistic single image super-resolution using a generative adversarial network, CVPR, 2017.</p>
<h2 id="srgan_1">SRGAN<a class="headerlink" href="#srgan_1" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-254.jpg?height=903&amp;width=1110&amp;top_left_y=637&amp;top_left_x=0" />
bicubic interpolation
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-254.jpg?height=894&amp;width=1116&amp;top_left_y=642&amp;top_left_x=1109" /></p>
<p>SRGAN
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-254.jpg?height=890&amp;width=1094&amp;top_left_y=644&amp;top_left_x=2234" />
ground truth</p>
<h2 id="srgan_2">SRGAN<a class="headerlink" href="#srgan_2" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-255.jpg?height=996&amp;width=3190&amp;top_left_y=561&amp;top_left_x=59" /></p>
<h2 id="image-colorization">Image colorization<a class="headerlink" href="#image-colorization" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-256.jpg?height=1409&amp;width=2055&amp;top_left_y=333&amp;top_left_x=588" />
R. Zhang, P. Isola, and A. A. Efros, Colorful image colorization, ECCV, 2016.</p>
<h2 id="image-inpainting">Image inpainting<a class="headerlink" href="#image-inpainting" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-257.jpg?height=1141&amp;width=3332&amp;top_left_y=497&amp;top_left_x=0" /></p>
<h2 id="image-inpainting_1">Image inpainting<a class="headerlink" href="#image-inpainting_1" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-258.jpg?height=1354&amp;width=2025&amp;top_left_y=416&amp;top_left_x=399" /></p>
<h2 id="linear-operator-cong-matrix">Linear operator <span class="arithmatex">\(\cong\)</span> matrix<a class="headerlink" href="#linear-operator-cong-matrix" title="Permanent link">&para;</a></h2>
<p>Core tenet of linear algebra: matrices are linear operators and linear operators are matrices.</p>
<p>Let <span class="arithmatex">\(f: \mathbb{R}^{n} \rightarrow \mathbb{R}^{m}\)</span> be linear, i.e.,</p>
<div class="arithmatex">\[
f(x+y)=f(x)+f(y) \text { and } f(\alpha x)=\alpha f(x)
\]</div>
<p>for all <span class="arithmatex">\(x, y \in \mathbb{R}^{n}\)</span> and <span class="arithmatex">\(\alpha \in \mathbb{R}\)</span>.</p>
<p>There exists a matrix <span class="arithmatex">\(A \in \mathbb{R}^{m \times n}\)</span> that represents <span class="arithmatex">\(f: \mathbb{R}^{n} \rightarrow \mathbb{R}^{m}\)</span>, i.e.,</p>
<div class="arithmatex">\[
f(x)=A x
\]</div>
<p>for all <span class="arithmatex">\(x \in \mathbb{R}^{n}\)</span>.</p>
<h2 id="linear-operator-cong-matrix_1">Linear operator <span class="arithmatex">\(\cong\)</span> matrix<a class="headerlink" href="#linear-operator-cong-matrix_1" title="Permanent link">&para;</a></h2>
<p>Let <span class="arithmatex">\(e_{i}\)</span> be the <span class="arithmatex">\(i\)</span>-th unit vector, i.e., <span class="arithmatex">\(e_{i}\)</span> has all zeros elements except entry 1 in the <span class="arithmatex">\(i\)</span>-th coordinate.</p>
<p>Given a linear <span class="arithmatex">\(f: \mathbb{R}^{n} \rightarrow \mathbb{R}^{m}\)</span>, we can find the matrix</p>
<div class="arithmatex">\[
A=\left[\begin{array}{llll}
A_{;, 1} &amp; A_{;, 2} &amp; \cdots &amp; A_{;, n}
\end{array}\right] \in \mathbb{R}^{m \times n}
\]</div>
<p>representing <span class="arithmatex">\(f\)</span> with</p>
<div class="arithmatex">\[
f\left(e_{j}\right)=A e_{j}=A_{;, j}
\]</div>
<p>for all <span class="arithmatex">\(j=1, \ldots, n\)</span>, or with</p>
<div class="arithmatex">\[
e_{i}^{\top} f\left(e_{j}\right)=e_{i}^{\top} A e_{j}=A_{i, j}
\]</div>
<p>for all <span class="arithmatex">\(i=1, \ldots, m\)</span> and <span class="arithmatex">\(j=1, \ldots, n\)</span>.</p>
<h2 id="linear-operator-not-neq-matrix">Linear operator <span class="arithmatex">\(\not \neq\)</span> matrix<a class="headerlink" href="#linear-operator-not-neq-matrix" title="Permanent link">&para;</a></h2>
<p>In applied mathematics and machine learning, there are many setups where explicitly forming the matrix representation <span class="arithmatex">\(A \in \mathbb{R}^{m \times n}\)</span> is costly, even though the matrix-vector products <span class="arithmatex">\(A x\)</span> and <span class="arithmatex">\(A^{\top} y\)</span> are efficient to evaluate.</p>
<p>In machine learning, convolutions are the primary example. Other areas, linear operators based on FFTs are the primary example.</p>
<p>In such setups, the matrix representation is still a useful conceptual tool, even if we never intend to form the matrix.</p>
<h2 id="transpose-adjoint-of-a-linear-operator">Transpose (adjoint) of a linear operator<a class="headerlink" href="#transpose-adjoint-of-a-linear-operator" title="Permanent link">&para;</a></h2>
<p>Given a matrix <span class="arithmatex">\(A\)</span>, the transpose <span class="arithmatex">\(A^{\top}\)</span> is obtained by flipping the row and column dimensions, i.e., <span class="arithmatex">\(\left(A^{\top}\right)_{i j}=(A)_{j i}\)</span>. However, using this definition is not always the most effective when understanding the action of <span class="arithmatex">\(A^{\top}\)</span>.</p>
<p>Another approach is to use the adjoint view. Since</p>
<div class="arithmatex">\[
y^{\top}(A x)=\left(A^{\top} y\right)^{\top} x
\]</div>
<p>for any <span class="arithmatex">\(x \in \mathbb{R}^{n}\)</span> and <span class="arithmatex">\(y \in \mathbb{R}^{m}\)</span>, understand the action of <span class="arithmatex">\(A^{\top}\)</span> by finding an expression of the form</p>
<div class="arithmatex">\[
y^{\top} A x=\sum_{j=1}^{n}(\text { something })_{j} x_{j}=\left(A^{\top} y\right)^{\top} x
\]</div>
<h2 id="example-1d-transpose-convolution">Example: 1D transpose convolution<a class="headerlink" href="#example-1d-transpose-convolution" title="Permanent link">&para;</a></h2>
<p>Consider the 1D convolution represented by <span class="arithmatex">\(A \in \mathbb{R}^{(n-f+1) \times n}\)</span> defined with a given <span class="arithmatex">\(w \in \mathbb{R}^{f}\)</span> and</p>
<div class="arithmatex">\[
A=\left[\begin{array}{cccccccc}
w_{1} &amp; \cdots &amp; w_{f} &amp; 0 &amp; \cdots &amp; &amp; &amp; 0 \\
0 &amp; w_{1} &amp; \cdots &amp; w_{f} &amp; 0 &amp; \cdots &amp; &amp; 0 \\
0 &amp; 0 &amp; w_{1} &amp; \cdots &amp; w_{f} &amp; 0 &amp; \cdots &amp; 0 \\
\vdots &amp; &amp; &amp; \ddots &amp; &amp; \ddots &amp; &amp; \vdots \\
0 &amp; &amp; \cdots &amp; 0 &amp; w_{1} &amp; \cdots &amp; w_{f} &amp; 0 \\
0 &amp; &amp; \cdots &amp; 0 &amp; 0 &amp; w_{1} &amp; \cdots &amp; w_{f}
\end{array}\right]
\]</div>
<p>Then we have</p>
<div class="arithmatex">\[
(A x)_{j}=\sum_{i=1}^{f} w_{i} x_{j+i-1}
\]</div>
<h2 id="example-1d-transpose-convolution_1">Example: 1D transpose convolution<a class="headerlink" href="#example-1d-transpose-convolution_1" title="Permanent link">&para;</a></h2>
<p>and we have the following formula which coincides with transposing the matrix <span class="arithmatex">\(A\)</span>.</p>
<div class="arithmatex">\[
\begin{aligned}
y^{\top} A x &amp; =\sum_{j=1}^{n-f+1} y_{j} \sum_{i=1}^{f} w_{i} x_{j+i-1} \\
&amp; =\sum_{j=1}^{n-f+1} \sum_{i=1}^{f} y_{j} w_{i} x_{j+i-1} \sum_{k=1}^{n} \mathbf{1}_{\{k=j+i-1\}}
\end{aligned}
\]</div>
<div class="arithmatex">\[
=\sum_{k=1}^{n} \sum_{j=1}^{n-f+1} \sum_{i=1}^{f} y_{j} w_{i} x_{k} \mathbf{1}_{\{k-j+1=i\}}
\]</div>
<div class="arithmatex">\[
=\sum_{k=1}^{n} x_{k} \sum_{j=1}^{n-f+1} \sum_{i=1}^{f} w_{k-j+1} y_{j} \mathbf{1}_{\{k-j+1=i\}}
\]</div>
<div class="arithmatex">\[
=\sum_{k=1}^{n} x_{k} \sum_{j=1}^{n-f+1} w_{k-j+1} y_{j} \sum_{i=1}^{f} \mathbf{1}_{\{k-j+1=i\}}
\]</div>
<div class="arithmatex">\[
=\sum_{k=1}^{n} x_{k} \sum_{j=1}^{n-f+1} w_{k-j+1} y_{j} \mathbf{1}_{\{1 \leq k-j+1 \leq f\}}
\]</div>
<div class="arithmatex">\[
=\sum_{k=1}^{n} x_{k} \sum_{j=1}^{n-f+1} w_{k-j+1} y_{j} \mathbf{1}_{\{j \leq k\}} \mathbf{1}_{\{k-f+1 \leq j\}}
\]</div>
<div class="arithmatex">\[
=\sum_{k=1}^{n} x_{k} \sum_{j=\max (k-f+1,1)}^{\min (n-f+1, k)} w_{k-j+1} y_{j}=\left(A^{\top} y\right)^{\top} x
\]</div>
<h2 id="operations-increasing-spatial-dimensions">Operations increasing spatial dimensions<a class="headerlink" href="#operations-increasing-spatial-dimensions" title="Permanent link">&para;</a></h2>
<p>In image classification tasks, the spatial dimensions of neural networks often decrease as the depth progresses.</p>
<p>This is because we are trying to forget location information. (In classification, we care about what is in the image, but we do not where it is in the image.)</p>
<p>However, there are many networks for which we want to increase the spatial dimension:</p>
<ul>
<li>Linear layers</li>
<li>Upsampling</li>
<li>Transposed convolution</li>
</ul>
<h2 id="upsampling-nearest-neighbor">Upsampling: Nearest neighbor<a class="headerlink" href="#upsampling-nearest-neighbor" title="Permanent link">&para;</a></h2>
<p>torch.nn.Upsample with mode='nearest'
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-266.jpg?height=681&amp;width=1863&amp;top_left_y=710&amp;top_left_x=1029" /></p>
<h2 id="upsampling-bilinear-interpolation">Upsampling: Bilinear interpolation<a class="headerlink" href="#upsampling-bilinear-interpolation" title="Permanent link">&para;</a></h2>
<p>Torch.nn.Upsample with mode='bilinear'
(We won't pay attention to the interpolation formula.)
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-267.jpg?height=443&amp;width=1028&amp;top_left_y=833&amp;top_left_x=1024" />
'linear' interpolation is available for 1D data 'trilinear' interpolation is available for 3D data</p>
<table>
<thead>
<tr>
<th style="text-align: left;">6.0000</th>
<th style="text-align: left;">6.5000</th>
<th style="text-align: left;">7.5000</th>
<th style="text-align: left;">8.0000</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">5.2500</td>
<td style="text-align: left;">5.6875</td>
<td style="text-align: left;">6.5625</td>
<td style="text-align: left;">7.0000</td>
</tr>
<tr>
<td style="text-align: left;">3.7500</td>
<td style="text-align: left;">4.0625</td>
<td style="text-align: left;">4.6875</td>
<td style="text-align: left;">5.0000</td>
</tr>
<tr>
<td style="text-align: left;">3.0000</td>
<td style="text-align: left;">3.2500</td>
<td style="text-align: left;">3.7500</td>
<td style="text-align: left;">4.0000</td>
</tr>
</tbody>
</table>
<h2 id="transposed-convolution">Transposed convolution<a class="headerlink" href="#transposed-convolution" title="Permanent link">&para;</a></h2>
<p>In transposed convolution, input neurons additively distribute values to the output via the kernel.</p>
<p>Before people noticed that this is the transpose</p>
<p>Input
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-268.jpg?height=239&amp;width=252&amp;top_left_y=918&amp;top_left_x=1728" /></p>
<p>Kernel
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-268.jpg?height=252&amp;width=252&amp;top_left_y=912&amp;top_left_x=2460" /></p>
<p>Output
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-268.jpg?height=379&amp;width=1804&amp;top_left_y=1320&amp;top_left_x=1099" /></p>
<table>
<thead>
<tr>
<th style="text-align: left;">0</th>
<th style="text-align: center;">0</th>
<th style="text-align: center;">1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">0</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">6</td>
</tr>
<tr>
<td style="text-align: left;">4</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">9</td>
</tr>
</tbody>
</table>
<h2 id="transposed-convolution_1">Transposed convolution<a class="headerlink" href="#transposed-convolution_1" title="Permanent link">&para;</a></h2>
<p>Input
Kernel
For each input neuron, multiply the kernel and add (accumulate) the value in the output.</p>
<p>Can accommodate strides, padding, and multiple channels.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-269.jpg?height=413&amp;width=430&amp;top_left_y=882&amp;top_left_x=1214" />
<span class="arithmatex">\(+\)</span>
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-269.jpg?height=421&amp;width=433&amp;top_left_y=878&amp;top_left_x=1757" />
<span class="arithmatex">\(+\)</span>
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-269.jpg?height=409&amp;width=448&amp;top_left_y=884&amp;top_left_x=2302" />
<span class="arithmatex">\(+\)</span>
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-269.jpg?height=405&amp;width=430&amp;top_left_y=886&amp;top_left_x=2864" />
<span class="arithmatex">\(=\)</span></p>
<table>
<thead>
<tr>
<th style="text-align: left;">0</th>
<th style="text-align: left;">0</th>
<th style="text-align: left;">0</th>
<th style="text-align: left;">1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">3</td>
</tr>
<tr>
<td style="text-align: left;">0</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">3</td>
</tr>
<tr>
<td style="text-align: left;">4</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">9</td>
</tr>
</tbody>
</table>
<h2 id="convolution-visualized">Convolution visualized<a class="headerlink" href="#convolution-visualized" title="Permanent link">&para;</a></h2>
<h2 id="transpose-convolution-visualized">Transpose convolution visualized<a class="headerlink" href="#transpose-convolution-visualized" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-271.jpg?height=1085&amp;width=1039&amp;top_left_y=495&amp;top_left_x=1071" /></p>
<h2 id="2d-trans-conv-iayer-formal-definition">2D trans. Conv. Iayer: Formal definition<a class="headerlink" href="#2d-trans-conv-iayer-formal-definition" title="Permanent link">&para;</a></h2>
<p>Input tensor: <span class="arithmatex">\(Y \in \mathbb{R}^{B \times C_{\mathrm{in}} \times m \times n}, B\)</span> batch size, <span class="arithmatex">\(C_{\mathrm{in}} \#\)</span> of input channels.
Output tensor: <span class="arithmatex">\(X \in \mathbb{R}^{B \times C_{\text {out }} \times\left(m+f_{1}-1\right) \times\left(n+f_{2}-1\right)}, B\)</span> batch size, <span class="arithmatex">\(C_{\text {out }} \#\)</span> of output channels, <span class="arithmatex">\(m, n \#\)</span> of vertical and horizontal indices.
Filter <span class="arithmatex">\(w \in \mathbb{R}^{C_{\text {in }} \times C_{\text {out }} \times f_{1} \times f_{2}}\)</span>, bias <span class="arithmatex">\(b \in \mathbb{R}^{C_{\text {out }}}\)</span>. (If bias=False, then <span class="arithmatex">\(b=0\)</span>.)</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a>def trans_conv(Y, w, b):
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a>    c_in, c_out, f1, f2 = w.shape
</span><span id="__span-9-3"><a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a>    batch, c_in, m, n = Y.shape
</span><span id="__span-9-4"><a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a>    X = torch.zeros(batch, c_out, m + f1 - 1, n + f2 - 1)
</span><span id="__span-9-5"><a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a>    for k in range(c_in):
</span><span id="__span-9-6"><a id="__codelineno-9-6" name="__codelineno-9-6" href="#__codelineno-9-6"></a>        for i in range(Y.shape[2]):
</span><span id="__span-9-7"><a id="__codelineno-9-7" name="__codelineno-9-7" href="#__codelineno-9-7"></a>            for j in range(Y.shape[3]):
</span><span id="__span-9-8"><a id="__codelineno-9-8" name="__codelineno-9-8" href="#__codelineno-9-8"></a>                X[:, :, i:i+f1, j:j+f2] += Y[:, k, i, j].view(-1,1,1,1)*w[k, :, :, :].unsqueeze(0)
</span><span id="__span-9-9"><a id="__codelineno-9-9" name="__codelineno-9-9" href="#__codelineno-9-9"></a>    return X + b.view(1,-1,1,1)
</span></code></pre></div>
<h2 id="dependency-by-sparsity-pattern">Dependency by sparsity pattern<a class="headerlink" href="#dependency-by-sparsity-pattern" title="Permanent link">&para;</a></h2>
<p>In a matrix representation <span class="arithmatex">\(A\)</span> of convolution. The dependencies of the inputs and outputs are represented by the non-zeros of <span class="arithmatex">\(A\)</span>, i.e., the sparsity pattern of <span class="arithmatex">\(A\)</span>.
If <span class="arithmatex">\(A_{i j}=0\)</span>, then input neuron <span class="arithmatex">\(j\)</span> does not affect the output neuron <span class="arithmatex">\(i\)</span>. If <span class="arithmatex">\(A_{i j} \neq 0\)</span>, then <span class="arithmatex">\(\left(A^{\top}\right)_{j i} \neq 0\)</span>. So if input neuron <span class="arithmatex">\(j\)</span> affects output neuron <span class="arithmatex">\(i\)</span> in convolution, then input neuron <span class="arithmatex">\(i\)</span> affects output neuron <span class="arithmatex">\(j\)</span> in transposed convolution.</p>
<p>We can combine this reasoning with our visual understanding of convolution. The diagram simultaneously illustrates the dependencies for both convolution and transposed convolution.</p>
<p>Input for conv
Output for trans.conv
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-273.jpg?height=775&amp;width=1174&amp;top_left_y=646&amp;top_left_x=2156" /></p>
<p>Output for conv Input for trans.conv.</p>
<h2 id="semantic-segmentation">Semantic segmentation<a class="headerlink" href="#semantic-segmentation" title="Permanent link">&para;</a></h2>
<p>In semantic
segmentation, the goal is to segment the image into semantically meaningful regions by classifying each pixel.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-274.jpg?height=1219&amp;width=1944&amp;top_left_y=372&amp;top_left_x=1146" />
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-274.jpg?height=231&amp;width=2055&amp;top_left_y=1628&amp;top_left_x=1158" /></p>
<h2 id="other-related-tasks">Other related tasks<a class="headerlink" href="#other-related-tasks" title="Permanent link">&para;</a></h2>
<p>Object localization localizes a single object usually via a bounding box.</p>
<p>Object detection detects many objects, with the same class often repeated, usually via bounding boxes.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-275.jpg?height=520&amp;width=626&amp;top_left_y=369&amp;top_left_x=1762" /></p>
<p>CAT
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-275.jpg?height=532&amp;width=613&amp;top_left_y=372&amp;top_left_x=2381" /></p>
<p>CAT
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-275.jpg?height=813&amp;width=1251&amp;top_left_y=1056&amp;top_left_x=1760" /></p>
<h2 id="other-related-tasks_1">Other related tasks<a class="headerlink" href="#other-related-tasks_1" title="Permanent link">&para;</a></h2>
<p>Instance segmentation distinguishes multiple instances of the same object type.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-276.jpg?height=481&amp;width=1230&amp;top_left_y=678&amp;top_left_x=406" /></p>
<p>Image Recognition
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-276.jpg?height=478&amp;width=1243&amp;top_left_y=1292&amp;top_left_x=395" /></p>
<p>Object Detection
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-276.jpg?height=486&amp;width=1235&amp;top_left_y=671&amp;top_left_x=1696" /></p>
<p>Semantic Segmentation
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-276.jpg?height=486&amp;width=1239&amp;top_left_y=1288&amp;top_left_x=1694" /></p>
<p>Instance Segmentation</p>
<h2 id="pascal-voc">Pascal VOC<a class="headerlink" href="#pascal-voc" title="Permanent link">&para;</a></h2>
<p>We will use PASCAL Visual Object Classes (VOC) dataset for semantic segmentation.
(Dataset also contains labels for object detection.)</p>
<p>There are 21 classes: 20 main classes and 1 "unlabeled" class.</p>
<p>Data <span class="arithmatex">\(X_{1}, \ldots, X_{N} \in \mathbb{R}^{3 \times m \times n}\)</span> and labels <span class="arithmatex">\(Y_{1}, \ldots, Y_{N} \in\{0,1, \ldots, 20\}^{m \times n}\)</span>, i.e., <span class="arithmatex">\(Y_{i}\)</span> provides a class label for every pixel of <span class="arithmatex">\(X_{i}\)</span>.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-277.jpg?height=1667&amp;width=864&amp;top_left_y=0&amp;top_left_x=2468" />
image</p>
<h2 id="loss-for-semantic-segmentation">Loss for semantic segmentation<a class="headerlink" href="#loss-for-semantic-segmentation" title="Permanent link">&para;</a></h2>
<p>Consider the neural network</p>
<div class="arithmatex">\[
f_{\theta}: \mathbb{R}^{3 \times m \times n} \rightarrow \mathbb{R}^{k \times m \times n}
\]</div>
<p>such that <span class="arithmatex">\(\mu\left(f_{\theta}(X)\right)_{i j} \in \Delta^{k}\)</span> is the probabilities for the <span class="arithmatex">\(k\)</span> classes for pixel <span class="arithmatex">\((i, j)\)</span>.</p>
<p>We minimize the sum of pixel-wise cross-entropy losses</p>
<div class="arithmatex">\[
\mathcal{L}(\theta)=\sum_{l=1}^{N} \sum_{i=1}^{m} \sum_{j=1}^{n} \ell^{\mathrm{CE}}\left(f_{\theta}\left(X_{l}\right)_{i j},\left(Y_{l}\right)_{i j}\right)
\]</div>
<p>where <span class="arithmatex">\(\ell^{C E}\)</span> is the cross entropy loss.</p>
<h2 id="u-net">U-Net<a class="headerlink" href="#u-net" title="Permanent link">&para;</a></h2>
<p>The U-Net architecture:</p>
<ul>
<li>Reduce the spatial dimension to obtain high-level (coarse scale) features</li>
<li>Upsample or transpose convolution to restore spatial dimension.</li>
<li>Use residual connections across each dimension reduction stage.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-279.jpg?height=1727&amp;width=1999&amp;top_left_y=0&amp;top_left_x=1331" /></li>
</ul>
<h2 id="magnetic-resonance-imaging">Magnetic resonance imaging<a class="headerlink" href="#magnetic-resonance-imaging" title="Permanent link">&para;</a></h2>
<p>Magnetic resonance imaging (MRI) is an inverse problem in which we partially* measure the Fourier transform of the patient and the goal is to reconstruct the patient's image.</p>
<p>So <span class="arithmatex">\(X_{\text {true }} \in \mathbb{R}^{n}\)</span> is the true original image (reshaped into a vector) with <span class="arithmatex">\(n\)</span> pixels or voxels and <span class="arithmatex">\(\mathcal{A}\left[X_{\text {true }}\right] \in \mathbb{C}^{k}\)</span> with <span class="arithmatex">\(k \ll n\)</span>. (If <span class="arithmatex">\(k=n\)</span>, MRI scan can take hours.)</p>
<p>Classical reconstruction algorithms rely on Fourier analysis, total variation regularization, compressed sensing, and optimization.</p>
<p>Recent state-of-the-art use deep neural networks.</p>
<h2 id="fastmri-dataset">fastMRI dataset<a class="headerlink" href="#fastmri-dataset" title="Permanent link">&para;</a></h2>
<p>A team of researchers from Facebook AI Research and NYU released a large MRI dataset to stimulate datadriven deep learning research for MRI reconstruction.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-281.jpg?height=1124&amp;width=1702&amp;top_left_y=514&amp;top_left_x=1318" /></p>
<h2 id="u-net-for-inverse-problems">U-Net for inverse problems<a class="headerlink" href="#u-net-for-inverse-problems" title="Permanent link">&para;</a></h2>
<p>Although U-Net was originally proposed as an architecture for semantic segmentation, it is also being used widely as one of the default architectures in inverse problems, including MRI reconstruction.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-282.jpg?height=966&amp;width=2233&amp;top_left_y=699&amp;top_left_x=1095" /></p>
<h2 id="computational-tomography">Computational tomography<a class="headerlink" href="#computational-tomography" title="Permanent link">&para;</a></h2>
<p>Computational tomography (CT) is an inverse problem in which we partially* measure the Radon transform of the patient and the goal is to reconstruct the patient's image.</p>
<p>So <span class="arithmatex">\(X_{\text {true }} \in \mathbb{R}^{n}\)</span> is the true original image (reshaped into a vector) with <span class="arithmatex">\(n\)</span> pixels or voxels and <span class="arithmatex">\(\mathcal{A}\left[X_{\text {true }}\right] \in \mathbb{R}^{k}\)</span> with <span class="arithmatex">\(k \ll n\)</span>. (If <span class="arithmatex">\(k=n\)</span>, the X -ray exposure to perform the CT scan can be harmful.)</p>
<p>Recent state-of-the-art use deep neural networks.</p>
<h2 id="u-net-for-ct-reconstruction">U-Net for CT reconstruction<a class="headerlink" href="#u-net-for-ct-reconstruction" title="Permanent link">&para;</a></h2>
<p>U-Net is also used as one of the default architectures in CT reconstruction
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-284.jpg?height=1115&amp;width=3271&amp;top_left_y=612&amp;top_left_x=57" /></p>
<h1 id="chapter-5-unsupervised-learning">Chapter 5: Unsupervised Learning<a class="headerlink" href="#chapter-5-unsupervised-learning" title="Permanent link">&para;</a></h1>
<p>Mathematical Foundations of Deep Neural Networks
Fall 2022
Department of Mathematical Sciences
Ernest K. Ryu
Seoul National University</p>
<h2 id="unsupervised-learning">Unsupervised learning<a class="headerlink" href="#unsupervised-learning" title="Permanent link">&para;</a></h2>
<p>Unsupervised learning utilizes data <span class="arithmatex">\(X_{1}, \ldots, X_{N}\)</span> to learn the "structure" of the data. No labels are utilized.</p>
<p>There are a wide range of unsupervised learning tasks. In this class, we discuss just a few.</p>
<p>Generally, unsupervised learning tasks tend to have more mathematical complexity.</p>
<h2 id="low-dimensional-latent-representation">Low-dimensional latent representation<a class="headerlink" href="#low-dimensional-latent-representation" title="Permanent link">&para;</a></h2>
<p>Many high-dimensional data has some underlying low-dimensional structure.*
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-287.jpg?height=652&amp;width=729&amp;top_left_y=703&amp;top_left_x=1311" /></p>
<p>If you randomly generate the pixels of a color image <span class="arithmatex">\(X \in \mathbb{R}^{3 \times m \times n}\)</span>, it will likely make no sense. Only a very small subset of pixel values correspond to meaningful images.</p>
<h2 id="finding-latent-representations">Finding latent representations<a class="headerlink" href="#finding-latent-representations" title="Permanent link">&para;</a></h2>
<p>In machine learning, especially in unsupervised learning, finding a "meaningful" lowdimensional latent representation is of interest.</p>
<p>A good lower-dimensional representation of the data implies you have a good understanding of the data.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-289.jpg?height=567&amp;width=1128&amp;top_left_y=91&amp;top_left_x=2064" /></p>
<p>An autoencoder (AE) has encoder <span class="arithmatex">\(E_{\theta}: \mathbb{R}^{n} \rightarrow \mathbb{R}^{r}\)</span> and decoder <span class="arithmatex">\(D_{\varphi}: \mathbb{R}^{r} \rightarrow \mathbb{R}^{n}\)</span> networks, where <span class="arithmatex">\(r \ll n\)</span>. (If <span class="arithmatex">\(r \geq n\)</span>, AE learns identity mapping, so pointless.) The two networks are trained through the loss</p>
<div class="arithmatex">\[
\mathcal{L}(\theta, \varphi)=\sum_{i=1}^{N}\left\|X_{i}-D_{\varphi}\left(E_{\theta}\left(X_{i}\right)\right)\right\|^{2}
\]</div>
<p>The low-dimensional output <span class="arithmatex">\(E_{\theta}(X)\)</span> is the latent vector. The encoder performs dimensionality reduction.</p>
<p>The autoencoder can be thought of as a deep non-linear generalization of the principle component analysis (PCA).</p>
<h2 id="autoencoder-with-mnist">Autoencoder with MNIST<a class="headerlink" href="#autoencoder-with-mnist" title="Permanent link">&para;</a></h2>
<p>PyTorch demo</p>
<h2 id="applications-of-ae-denoising">Applications of AE: Denoising<a class="headerlink" href="#applications-of-ae-denoising" title="Permanent link">&para;</a></h2>
<p>Autoencoders can be used to denoise or reconstruct corrupted images.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-291.jpg?height=1231&amp;width=2818&amp;top_left_y=439&amp;top_left_x=240" />
P. Vincent, H. Larochelle, I. Lajoie, Y. Bengio, and P.-A. Manzagol, Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion, <span class="arithmatex">\(J M L R, 2010\)</span>.</p>
<h2 id="applications-of-ae-compression">Applications of AE: Compression<a class="headerlink" href="#applications-of-ae-compression" title="Permanent link">&para;</a></h2>
<p>Once an AE has been trained, storing the latent variable representation, rather than the original image can be used as a compression mechanism.</p>
<p>More generally, latent variable representations can be used for video compression. https://youtu.be/NqmMnjJ6GEg</p>
<h2 id="applications-of-ae-clustering">Applications of AE: Clustering<a class="headerlink" href="#applications-of-ae-clustering" title="Permanent link">&para;</a></h2>
<p>Train an AE and then perform clustering on the latent variables. For the clustering algorithm, one can use things like k-means, which groups together
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-293.jpg?height=1022&amp;width=1855&amp;top_left_y=714&amp;top_left_x=744" /></p>
<h2 id="applications-of-ae-clustering_1">Applications of AE: Clustering<a class="headerlink" href="#applications-of-ae-clustering_1" title="Permanent link">&para;</a></h2>
<p>Clustering is also referred to as unsupervised classification. Without labels, we want the group "similar" data.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-294.jpg?height=1107&amp;width=2135&amp;top_left_y=535&amp;top_left_x=1199" /></p>
<h2 id="anomalyoutlier-detection">Anomaly/outlier detection<a class="headerlink" href="#anomalyoutlier-detection" title="Permanent link">&para;</a></h2>
<p>Problem: detecting data that is significantly different from the data seen during training.</p>
<p>Insight: AE should not be able to faithfully reconstruct novel data.</p>
<p>Solution: Train an AE and define the score function to be the reconstruction loss:</p>
<div class="arithmatex">\[
s(X)=\left\|X-D_{\varphi}\left(E_{\theta}(X)\right)\right\|^{2}
\]</div>
<p>If score is high, determine the datapoint to be an outliner. (Cf. hw7.)</p>
<h2 id="probabilistic-generative-models">Probabilistic generative models<a class="headerlink" href="#probabilistic-generative-models" title="Permanent link">&para;</a></h2>
<p>A probabilistic generative model learns a distribution <span class="arithmatex">\(p_{\theta}\)</span> from <span class="arithmatex">\(X_{1}, \ldots, X_{N} \sim p_{\text {true }}\)</span> such that <span class="arithmatex">\(p_{\theta} \approx p_{\text {true }}\)</span> and such that we can generate new samples <span class="arithmatex">\(X \sim p_{\theta}\)</span>.</p>
<p>The ability to generate new synthetic data is interesting, but by itself not very useful.*</p>
<p>The structure of the data learned through the unsupervised learning is of higher value. However, we won't talk about the downstream applications in this course.</p>
<p>In this class, we will talk about flow models, VAEs, and GANs.</p>
<h2 id="flow-model-change-of-variable-formula-combined-with-deep-neural-networks">Flow model: Change of variable formula combined with deep neural networks<a class="headerlink" href="#flow-model-change-of-variable-formula-combined-with-deep-neural-networks" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-297.jpg?height=1281&amp;width=3330&amp;top_left_y=457&amp;top_left_x=2" /></p>
<h2 id="flow-models">Flow models<a class="headerlink" href="#flow-models" title="Permanent link">&para;</a></h2>
<p>Fit a probability density function <span class="arithmatex">\(p_{\theta}(x)\)</span> with continuous data <span class="arithmatex">\(X_{1}, \ldots, X_{N} \sim p_{\text {true }}(x)\)</span>.</p>
<ul>
<li>We want to fit the data <span class="arithmatex">\(X_{1}, \ldots, X_{N}\)</span> (or really the underlying distribution <span class="arithmatex">\(p_{\text {true }}\)</span> ) well.</li>
<li>We want to be able to sample from <span class="arithmatex">\(p_{\theta}\)</span>.</li>
<li>(We want to get a good latent representation.)</li>
</ul>
<p>We first develop the mathematical discussion with 1D flows, and then generalize the discussion to high dimensions.</p>
<h2 id="example-density-model-gaussian-mixture-model">Example density model: Gaussian mixture model<a class="headerlink" href="#example-density-model-gaussian-mixture-model" title="Permanent link">&para;</a></h2>
<div class="arithmatex">\[
p_{\theta}(x)=\sum_{i=1}^{k} \pi_{i} \mathcal{N}\left(x ; \mu_{i}, \sigma_{i}^{2}\right)
\]</div>
<p>Parameters: means and variances of components, mixture weights</p>
<div class="arithmatex">\[
\theta=\left(\pi_{1}, \ldots, \pi_{k}, \mu_{1}, \ldots, \mu_{k}, \sigma_{1}, \ldots, \sigma_{k}\right)
\]</div>
<p>Problems with GMM:</p>
<ul>
<li>Highly non-convex optimization problem. Can easily get stuck in local minima.</li>
<li>It is does not have the representation power to express high-dimensional data.</li>
</ul>
<h2 id="example-density-model-gaussian-mixture-model_1">Example density model: Gaussian mixture model<a class="headerlink" href="#example-density-model-gaussian-mixture-model_1" title="Permanent link">&para;</a></h2>
<p>GMM doesn't work with high-dimensional data. The sampling process is:
1.Pick a cluster center
2.Add Gaussian noise</p>
<p>If this is done with natural images, a realistic image can be generated only if it is a cluster center, i.e., the clusters must already be realistic images.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-300.jpg?height=831&amp;width=1672&amp;top_left_y=469&amp;top_left_x=1622" /></p>
<p>So then how do we fit a general (complex) density model?</p>
<h2 id="math-review-1d-continuous-rv">Math review: 1D continuous RV<a class="headerlink" href="#math-review-1d-continuous-rv" title="Permanent link">&para;</a></h2>
<p>A random variable <span class="arithmatex">\(X\)</span> is continuous if there exists a probability density function <span class="arithmatex">\(p_{X}(x) \geq 0\)</span> such that</p>
<div class="arithmatex">\[
\mathbb{P}(a \leq X \leq b)=\int_{a}^{b} p_{X}(x) d x
\]</div>
<p><span class="arithmatex">\(p_{X}(x)\)</span>
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-301.jpg?height=686&amp;width=834&amp;top_left_y=133&amp;top_left_x=2462" /></p>
<p>In this case, we write <span class="arithmatex">\(X \sim p_{X}\)</span>.</p>
<p>The cumulative distribution function (CDF) of <span class="arithmatex">\(X\)</span> is defined as</p>
<div class="arithmatex">\[
F_{X}(t)=\mathbb{P}(X \leq t)=\int_{-\infty}^{t} p_{X}(x) d x
\]</div>
<p><span class="arithmatex">\(F_{X}(t)\)</span> is a nondecreasing function.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-301.jpg?height=652&amp;width=1004&amp;top_left_y=916&amp;top_left_x=2275" />
<span class="arithmatex">\(F_{X}(t)\)</span> is a continuous function if <span class="arithmatex">\(X\)</span> is a continuous random variable.</p>
<h2 id="naive-approach-prameterize-p_theta-as-dnn">Naïve approach: prameterize <span class="arithmatex">\(p_{\theta}\)</span> as DNN<a class="headerlink" href="#naive-approach-prameterize-p_theta-as-dnn" title="Permanent link">&para;</a></h2>
<p>Naïve approach for fitting a density model. Represent <span class="arithmatex">\(p_{\theta}(x)\)</span> with DNN.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-302.jpg?height=545&amp;width=1685&amp;top_left_y=629&amp;top_left_x=663" /></p>
<p>There are some challenges:</p>
<ol>
<li>How to ensure proper distribution?
<span class="arithmatex">\(\int_{-\infty}^{+\infty} p_{\theta}(x) d x=1, \quad p_{\theta}(x) \geq 0, \quad x \in \mathbb{R}\)</span></li>
<li>How to sample?</li>
</ol>
<h2 id="normalization-of-p_theta">Normalization of <span class="arithmatex">\(p_{\theta}\)</span><a class="headerlink" href="#normalization-of-p_theta" title="Permanent link">&para;</a></h2>
<p>For discrete random variables, one can use the soft-max function <span class="arithmatex">\(\mu: \mathbb{R}^{k} \rightarrow \mathbb{R}^{k}\)</span> defined as</p>
<div class="arithmatex">\[
\mu_{i}(z)_{i}=\frac{e^{z_{i}}}{\sum_{j=1}^{k} e^{z_{j}}}
\]</div>
<p>to normalize probabilities.</p>
<p>For continuous random variables, we can ensure <span class="arithmatex">\(p_{\theta} \geq 0\)</span> with <span class="arithmatex">\(p_{\theta}(x)=e^{f_{\theta}(x)}\)</span>, where <span class="arithmatex">\(f_{\theta}\)</span> is the output of the neural network. However, ensuring the normalization</p>
<div class="arithmatex">\[
\int_{-\infty}^{+\infty} p_{\theta}(x) d x=1
\]</div>
<p>is not a simple matter. (Any Bayesian statistician can tell you how difficult this is.)</p>
<h2 id="what-happens-if-we-ignore-normalization">What happens if we ignore normalization?<a class="headerlink" href="#what-happens-if-we-ignore-normalization" title="Permanent link">&para;</a></h2>
<p>Do we really need this normalization thing? Yes, we do.</p>
<p>Without normalization, one can just assign arbitrarily large probabilities everywhere when we perform maximum likelihood estimation:</p>
<div class="arithmatex">\[
\underset{\theta \in \mathbb{R}^{p}}{\operatorname{maximize}} \sum_{i=1}^{N} \log p_{\theta}\left(X_{i}\right)
\]</div>
<p>The solution is to set <span class="arithmatex">\(p_{\theta}(x)=M\)</span> with <span class="arithmatex">\(M \rightarrow \infty\)</span>.</p>
<p>We want model to place large probability on data <span class="arithmatex">\(X_{1}, \ldots, X_{N}\)</span> while placing small probability elsewhere. Normalization forces model to place small probability where data doesn't reside.</p>
<h2 id="key-insight-parameterize-zf_thetax-with-dnn">Key insight: Parameterize <span class="arithmatex">\(Z=f_{\theta}(X)\)</span> with DNN<a class="headerlink" href="#key-insight-parameterize-zf_thetax-with-dnn" title="Permanent link">&para;</a></h2>
<p>Key insight of normalizing flow: DNN outputs random variable <span class="arithmatex">\(Z\)</span>, rather than <span class="arithmatex">\(p_{\theta}(X)\)</span>
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-305.jpg?height=562&amp;width=1804&amp;top_left_y=633&amp;top_left_x=374" /></p>
<p>In normalizing flow, find <span class="arithmatex">\(\theta\)</span> such that the flow <span class="arithmatex">\(f_{\theta}\)</span> normalizes the random variable <span class="arithmatex">\(X \sim p_{X}\)</span> into <span class="arithmatex">\(Z \sim \mathcal{N}(0,1)^{*}\)</span>.</p>
<p>Important questions to resolve:</p>
<ol>
<li>How to train? (How to evaluate <span class="arithmatex">\(p_{\theta}(x)\)</span> ? DNN outputs <span class="arithmatex">\(f_{\theta}\)</span>, not <span class="arithmatex">\(p_{\theta}\)</span>.)</li>
<li>How to sample <span class="arithmatex">\(X\)</span> ?</li>
</ol>
<h2 id="1d-change-of-variable-formula">1D change of variable formula<a class="headerlink" href="#1d-change-of-variable-formula" title="Permanent link">&para;</a></h2>
<p>Assume <span class="arithmatex">\(f\)</span> is invertible, <span class="arithmatex">\(f\)</span> is differentiable, and <span class="arithmatex">\(f^{-1}\)</span> is differentiable.
If <span class="arithmatex">\(X \sim p_{X}\)</span>, then <span class="arithmatex">\(Z=f(X)\)</span> has pdf</p>
<div class="arithmatex">\[
p_{Z}(z)=p_{X}\left(f^{-1}(z)\right)\left|\frac{d x}{d z}\right|
\]</div>
<p>If <span class="arithmatex">\(Z \sim p_{Z}\)</span>, then <span class="arithmatex">\(X=f^{-1}(Z)\)</span> has pdf</p>
<div class="arithmatex">\[
p_{X}(x)=p_{Z}(f(x))\left|\frac{d f(x)}{d x}\right|
\]</div>
<p>Since <span class="arithmatex">\(Z=f(X)\)</span>, one might think <span class="arithmatex">\(p_{X}(x)=p_{Z}(z)=p_{Z}(f(x)) . \leftarrow\)</span> This is wrong.</p>
<p>Invertibility of <span class="arithmatex">\(f\)</span> is essential; it is not a minor technical issue.</p>
<h2 id="training-flow-models">Training flow models<a class="headerlink" href="#training-flow-models" title="Permanent link">&para;</a></h2>
<p>Train model with MLE</p>
<div class="arithmatex">\[
\underset{\theta \in \mathbb{R}^{p}}{\operatorname{maximize}} \sum_{i=1}^{N} \log p_{\theta}\left(X_{i}\right)=\underset{\theta \in \mathbb{R}^{p}}{\operatorname{maximize}} \sum_{i=1}^{N} \log p_{Z}\left(f_{\theta}\left(X_{i}\right)\right)+\log \left|\frac{\partial f_{\theta}}{\partial x}\left(X_{i}\right)\right|
\]</div>
<p>where <span class="arithmatex">\(f_{\theta}\)</span> is invertible and differentiable, and <span class="arithmatex">\(X=f_{\theta}^{-1}(Z)\)</span> with <span class="arithmatex">\(Z \sim p_{Z}\)</span> so</p>
<div class="arithmatex">\[
p_{X}(x)=p_{Z}\left(f_{\theta}(x)\right)\left|\frac{\partial f_{\theta}}{\partial x}(x)\right|
\]</div>
<p>Can optimize with SGD, if we know how to perform backprop on <span class="arithmatex">\(\left|\frac{\partial f_{\theta}}{\partial x}\left(X_{i}\right)\right|\)</span>. More on this later.</p>
<h2 id="sampling-from-flow-models">Sampling from flow models<a class="headerlink" href="#sampling-from-flow-models" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-308.jpg?height=566&amp;width=1973&amp;top_left_y=465&amp;top_left_x=370" /></p>
<p>Step 1: Sample <span class="arithmatex">\(Z \sim p_{Z}\)</span>
Step 2: Compute <span class="arithmatex">\(X=f_{\theta}^{-1}(Z)\)</span></p>
<h2 id="requirements-of-flow-f_theta">Requirements of flow <span class="arithmatex">\(f_{\theta}\)</span><a class="headerlink" href="#requirements-of-flow-f_theta" title="Permanent link">&para;</a></h2>
<p>Theoretical requirement:</p>
<ul>
<li><span class="arithmatex">\(f_{\theta}(x)\)</span> invertible and differentiable.</li>
</ul>
<p>Computational requirements:</p>
<ul>
<li><span class="arithmatex">\(f_{\theta}(x)\)</span> and <span class="arithmatex">\(\nabla_{\theta} f_{\theta}(x)\)</span> efficient to evaluate (for training)</li>
<li><span class="arithmatex">\(\left|\frac{\partial f_{\theta}}{\partial x}(x)\right|\)</span> and <span class="arithmatex">\(\nabla_{\theta}\left|\frac{\partial f_{\theta}}{\partial x}(x)\right|\)</span> efficient to evaluate (for training)</li>
<li><span class="arithmatex">\(f_{\theta}^{-1}\)</span> efficient to evaluate (for sampling)</li>
</ul>
<h2 id="example-flow-to-z-uniform01">Example: Flow to <span class="arithmatex">\(Z\)</span> ~ Uniform([0,1])<a class="headerlink" href="#example-flow-to-z-uniform01" title="Permanent link">&para;</a></h2>
<h2 id="before-training">Before training<a class="headerlink" href="#before-training" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-310.jpg?height=579&amp;width=813&amp;top_left_y=442&amp;top_left_x=580" />
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-310.jpg?height=604&amp;width=813&amp;top_left_y=438&amp;top_left_x=1405" />
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-310.jpg?height=596&amp;width=838&amp;top_left_y=438&amp;top_left_x=2209" />
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-310.jpg?height=422&amp;width=418&amp;top_left_y=1048&amp;top_left_x=55" />
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-310.jpg?height=575&amp;width=817&amp;top_left_y=1065&amp;top_left_x=578" />
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-310.jpg?height=584&amp;width=809&amp;top_left_y=1052&amp;top_left_x=1403" />
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-310.jpg?height=592&amp;width=801&amp;top_left_y=1048&amp;top_left_x=2236" /></p>
<h2 id="example-flow-to-z-sim-operatornamebeta55">Example: Flow to <span class="arithmatex">\(Z \sim \operatorname{Beta}(5,5)\)</span><a class="headerlink" href="#example-flow-to-z-sim-operatornamebeta55" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-311.jpg?height=1281&amp;width=3139&amp;top_left_y=397&amp;top_left_x=25" /></p>
<h2 id="example-flow-to-z-sim-mathcaln01">Example: Flow to <span class="arithmatex">\(Z \sim \mathcal{N}(0,1)\)</span><a class="headerlink" href="#example-flow-to-z-sim-mathcaln01" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-312.jpg?height=1491&amp;width=2943&amp;top_left_y=384&amp;top_left_x=17" /></p>
<h2 id="1d-flow-demonstration">1D flow demonstration<a class="headerlink" href="#1d-flow-demonstration" title="Permanent link">&para;</a></h2>
<p>PyTorch demo</p>
<h2 id="universality-of-flows">Universality of flows<a class="headerlink" href="#universality-of-flows" title="Permanent link">&para;</a></h2>
<p>Are flows universal, i.e., can <span class="arithmatex">\(f_{\theta}^{-1}(Z) \sim p_{X}\)</span> for any <span class="arithmatex">\(X\)</span> provided that <span class="arithmatex">\(f_{\theta}\)</span> can represent any invertible function?</p>
<p>Yes, 1D flows are universal due to the inverse CDF sampling technique.*</p>
<p>Higher dimensional flows are also universal as shown by Huang et al.# or earlier by the general theory of optimal transport. <span class="arithmatex">\({ }^{\%}\)</span></p>
<h2 id="math-review-sampling-via-inverse-cdf">Math review: Sampling via inverse CDF<a class="headerlink" href="#math-review-sampling-via-inverse-cdf" title="Permanent link">&para;</a></h2>
<p>Inverse CDF sampling is a technique for sampling <span class="arithmatex">\(X \sim p_{X}\)</span>.
If <span class="arithmatex">\(F_{X}(t)\)</span> is furthermore a strictly increasing function, then <span class="arithmatex">\(F_{X}\)</span> is invertible, i.e., <span class="arithmatex">\(F_{X}^{-1}\)</span> exists.</p>
<p>Generate a random number <span class="arithmatex">\(U \sim \operatorname{Uniform}([0,1])\)</span> and compute <span class="arithmatex">\(F_{X}^{-1}(U)\)</span>. Then</p>
<div class="arithmatex">\[
F_{X}^{-1}(U) \sim p_{X}
\]</div>
<p>since</p>
<div class="arithmatex">\[
\mathbb{P}\left(F_{X}^{-1}(U) \leq t\right)=\mathbb{P}\left(U \leq F_{X}(t)\right)=F_{X}(t)
\]</div>
<p>Technique can be generalized to when <span class="arithmatex">\(F_{X}\)</span> is not invertible.</p>
<h2 id="universality-of-1d-flows">Universality of 1D flows<a class="headerlink" href="#universality-of-1d-flows" title="Permanent link">&para;</a></h2>
<p>Composition of flows is a flow, and inverse of a flow is a flow</p>
<p>Universality of 1D flows:</p>
<ul>
<li>Use inverse CDF as flow to transform <span class="arithmatex">\(X \sim p_{X}\)</span> into <span class="arithmatex">\(U \sim \operatorname{Uniform}([0,1])\)</span> and <span class="arithmatex">\(Z \sim \mathcal{N}(0,1)\)</span> into <span class="arithmatex">\(U \sim\)</span> Uniform ( <span class="arithmatex">\([0,1]\)</span> ).</li>
<li>Compose flow <span class="arithmatex">\(X \rightarrow U\)</span> and inverse flow <span class="arithmatex">\(U \rightarrow Z\)</span>
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-316.jpg?height=514&amp;width=1231&amp;top_left_y=599&amp;top_left_x=1973" /></li>
</ul>
<h2 id="jacobian-notation">Jacobian notation<a class="headerlink" href="#jacobian-notation" title="Permanent link">&para;</a></h2>
<p>Let <span class="arithmatex">\(f: \mathbb{R}^{n} \rightarrow \mathbb{R}^{n}\)</span>, such that</p>
<div class="arithmatex">\[
f(x)=\left[\begin{array}{c}
f_{1}(x) \\
f_{2}(x) \\
\vdots \\
f_{n}(x)
\end{array}\right]
\]</div>
<p>The Jacobian matrix is</p>
<div class="arithmatex">\[
\frac{\partial f}{\partial x}(x)=\left[\begin{array}{cccc}
\frac{\partial f_{1}}{\partial x_{1}}(x) &amp; \frac{\partial f_{1}}{\partial x_{2}}(x) &amp; \cdots &amp; \frac{\partial f_{1}}{\partial x_{n}}(x) \\
\frac{\partial f_{2}}{\partial x_{1}}(x) &amp; \frac{\partial f_{2}}{\partial x_{2}}(x) &amp; \cdots &amp; \frac{\partial f_{2}}{\partial x_{n}}(x) \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
\frac{\partial f_{n}}{\partial x_{1}}(x) &amp; \frac{\partial f_{n}}{\partial x_{2}}(x) &amp; \cdots &amp; \frac{\partial f_{n}}{\partial x_{n}}(x)
\end{array}\right]=\left[\begin{array}{c}
\left(\nabla f_{1}(x)\right)^{\top} \\
\left(\nabla f_{2}(x)\right)^{\top} \\
\vdots \\
\left(\nabla f_{n}(x)\right)^{\top}
\end{array}\right]
\]</div>
<p>The Jacobian determinant is <span class="arithmatex">\(\operatorname{det}\left(\frac{\partial f}{\partial x}\right)\)</span>. We use the notation</p>
<div class="arithmatex">\[
\left|\frac{\partial f}{\partial x}(x)\right|=\left|\operatorname{det}\left(\frac{\partial f}{\partial x}(x)\right)\right|
\]</div>
<p>where the second <span class="arithmatex">\(|\cdot|\)</span> is the absolute value of the determinant. (This notation is not completely standard.)</p>
<h2 id="math-review-multivariate-change-of-variables">Math review: Multivariate change of variables<a class="headerlink" href="#math-review-multivariate-change-of-variables" title="Permanent link">&para;</a></h2>
<p>Let <span class="arithmatex">\(f: \mathbb{R}^{n} \rightarrow \mathbb{R}^{n}\)</span> be an invertible function such that both <span class="arithmatex">\(f\)</span> and <span class="arithmatex">\(f^{-1}\)</span> are differentiable. Let <span class="arithmatex">\(U \subseteq \mathbb{R}^{n}\)</span>. Then</p>
<div class="arithmatex">\[
\int_{f(U)} h(v) d v=\int_{U} h(f(u))\left|\frac{\partial f}{\partial u}(u)\right| d u
\]</div>
<p>for any <span class="arithmatex">\(h: \mathbb{R}^{n} \rightarrow \mathbb{R}\)</span>. (Change of variable from <span class="arithmatex">\(v=f(u)\)</span> to <span class="arithmatex">\(u=f^{-1}(v)\)</span>.)</p>
<h2 id="math-review-multivariate-continuous-rv">Math review: Multivariate continuous RV<a class="headerlink" href="#math-review-multivariate-continuous-rv" title="Permanent link">&para;</a></h2>
<p>A multivariate random variable <span class="arithmatex">\(X \in \mathbb{R}^{n}\)</span> is continuous if there exists a probability density function <span class="arithmatex">\(p_{X}(x)\)</span> such that</p>
<div class="arithmatex">\[
\mathbb{P}(X \in A)=\int_{A} p_{X}(x) d x
\]</div>
<p>where the integral is over the volume <span class="arithmatex">\(A \subseteq \mathbb{R}^{n}\)</span>. In this case, we write <span class="arithmatex">\(X \sim p_{X}\)</span>.</p>
<p>The joint cumulative distribution function (the copula) does not seem to be useful in the context of high-dimensional flow models.</p>
<h2 id="math-review-mult-change-of-variables-for-rv">Math review: Mult. change of variables for RV<a class="headerlink" href="#math-review-mult-change-of-variables-for-rv" title="Permanent link">&para;</a></h2>
<p>Let <span class="arithmatex">\(f: \mathbb{R}^{n} \rightarrow \mathbb{R}^{n}\)</span> be an invertible function such that both <span class="arithmatex">\(f\)</span> and <span class="arithmatex">\(f^{-1}\)</span> are differentiable. Let <span class="arithmatex">\(X\)</span> be a continuous random variable with probability density function <span class="arithmatex">\(p_{X}\)</span> and let <span class="arithmatex">\(Y=f(X)\)</span> have density <span class="arithmatex">\(p_{Y}\)</span>. Then</p>
<div class="arithmatex">\[
p_{X}(x)=p_{Y}(f(x))\left|\frac{\partial f}{\partial x}(x)\right|
\]</div>
<p>Proof)</p>
<div class="arithmatex">\[
\mathbb{P}\left(f^{-1}(Y) \in A\right)=\mathbb{P}(Y \in f(A))=\int_{f(A)} p_{Y}(y) d y=\int_{A} p_{Y}(f(x))\left|\frac{\partial f}{\partial x}(x)\right| d x=\mathbb{P}(X \in A)
\]</div>
<p>Invertibility of <span class="arithmatex">\(f\)</span> is essential; it is not a minor technical issue.</p>
<h2 id="math-review-determinant-formulae">Math review: Determinant formulae<a class="headerlink" href="#math-review-determinant-formulae" title="Permanent link">&para;</a></h2>
<p>Fact: Determinant definitions in undergraduate linear algebra textbooks require exponentially many operations to compute:</p>
<div class="arithmatex">\[
\operatorname{det}(A)=\sum_{\sigma \in S_{n}}\left(\operatorname{sgn}(\sigma) \prod_{i=1}^{n} a_{i, \sigma_{i}}\right)
\]</div>
<p>Efficient computation of determinant for general matrices and performing backprop through the computation is difficult. Therefore, high-dimensional flow model are designed to compute determinants only on simple matrices.</p>
<p>Product formula: if <span class="arithmatex">\(A\)</span> and <span class="arithmatex">\(B\)</span> are square, then</p>
<div class="arithmatex">\[
\operatorname{det}(A B)=\operatorname{det}(A) \operatorname{det}(B)
\]</div>
<p>Block lower triangular formula: if <span class="arithmatex">\(A \in \mathbb{R}^{n \times n}\)</span> and <span class="arithmatex">\(C \in \mathbb{R}^{m \times m}\)</span>, then</p>
<div class="arithmatex">\[
\operatorname{det}\left(\begin{array}{ll}
A &amp; 0 \\
B &amp; C
\end{array}\right)=\operatorname{det}(A) \operatorname{det}(C)
\]</div>
<p>Lower triangular formula: if <span class="arithmatex">\(a_{1}, \ldots, a_{n} \in \mathbb{R}\)</span> and <span class="arithmatex">\(*\)</span> represents arbitrary values, then</p>
<div class="arithmatex">\[
\operatorname{det}\left(\begin{array}{cccc}
a_{1} &amp; 0 &amp; \cdots &amp; 0 \\
* &amp; a_{2} &amp; &amp; \vdots \\
* &amp; * &amp; \ddots &amp; 0 \\
* &amp; * &amp; * &amp; a_{n}
\end{array}\right)=\prod_{i=1}^{n} a_{i}
\]</div>
<p>Upper triangular formula: same as for lower triangular matrices.</p>
<h2 id="training-high-dim-flow-models">Training high-dim flow models<a class="headerlink" href="#training-high-dim-flow-models" title="Permanent link">&para;</a></h2>
<p>Train model with MLE</p>
<div class="arithmatex">\[
\underset{\theta \in \mathbb{R}^{p}}{\operatorname{maximize}} \sum_{i=1}^{N} \log p_{\theta}\left(X_{i}\right)=\underset{\theta \in \mathbb{R}^{p}}{\operatorname{maximize}} \sum_{i=1}^{N} \log p_{Z}\left(f_{\theta}\left(X_{i}\right)\right)+\log \left|\frac{\partial f_{\theta}}{\partial x}\left(X_{i}\right)\right|
\]</div>
<p>where <span class="arithmatex">\(f_{\theta}(z)\)</span> is invertible and differentiable, and <span class="arithmatex">\(X=f^{-1}(Z)\)</span> with <span class="arithmatex">\(Z \sim p_{Z}\)</span> so</p>
<div class="arithmatex">\[
p_{X}(x)=p_{Z}\left(f_{\theta}(x)\right)\left|\frac{\partial f_{\theta}}{\partial x}(x)\right|
\]</div>
<p>(Exactly the same formula as with 1D flow.)</p>
<p>Can optimize with SGD, if we know how to perform backprop on <span class="arithmatex">\(\left|\frac{\partial f_{\theta}}{\partial x}\left(X_{i}\right)\right|\)</span>.</p>
<h2 id="composing-flows">Composing flows<a class="headerlink" href="#composing-flows" title="Permanent link">&para;</a></h2>
<p>Flows can be composed to increase expressiveness. (Deep NN more expressive.)
Consider composition of <span class="arithmatex">\(k\)</span> flows</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; x \rightarrow f_{1} \rightarrow f_{2} \rightarrow \cdots \rightarrow f_{k} \rightarrow z \\
&amp; z=f_{k} \circ \cdots \circ f_{1}(x) \\
&amp; x=f_{1}^{-1} \circ \cdots \circ f_{k}^{-1}(z)
\end{aligned}
\]</div>
<p>Determinant computation splits nicely due to chain rule and product formula</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \operatorname{det}\left(\frac{\partial z}{\partial x}\right)=\operatorname{det}\left(\frac{\partial f_{k}}{\partial f_{k-1}} \cdots \frac{\partial f_{1}}{\partial f_{0}}\right)=\operatorname{det}\left(\frac{\partial f_{k}}{\partial f_{k-1}}\right) \cdots \operatorname{det}\left(\frac{\partial f_{1}}{\partial f_{0}}\right) \\
&amp; \log p_{\theta}(x)=\log p_{\theta}(z)+\sum_{i=1}^{k} \log \left|\frac{\partial f_{i}}{\partial f_{i-1}}\right|
\end{aligned}
\]</div>
<h2 id="basic-example-affine-flows">Basic example: Affine flows<a class="headerlink" href="#basic-example-affine-flows" title="Permanent link">&para;</a></h2>
<p>An affine (linear) transformation</p>
<div class="arithmatex">\[
f_{A, b}(x)=A^{-1}(x-b)
\]</div>
<p>is a flow if matrix <span class="arithmatex">\(A\)</span> is invertible. Then</p>
<div class="arithmatex">\[
\frac{\partial f_{A, b}}{\partial x}=A^{-1}
\]</div>
<p>and</p>
<div class="arithmatex">\[
\left|\frac{\partial f_{A, b}}{\partial x}\right|=\left|\operatorname{det}\left(A^{-1}\right)\right|=\frac{1}{|\operatorname{det}(A)|}
\]</div>
<p>Sampling: <span class="arithmatex">\(X=A Z+b\)</span>, where <span class="arithmatex">\(Z \sim \mathcal{N}(0, I)\)</span>.
Problem with affine flows:</p>
<ul>
<li>Computing <span class="arithmatex">\(|\operatorname{det}(A)|\)</span> is expensive and performing backprop over it is difficult. We want <span class="arithmatex">\(\frac{\partial f_{A, b}}{\partial x}\)</span> to be further structured so that determinant is easy to compute.</li>
<li>One affine flow is insufficient to generate complex data. However, composing multiple affine flows yields an affine flow and therefore is pointless. We need to introduce nonlinearities.</li>
</ul>
<h2 id="coupling-flows">Coupling flows<a class="headerlink" href="#coupling-flows" title="Permanent link">&para;</a></h2>
<p>A coupling flow is a general and practical approach for constructing non-linear flows.</p>
<p>Partition input into two disjoint subsets <span class="arithmatex">\(x=\left(x^{A}, x^{B}\right)\)</span>. Then</p>
<div class="arithmatex">\[
f(x)=\left(x^{A}, \hat{f}\left(x^{B} \mid \psi_{\theta}\left(x^{A}\right)\right)\right)
\]</div>
<p>where <span class="arithmatex">\(\psi_{\theta}\)</span> is a neural network and <span class="arithmatex">\(\hat{f}\left(x^{B} \mid \psi_{\theta}\left(x^{A}\right)\right)\)</span> is another flow whose parameters depend on <span class="arithmatex">\(x^{A}\)</span>.</p>
<h2 id="coupling-flow-forward-evaluation">Coupling flow: forward evaluation<a class="headerlink" href="#coupling-flow-forward-evaluation" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-326.jpg?height=1157&amp;width=2995&amp;top_left_y=510&amp;top_left_x=233" /></p>
<h2 id="coupling-flow-inverse-evaluation">Coupling flow: inverse evaluation<a class="headerlink" href="#coupling-flow-inverse-evaluation" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-327.jpg?height=1132&amp;width=3152&amp;top_left_y=633&amp;top_left_x=57" /></p>
<h2 id="jacobian-of-coupling-flows">Jacobian of coupling flows<a class="headerlink" href="#jacobian-of-coupling-flows" title="Permanent link">&para;</a></h2>
<p>The Jacobian of a coupling flow has a nice block structure</p>
<div class="arithmatex">\[
\frac{\partial f_{\theta}}{\partial x}(x)=\left[\begin{array}{cc}
I &amp; 0 \\
\frac{\partial \hat{f}}{\partial x^{A}}\left(x^{B} \mid \psi_{\theta}\left(x^{A}\right)\right) &amp; \frac{\partial \hat{f}}{\partial x^{B}}\left(x^{B} \mid \psi_{\theta}\left(x^{A}\right)\right)
\end{array}\right]
\]</div>
<p>which leads to the simplified determinant formula</p>
<div class="arithmatex">\[
\operatorname{det}\left(\frac{\partial f_{\theta}}{\partial x}(x)\right)=\operatorname{det}\left(\frac{\partial \hat{f}}{\partial x^{B}}\left(x^{B} \mid \psi_{\theta}\left(x^{A}\right)\right)\right)
\]</div>
<p>Note <span class="arithmatex">\(\frac{\partial \hat{f}}{\partial x^{A}}\left(x^{B} \mid \psi_{\theta}\left(x^{A}\right)\right)\)</span>, which will be very complicated, does not appear in the determinant.</p>
<h2 id="coupling-transformation-hatfx-mid-psi">Coupling transformation <span class="arithmatex">\(\hat{f}(x \mid \psi)\)</span><a class="headerlink" href="#coupling-transformation-hatfx-mid-psi" title="Permanent link">&para;</a></h2>
<p>Additive transformations (NICE)*</p>
<div class="arithmatex">\[
\hat{f}(x \mid \psi)=x+t
\]</div>
<p>where <span class="arithmatex">\(\psi=t\)</span>.</p>
<p>Affine transformations (Real NVP) <span class="arithmatex">\({ }^{\#}\)</span></p>
<div class="arithmatex">\[
\hat{f}(x \mid \psi)=e^{s} \odot x+t
\]</div>
<p>where <span class="arithmatex">\(\psi=(s, t)\)</span>.</p>
<p>Other transformations studied throughout the literature.</p>
<h2 id="nice-non-linear-independent-components-estimation">NICE (Non-linear Independent Components Estimation)<a class="headerlink" href="#nice-non-linear-independent-components-estimation" title="Permanent link">&para;</a></h2>
<p>NICE uses additive coupling layers:
Split variables in half: <span class="arithmatex">\(x_{1: n / 2}, x_{n / 2: n}\)</span></p>
<div class="arithmatex">\[
\begin{aligned}
&amp; z_{1: n / 2}=x_{1: n / 2} \\
&amp; z_{n / 2: n}=x_{n / 2: n}+t_{\theta}\left(x_{1: n / 2}\right)
\end{aligned}
\]</div>
<p>Easily invertible:</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; x_{1: n / 2}=z_{1: n / 2} \\
&amp; x_{n / 2: n}=z_{n / 2: n}-t_{\theta}\left(x_{1: n / 2}\right)
\end{aligned}
\]</div>
<p>Jacobian determinant is easy to compute:
<span class="arithmatex">\(\operatorname{det} \frac{\partial f_{\theta}}{\partial x}(x)=\operatorname{det}\left[\begin{array}{cc}I &amp; 0 \\ \frac{\partial \hat{f}}{\partial x^{A}}\left(x^{B} \mid \psi_{\theta}\left(x^{A}\right)\right) &amp; \frac{\partial \hat{f}}{\partial x^{B}}\left(x^{B} \mid \psi_{\theta}\left(x^{A}\right)\right)\end{array}\right]=\operatorname{det}\left[\begin{array}{cc}I &amp; 0 \\ \frac{\partial \hat{f}}{\partial x^{A}}\left(x^{B} \mid \psi_{\theta}\left(x^{A}\right)\right) &amp; I\end{array}\right]=1\)</span></p>
<h2 id="real-nvp-real-valued-non-volume-preserving">Real NVP (Real-valued Non-Volume Preserving)<a class="headerlink" href="#real-nvp-real-valued-non-volume-preserving" title="Permanent link">&para;</a></h2>
<p>Real NVP uses affine coupling layers:</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; z_{1: n / 2}=x_{1: n / 2} \\
&amp; z_{n / 2: n}=e^{s_{\theta}\left(x_{1: n / 2}\right)} \odot x_{n / 2: n}+t_{\theta}\left(x_{1: n / 2}\right)
\end{aligned}
\]</div>
<p>Easily invertible:</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; x_{1: n / 2}=z_{1: n / 2} \\
&amp; x_{n / 2: n}=\left(z_{n / 2: n}-t_{\theta}\left(x_{1: n / 2}\right)\right) \odot e^{-s_{\theta}\left(x_{1: n / 2}\right)}
\end{aligned}
\]</div>
<p>Jacobian determinant is easy to compute:</p>
<div class="arithmatex">\[
\begin{aligned}
\operatorname{det} \frac{\partial f_{\theta}}{\partial x}(x) &amp; =\operatorname{det}\left[\begin{array}{cc}
I &amp; 0 \\
\frac{\partial \hat{f}}{\partial x^{A}}\left(x^{B} \mid \psi_{\theta}\left(x^{A}\right)\right) &amp; \frac{\partial \hat{f}}{\partial x^{B}}\left(x^{B} \mid \psi_{\theta}\left(x^{A}\right)\right)
\end{array}\right] \\
&amp; =\operatorname{det}\left[\begin{array}{cc}
I &amp; 0 \\
\frac{\partial \hat{f}}{\partial x^{A}}\left(x^{B} \mid \psi_{\theta}\left(x^{A}\right)\right) &amp; \operatorname{diag}\left(e^{s_{\theta}\left(x_{1: n / 2}\right)}\right)
\end{array}\right]=\exp \left(\mathbf{1}_{n / 2}^{\top} s_{\theta}\left(x_{1: n / 2}\right)\right)
\end{aligned}
\]</div>
<h2 id="real-nvp-results">Real NVP - Results<a class="headerlink" href="#real-nvp-results" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-332.jpg?height=1366&amp;width=2822&amp;top_left_y=365&amp;top_left_x=257" /></p>
<h2 id="how-to-partition-variables">How to partition variables?<a class="headerlink" href="#how-to-partition-variables" title="Permanent link">&para;</a></h2>
<p>Note that the additive and affine coupling layers of NICE and Real NVP are nonlinear mappings from <span class="arithmatex">\(x_{1: n}\)</span> to <span class="arithmatex">\(z_{1: n}\)</span>, since <span class="arithmatex">\(s_{\theta}\left(x_{1: n / 2}\right)\)</span> and <span class="arithmatex">\(t_{\theta}\left(x_{1: n / 2}\right)\)</span> are nonlinear.</p>
<p>Flow models compose multiple nonlinear flows. But if <span class="arithmatex">\(x_{1: n / 2}\)</span> is always unchanged, then the full composition will leave it unchanged. Therefore, we change the partitioning for every coupling layer.</p>
<h2 id="nice-architecture">NICE architecture<a class="headerlink" href="#nice-architecture" title="Permanent link">&para;</a></h2>
<p>PyTorch demo</p>
<h2 id="real-nvp-variable-partitioning">Real NVP variable partitioning<a class="headerlink" href="#real-nvp-variable-partitioning" title="Permanent link">&para;</a></h2>
<p>Two partition strategies:</p>
<ol>
<li>Partition with
checkerboard pattern.</li>
<li>Reshape tensor and then partition channelwise.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-335.jpg?height=975&amp;width=2036&amp;top_left_y=720&amp;top_left_x=1294" /></li>
</ol>
<h2 id="real-nvp-architecture">Real NVP Architecture<a class="headerlink" href="#real-nvp-architecture" title="Permanent link">&para;</a></h2>
<p>Input <span class="arithmatex">\(X\)</span> : <span class="arithmatex">\(c \times 32 \times 32\)</span> image with <span class="arithmatex">\(c=3\)</span>
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-336.jpg?height=868&amp;width=2286&amp;top_left_y=0&amp;top_left_x=997" /></p>
<h2 id="layer-1-input-x-c-times-32-times-32">Layer 1: Input <span class="arithmatex">\(X: c \times 32 \times 32\)</span><a class="headerlink" href="#layer-1-input-x-c-times-32-times-32" title="Permanent link">&para;</a></h2>
<ul>
<li>Checkerboard <span class="arithmatex">\(\times 3\)</span>, channel reshape into <span class="arithmatex">\(4 c \times 16 \times 16\)</span>, channel <span class="arithmatex">\(\times 3\)</span></li>
<li>Output: Split result to get <span class="arithmatex">\(X_{1}: 2 c \times 16 \times 16\)</span> and <span class="arithmatex">\(Z_{1}: 2 c \times 16 \times 16\)</span> (fine-grained latents) Layer 2: Input <span class="arithmatex">\(X_{1}: 2 c \times 16 \times 16\)</span> from layer 1</li>
<li>Checkerboard <span class="arithmatex">\(\times 3\)</span>, channel reshape into <span class="arithmatex">\(8 c \times 8 \times 8\)</span>, channel <span class="arithmatex">\(\times 3\)</span></li>
<li>Split result to get <span class="arithmatex">\(X_{2}: 4 c \times 8 \times 8\)</span> and <span class="arithmatex">\(Z_{2}: 4 c \times 8 \times 8\)</span> (coarser latents)</li>
</ul>
<p>Layer 3: Input <span class="arithmatex">\(X_{2}: 4 c \times 8 \times 8\)</span> from layer 2</p>
<ul>
<li>Checkerboard <span class="arithmatex">\(\times 3\)</span>, channel reshape into <span class="arithmatex">\(16 c \times 4 \times 4\)</span>, channel <span class="arithmatex">\(\times 3\)</span></li>
<li>Get <span class="arithmatex">\(Z_{3}: 16 c \times 4 \times 4\)</span> (latents for highest-level details)</li>
</ul>
<h2 id="batch-normalization_1">Batch normalization<a class="headerlink" href="#batch-normalization_1" title="Permanent link">&para;</a></h2>
<p>To train deep flows, BN is helpful. However, the large model size forces the use of small batch sizes, and BN is not robust with small batch sizes. RealNVP uses a modified form of BN</p>
<div class="arithmatex">\[
x \mapsto \frac{x-\tilde{\mu}}{\sqrt{\tilde{\sigma}^{2}+\varepsilon}}
\]</div>
<p>(No <span class="arithmatex">\(\beta\)</span> and <span class="arithmatex">\(\gamma\)</span> parameters.) This layer has the log Jacobian determinant</p>
<div class="arithmatex">\[
-\frac{1}{2} \sum_{i} \log \left(\tilde{\sigma}_{i}^{2}+\varepsilon\right)
\]</div>
<p>The mean and variance parameters are updated with</p>
<div class="arithmatex">\[
\begin{aligned}
\tilde{\mu}_{k+1} &amp; =\rho \tilde{\mu}_{k}+(1-\rho) \hat{\mu}_{k} \\
\tilde{\sigma}_{k+1}^{2} &amp; =\rho \tilde{\sigma}_{k}^{2}+(1-\rho) \hat{\sigma}_{k}^{2}
\end{aligned}
\]</div>
<p>where <span class="arithmatex">\(\rho\)</span> is the momentum. During gradient computation, only backprop through the current batch statistics <span class="arithmatex">\(\hat{\mu}_{k}\)</span> and <span class="arithmatex">\(\hat{\sigma}_{k}^{2}\)</span>.</p>
<h2 id="s_theta-and-t_theta-networks"><span class="arithmatex">\(s_{\theta}\)</span> and <span class="arithmatex">\(t_{\theta}\)</span> networks<a class="headerlink" href="#s_theta-and-t_theta-networks" title="Permanent link">&para;</a></h2>
<p>The <span class="arithmatex">\(s_{\theta}\)</span> and <span class="arithmatex">\(t_{\theta}\)</span> do not need to be invertible. The original RealNVP paper does not describe its construction.</p>
<p>We let <span class="arithmatex">\(\left(s_{\theta}, t_{\theta}\right)\)</span> be a deep (20-layer) convolutional neural network using residual connections and standard batch normalization.</p>
<h2 id="real-nvp-architecture_1">Real NVP architecture<a class="headerlink" href="#real-nvp-architecture_1" title="Permanent link">&para;</a></h2>
<p>PyTorch demo</p>
<h2 id="glow-paper">Glow paper<a class="headerlink" href="#glow-paper" title="Permanent link">&para;</a></h2>
<p>The authors of the Glow paper also released a blog post.
https://openai.com/blog/glow/</p>
<h2 id="ffjord">FFJORD<a class="headerlink" href="#ffjord" title="Permanent link">&para;</a></h2>
<p>Instead of a discrete composition of flows, what if we have a continuous-time flow?</p>
<div class="arithmatex">\[
\begin{aligned}
z_{0} &amp; =x \\
z_{t} &amp; =z_{0}+\int_{0}^{t} h\left(t, z_{t}\right) d t \\
f(x) &amp; =z_{1}
\end{aligned}
\]</div>
<p>Inverse:</p>
<div class="arithmatex">\[
\begin{aligned}
z_{1} &amp; =z \\
z_{t} &amp; =z_{1}-\int_{t}^{1} h\left(t, z_{t}\right) d t \\
f^{-1}(z) &amp; =z_{0}
\end{aligned}
\]</div>
<p>R. T. Q. Chen, Y. Rubanova, J. Bettencourt, and D. Duvenaud, Neural ordinary differential equations, NeurIPS, 2018.
W. GrathwohI, R. T. Q. Chen, J. Bettencourt, I. Sutskever, and D. Duvenaud, FFJORD: Free-form continuous dynamics for scalable reversible generative</p>
<h2 id="math-review-conditional-probabilities">Math review: Conditional probabilities<a class="headerlink" href="#math-review-conditional-probabilities" title="Permanent link">&para;</a></h2>
<p>Let <span class="arithmatex">\(A\)</span> and <span class="arithmatex">\(B\)</span> be probabilistic events. Assume <span class="arithmatex">\(A\)</span> has nonzero probability.</p>
<p>Conditional probability satisfies</p>
<div class="arithmatex">\[
\mathbb{P}(B \mid A) \mathbb{P}(A)=\mathbb{P}(A \cap B)
\]</div>
<p>Bayes' theorem is an application of conditional probability:</p>
<div class="arithmatex">\[
\mathbb{P}(B \mid A)=\frac{\mathbb{P}(A \mid B) \mathbb{P}(B)}{\mathbb{P}(A)}
\]</div>
<h2 id="math-review-conditional-densities">Math review: Conditional densities<a class="headerlink" href="#math-review-conditional-densities" title="Permanent link">&para;</a></h2>
<p>Let <span class="arithmatex">\(X \in \mathbb{R}^{m}\)</span> and <span class="arithmatex">\(Z \in \mathbb{R}^{n}\)</span> be continuous random variables with joint density <span class="arithmatex">\(p(x, z)\)</span>.</p>
<p>The marginal densities are defined by</p>
<div class="arithmatex">\[
p_{X}(x)=\int_{\mathbb{R}^{n}} p(x, z) d z, \quad p_{Z}(z)=\int_{\mathbb{R}^{m}} p(x, z) d x
\]</div>
<p>The conditional density function <span class="arithmatex">\(p(z \mid x)\)</span> has the following properties</p>
<div class="arithmatex">\[
\begin{gathered}
\mathbb{P}(Z \in S \mid X=x)=\int_{S} p(z \mid x) d z \\
p(z \mid x) p_{X}(x)=p(x, z), \quad p(z \mid x)=\frac{p(x \mid z) p_{Z}(Z)}{p_{X}(X)}
\end{gathered}
\]</div>
<h2 id="variational-autoencoders-vae">Variational autoencoders (VAE)<a class="headerlink" href="#variational-autoencoders-vae" title="Permanent link">&para;</a></h2>
<p>These are synthetic (fake) images.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-344.jpg?height=1381&amp;width=2093&amp;top_left_y=365&amp;top_left_x=1220" /></p>
<h2 id="variational-autoencoders-vae_1">Variational autoencoders (VAE)<a class="headerlink" href="#variational-autoencoders-vae_1" title="Permanent link">&para;</a></h2>
<p>Key idea of VAE:</p>
<ul>
<li>Latent variable model with conditional probability distribution represented by <span class="arithmatex">\(p_{\theta}(x \mid z)\)</span>.</li>
<li>Efficiently estimate <span class="arithmatex">\(p_{\theta}(x)=\mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}(x \mid Z)\right]\)</span> by importance sampling with <span class="arithmatex">\(Z \sim q_{\phi}(z \mid x)\)</span>.</li>
</ul>
<p>We can interpret <span class="arithmatex">\(q_{\phi}(z \mid x)\)</span> as an encoder and <span class="arithmatex">\(p_{\theta}(x \mid z)\)</span> as a decoder.</p>
<p>VAEs differ from autoencoders as follows:</p>
<ul>
<li>Derivations (latent variable model vs. dimensionality reduction)</li>
<li>VAE regularizes/controls latent distribution, while AE does not.</li>
</ul>
<h2 id="latent-variable-model">Latent variable model<a class="headerlink" href="#latent-variable-model" title="Permanent link">&para;</a></h2>
<p>Assumption on data <span class="arithmatex">\(X_{1}, \ldots, X_{N}\)</span> : Assumes there is an underlying latent variable <span class="arithmatex">\(Z\)</span> representing the "essential structure" of the data and an observable variable <span class="arithmatex">\(X\)</span> which generation is conditioned on <span class="arithmatex">\(Z\)</span>. Implicitly assumes the conditional randomness of <span class="arithmatex">\(X \sim p_{X \mid Z}\)</span> is significantly smaller than the overall randomness <span class="arithmatex">\(X \sim p_{X}\)</span>.</p>
<p>Example: <span class="arithmatex">\(X\)</span> is a cat picture. <span class="arithmatex">\(Z\)</span> encodes information about the body position, fur color, and facial expression of a cat. Latent variable <span class="arithmatex">\(Z\)</span> encodes the overall content of the image, but <span class="arithmatex">\(X\)</span> does contain details not specified in <span class="arithmatex">\(Z\)</span>.</p>
<p>Specification VAE's model: VAEs implements a latent variable model with a NN that generates <span class="arithmatex">\(X\)</span> given <span class="arithmatex">\(Z\)</span>. More precisely, NN is a deterministic function that outputs the conditional distribution <span class="arithmatex">\(p_{\theta}(x \mid Z)\)</span>, and <span class="arithmatex">\(X\)</span> is randomly generated according to this distribution. This structure may effectively learn the latent structure from data if the assumption on data is accurate.</p>
<h2 id="latent-variable-model_1">Latent variable model<a class="headerlink" href="#latent-variable-model_1" title="Permanent link">&para;</a></h2>
<p>Sampling process:</p>
<div class="arithmatex">\[
X \sim p_{\theta}(x \mid Z), \quad Z \sim p_{Z}(z)
\]</div>
<p>Usually <span class="arithmatex">\(p_{Z}\)</span> is a Gaussian (fixed) and <span class="arithmatex">\(p_{\theta}(x \mid z)\)</span> is a NN parameterized by <span class="arithmatex">\(\theta\)</span>.</p>
<p>Evaluating density (likelihood):
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-347.jpg?height=256&amp;width=235&amp;top_left_y=276&amp;top_left_x=2111" />
<span class="arithmatex">\(p_{\theta}(x \mid z)\)</span></p>
<div class="arithmatex">\[
p_{\theta}\left(X_{i}\right)=\int_{z} p_{Z}(z) p_{\theta}\left(X_{i} \mid z\right) d z=\mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}\left(X_{i} \mid Z\right)\right]
\]</div>
<p>Training via MLE: <span class="arithmatex">\(\underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \log p_{\theta}\left(X_{i}\right)=\underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \log \mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}\left(X_{i} \mid Z\right)\right]\)</span></p>
<h2 id="latent-variable-model_2">Latent variable model<a class="headerlink" href="#latent-variable-model_2" title="Permanent link">&para;</a></h2>
<p>When <span class="arithmatex">\(p_{Z}\)</span> is a discrete:</p>
<div class="arithmatex">\[
p_{\theta}(x)=\mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}(x \mid Z)\right]=\sum_{z} p_{Z}(z) p_{\theta}(x \mid Z)
\]</div>
<p>When <span class="arithmatex">\(p_{Z}\)</span> is a continuous:</p>
<div class="arithmatex">\[
p_{\theta}(x)=\mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}(x \mid Z)\right]=\int_{z} p_{Z}(z) p_{\theta}(x \mid z) d z
\]</div>
<p>To clarify, specification of <span class="arithmatex">\(p_{Z}(z)\)</span> and <span class="arithmatex">\(p_{\theta}(x \mid z)\)</span> fully determines <span class="arithmatex">\(p_{\theta}(x)\)</span> (as above) and</p>
<div class="arithmatex">\[
p_{\theta}(z \mid x)=\frac{p_{\theta}(x \mid z) p_{Z}(z)}{p_{\theta}(x)}
\]</div>
<h2 id="latent-variable-model-training">Latent variable model: Training<a class="headerlink" href="#latent-variable-model-training" title="Permanent link">&para;</a></h2>
<p>Training</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \log p_{\theta}\left(X_{i}\right)=\underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \log \mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}\left(X_{i} \mid Z\right)\right]
\]</div>
<p>requires evaluation <span class="arithmatex">\(\mathbb{E}_{Z}\)</span>.</p>
<p>Scenario 1: If <span class="arithmatex">\(Z\)</span> is discrete and takes a few of values, then compute <span class="arithmatex">\(\sum_{z}\)</span> exactly.</p>
<p>Scenario 2: If <span class="arithmatex">\(Z\)</span> takes many values or if it is a continuous, then <span class="arithmatex">\(\sum_{z}\)</span> or <span class="arithmatex">\(\mathbb{E}_{Z}\)</span> is impractical to compute. In this case, approximate expectation with Monte Carlo and importance sampling.</p>
<h2 id="example-latent-variable-model-mixture-of-gaussians">Example latent variable model: Mixture of Gaussians<a class="headerlink" href="#example-latent-variable-model-mixture-of-gaussians" title="Permanent link">&para;</a></h2>
<p>Mixture of 3 Gaussians in <span class="arithmatex">\(\mathbb{R}^{2}\)</span>, uniform prior over components. (We can make the mixture weights a trainable parameter.)</p>
<div class="arithmatex">\[
\begin{gathered}
p_{Z}(Z=A)=p_{Z}(Z=B)=p_{Z}(Z=C)=\frac{1}{3} \\
p_{\theta}(x \mid Z=k)=\frac{1}{2 \pi\left|\Sigma_{k}\right|^{\frac{1}{2}}} \exp \left(-\frac{1}{2}\left(x-\mu_{k}\right)^{\top} \Sigma_{k}^{-1}\left(x-\mu_{k}\right)\right)
\end{gathered}
\]</div>
<p>Training objective:</p>
<div class="arithmatex">\[
\begin{aligned}
\underset{\mu, \Sigma}{\operatorname{maximize}} \sum_{i=1}^{N} \log p_{\theta}\left(X_{i}\right)=\underset{\mu, \Sigma}{\operatorname{maximize}} \sum_{i=1}^{N} \log [ &amp; \frac{1}{3} \frac{1}{2 \pi\left|\Sigma_{A}\right|^{\frac{1}{2}}} \exp \left(-\frac{1}{2}\left(X_{i}-\mu_{A}\right)^{\top} \Sigma_{A}^{-1}\left(X_{i}-\mu_{A}\right)\right) \\
&amp; +\frac{1}{3} \frac{1}{2 \pi\left|\Sigma_{B}\right|^{\frac{1}{2}}} \exp \left(-\frac{1}{2}\left(X_{i}-\mu_{B}\right)^{\top} \Sigma_{B}^{-1}\left(X_{i}-\mu_{B}\right)\right) \\
&amp; \left.+\frac{1}{3} \frac{1}{2 \pi\left|\Sigma_{C}\right|^{\frac{1}{2}}} \exp \left(-\frac{1}{2}\left(X_{i}-\mu_{C}\right)^{\top} \Sigma_{C}^{-1}\left(X_{i}-\mu_{C}\right)\right)\right]
\end{aligned}
\]</div>
<h2 id="example-2d-mixture-of-gaussians">Example: 2D mixture of Gaussians<a class="headerlink" href="#example-2d-mixture-of-gaussians" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-351.jpg?height=1056&amp;width=2361&amp;top_left_y=637&amp;top_left_x=308" /></p>
<h2 id="vae-outline">VAE outline<a class="headerlink" href="#vae-outline" title="Permanent link">&para;</a></h2>
<p>Train latent variable model with MLE</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \log p_{\theta}\left(X_{i}\right)=\underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \log \mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}\left(X_{i} \mid Z\right)\right]
\]</div>
<p>Outline of variational autoencoder (VAE):</p>
<ol>
<li>Approximate intractable objective with a single <span class="arithmatex">\(Z\)</span> sample</li>
</ol>
<div class="arithmatex">\[
\sum_{i=1}^{N} \log \mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}\left(X_{i} \mid Z\right)\right] \approx \sum_{i=1}^{N} \log p_{\theta}\left(X_{i} \mid Z_{i}\right), \quad Z_{i} \sim p_{Z}
\]</div>
<ol>
<li>Improve accuracy of approximation by sampling <span class="arithmatex">\(Z_{i}\)</span> with importance sampling</li>
</ol>
<div class="arithmatex">\[
\sum_{i=1}^{N} \log \mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}\left(X_{i} \mid Z\right)\right] \approx \sum_{i=1}^{N} \log \frac{p_{\theta}\left(X_{i} \mid Z_{i}\right) p_{Z}\left(Z_{i}\right)}{q_{i}\left(Z_{i}\right)}, \quad Z_{i} \sim q_{i}
\]</div>
<ol>
<li>Optimize approximate objective with SGD.</li>
</ol>
<h2 id="iwae-outline">IWAE outline<a class="headerlink" href="#iwae-outline" title="Permanent link">&para;</a></h2>
<p>Importance weighted autoencoders (IWAE) approximates intractable with <span class="arithmatex">\(K\)</span> samples of <span class="arithmatex">\(Z\)</span> :</p>
<div class="arithmatex">\[
\sum_{i=1}^{N} \log \mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}\left(X_{i} \mid Z\right)\right] \approx \sum_{i=1}^{N} \log \frac{1}{K} \sum_{k=1}^{K} \frac{p_{\theta}\left(X_{i} \mid Z_{i, k}\right) p_{Z}\left(Z_{i, k}\right)}{q_{i}\left(Z_{i, k}\right)}, \quad Z_{i, 1}, \ldots, Z_{i, K} \sim q_{i}
\]</div>
<p>More on this in hw 9.</p>
<h2 id="why-does-vae-need-is">Why does VAE need IS?<a class="headerlink" href="#why-does-vae-need-is" title="Permanent link">&para;</a></h2>
<p>Sampling <span class="arithmatex">\(Z_{i} \sim p_{Z}\)</span> results in a high-variance estimator:</p>
<div class="arithmatex">\[
\mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}\left(X_{i} \mid Z\right)\right] \approx p_{\theta}\left(X_{i} \mid Z_{i}\right),
\]</div>
<p>In the Gaussian mixture example, only <span class="arithmatex">\(1 / 3\)</span> of the <span class="arithmatex">\(Z\)</span> samples meaningfully contribute to the estimate. More specifically, if <span class="arithmatex">\(X_{i}\)</span> is near <span class="arithmatex">\(\mu_{A}\)</span> but is far from <span class="arithmatex">\(\mu_{B}\)</span> and <span class="arithmatex">\(\mu_{C}\)</span>, then <span class="arithmatex">\(p_{\theta}\left(X_{i} \mid Z=A\right) \gg 0\)</span> but <span class="arithmatex">\(p_{\theta}\left(X_{i} \mid Z=B\right) \approx 0\)</span> and <span class="arithmatex">\(p_{\theta}\left(X_{i} \mid Z=C\right) \approx 0\)</span>.</p>
<p>The issue worsens as the observable and latent variable dimension increases.</p>
<h2 id="naively-using-is-for-each-x_i">Naïvely using IS for each <span class="arithmatex">\(X_{i}\)</span><a class="headerlink" href="#naively-using-is-for-each-x_i" title="Permanent link">&para;</a></h2>
<p>To improve estimation of <span class="arithmatex">\(\mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}\left(X_{i} \mid Z\right)\right]\)</span>, consider importance sampling (IS) with sampling distribution <span class="arithmatex">\(Z_{i} \sim q_{i}(z)\)</span> :</p>
<div class="arithmatex">\[
\mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}\left(X_{i} \mid Z\right)\right] \approx p_{\theta}\left(X_{i} \mid Z_{i}\right) \frac{p_{Z}\left(Z_{i}\right)}{q_{i}\left(Z_{i}\right)}
\]</div>
<p>Optimal IS sampling distribution</p>
<div class="arithmatex">\[
q_{i}^{\star}(z)=\frac{p_{\theta}\left(X_{i} \mid z\right) p_{Z}(z)}{p_{\theta}\left(X_{i}\right)}=p_{\theta}\left(z \mid X_{i}\right)
\]</div>
<p>To clarify, optimal sampling distribution depends on <span class="arithmatex">\(X_{i}\)</span>. To clarify, <span class="arithmatex">\(p_{\theta}\left(X_{i}\right)\)</span> is the unkown normalizing factor so <span class="arithmatex">\(p_{\theta}\left(z \mid X_{i}\right)\)</span> is also unkown. We call <span class="arithmatex">\(q_{i}^{\star}(z)=p_{\theta}\left(z \mid X_{i}\right)\)</span> the true posterior distribution and we will soon consider the approximation <span class="arithmatex">\(q_{\phi}(z \mid x) \approx p_{\theta}(z \mid x)\)</span>, which we call the approximate posterior.</p>
<h2 id="naively-using-is-for-each-x_i_1">Naïvely using IS for each <span class="arithmatex">\(X_{i}\)</span><a class="headerlink" href="#naively-using-is-for-each-x_i_1" title="Permanent link">&para;</a></h2>
<p>For each <span class="arithmatex">\(X_{i}\)</span>, consider</p>
<div class="arithmatex">\[
\begin{gathered}
\underset{q_{i}}{\operatorname{minimize}} D_{\mathrm{KL}}\left(q_{i}(\cdot) \| p_{\theta}\left(\cdot \mid X_{i}\right)\right) \\
=\underset{q_{i}}{\operatorname{minimize}} \mathbb{E}_{Z \sim q_{i}} \log \left(\frac{q_{i}(Z)}{p_{\theta}\left(Z \mid X_{i}\right)}\right) \\
=\underset{q_{i}}{\operatorname{minimize}} \mathbb{E}_{Z \sim q_{i}} \log \left(\frac{q_{i}(Z)}{p_{\theta}\left(X_{i} \mid Z\right) p_{Z}(Z) / p_{\theta}\left(X_{i}\right)}\right) \\
=\underset{Z \sim q_{i}}{\operatorname{minimize}}\left[\log q_{i}(Z)-\log p_{Z}(Z)-\log p_{\theta}\left(X_{i} \mid Z\right)\right]+\log p_{\theta}\left(X_{i}\right)
\end{gathered}
\]</div>
<p>Note, <span class="arithmatex">\(q_{i}(z), p_{Z}(z)\)</span>, and <span class="arithmatex">\(p_{\theta}(x \mid z)\)</span> are tractable/known while <span class="arithmatex">\(p_{\theta}\left(X_{i}\right)\)</span> and <span class="arithmatex">\(p_{\theta}\left(z \mid X_{i}\right)\)</span> are intractable/unknown. Since <span class="arithmatex">\(\log p_{\theta}\left(X_{i}\right)\)</span> does not depend on <span class="arithmatex">\(q_{i}\)</span>, all quantities needed in the optimization problems are tractable. However, solving this minimization problem to obtain each <span class="arithmatex">\(q_{i}\)</span> for each data point <span class="arithmatex">\(X_{i}\)</span> is computationally too expensive.</p>
<h2 id="non-amortized-inference">Non-amortized inference<a class="headerlink" href="#non-amortized-inference" title="Permanent link">&para;</a></h2>
<p>Individual inference (not amortized): For each <span class="arithmatex">\(X_{1}, \ldots, X_{N}\)</span>, find corresponding optimal <span class="arithmatex">\(q_{1}, \ldots, q_{N}\)</span> by solving</p>
<div class="arithmatex">\[
\underset{q_{i}}{\operatorname{minimize}} \quad D_{\mathrm{KL}}\left(q_{i}(\cdot) \| p_{\theta}\left(\cdot \mid X_{i}\right)\right)
\]</div>
<p>This is expensive as it requires solving <span class="arithmatex">\(N\)</span> separate optimization problems.</p>
<p>We need variational approach and amortized inference.</p>
<h2 id="variational-approach-and-amortized-inference">Variational approach and amortized inference<a class="headerlink" href="#variational-approach-and-amortized-inference" title="Permanent link">&para;</a></h2>
<p>General principle of variational approach: We can't directly use the <span class="arithmatex">\(q\)</span> we want. So, instead, we propose a parameterized distribution <span class="arithmatex">\(q_{\phi}\)</span> that we can work with easily (in this case, sample from easily), and find a parameter setting that makes it as good as possible.</p>
<p>Parametrization of VAE:</p>
<div class="arithmatex">\[
q_{\phi}\left(z \mid X_{i}\right) \approx q_{i}^{\star}(z)=p_{\theta}\left(z \mid X_{i}\right) \quad \text { for all } i=1, \ldots, N
\]</div>
<p>Amortized inference: Train a neural network <span class="arithmatex">\(q_{\phi}(\cdot \mid x)\)</span> such that <span class="arithmatex">\(q_{\phi}\left(\cdot \mid X_{i}\right)\)</span> approximates the optimal <span class="arithmatex">\(q_{i}(\cdot)\)</span>.</p>
<div class="arithmatex">\[
\underset{\phi \in \Phi}{\operatorname{minimize}} \sum_{i=1}^{N} D_{\mathrm{KL}}\left(q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{\theta}\left(\cdot \mid X_{i}\right)\right)
\]</div>
<p>Approximation <span class="arithmatex">\(q_{\phi}\left(z \mid X_{i}\right) \approx p_{\theta}\left(z \mid X_{i}\right)\)</span> is often less precise than that of individual inference <span class="arithmatex">\(q_{i}(z) \approx\)</span> <span class="arithmatex">\(p_{\theta}\left(z \mid X_{i}\right)\)</span>, but amortized inference is often significantly faster.</p>
<h2 id="encoder-q_phi-optimization">Encoder <span class="arithmatex">\(q_{\phi}\)</span> optimization<a class="headerlink" href="#encoder-q_phi-optimization" title="Permanent link">&para;</a></h2>
<p>In analogy with autoencoders, we call <span class="arithmatex">\(q_{\phi}\)</span> the encoder.</p>
<p>Optimization problem for encoder</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \underset{\phi \in \Phi}{\operatorname{minimize}} \sum_{i=1}^{N} D_{\mathrm{KL}}\left(q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{\theta}\left(\cdot \mid X_{i}\right)\right) \\
&amp; \quad=\underset{\phi \in \Phi}{\operatorname{maximize}} \sum_{i=1}^{N} \mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\log \left(\frac{p_{\theta}\left(X_{i} \mid Z\right) p_{Z}(Z)}{q_{\phi}\left(Z \mid X_{i}\right)}\right)\right]+\text { constant independent of } \phi \\
&amp; \quad=\underset{\phi \in \Phi}{\operatorname{maximize}} \sum_{i=1}^{N} \mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\log p_{\theta}\left(X_{i} \mid Z\right)\right]-D_{\mathrm{KL}}\left(q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{Z}(\cdot)\right)
\end{aligned}
\]</div>
<h2 id="decoder-p_theta-optimization">Decoder <span class="arithmatex">\(p_{\theta}\)</span> optimization<a class="headerlink" href="#decoder-p_theta-optimization" title="Permanent link">&para;</a></h2>
<p>In analogy with autoencoders, we call <span class="arithmatex">\(p_{\theta}\)</span> the decoder. Perform approximate MLE with</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \log p_{\theta}\left(X_{i}\right)=\underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \log \mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}\left(X_{i} \mid Z\right)\right] \\
&amp; \stackrel{(a)}{\approx} \underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \log \left(\frac{p_{\theta}\left(X_{i} \mid Z_{i}\right) p_{Z}\left(Z_{i}\right)}{q_{\phi}\left(Z_{i} \mid X_{i}\right)}\right), \quad Z_{i} \sim q_{\phi}\left(z \mid X_{i}\right) \\
&amp; \stackrel{(b)}{\approx} \underset{\theta \in \Theta}{\operatorname{maximize}} \\
&amp; \sum_{i=1}^{N} \mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\log \left(\frac{p_{\theta}\left(X_{i} \mid Z\right) p_{Z}(Z)}{q_{\phi}\left(Z \mid X_{i}\right)}\right)\right] \\
&amp;=\underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\log p_{\theta}\left(X_{i} \mid Z\right)\right]-D_{\mathrm{KL}}\left(q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{Z}(\cdot)\right)
\end{aligned}
\]</div>
<p>The <span class="arithmatex">\(\stackrel{(a)}{\approx}\)</span> step replaces expectation inside the log with an estimate with <span class="arithmatex">\(Z_{i}\)</span>. The <span class="arithmatex">\(\stackrel{(b)}{\approx}\)</span> step replaces the random variable with the expectation. These steps take <span class="arithmatex">\(\mathbb{E}_{Z}\)</span> outside of the log. More on this later.</p>
<h2 id="vae-optimization">VAE optimization<a class="headerlink" href="#vae-optimization" title="Permanent link">&para;</a></h2>
<p>The optimization objectives for the encoder and decoder are the same.</p>
<p>Simultaneously train <span class="arithmatex">\(p_{\theta}\)</span> and <span class="arithmatex">\(q_{\phi}\)</span> by solving</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta, \phi \in \Phi}{\operatorname{maximize}} \sum_{i=1}^{N} \underbrace{\mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\log p_{\theta}\left(X_{i} \mid Z\right)\right]-D_{\mathrm{KL}}\left(q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{Z}(\cdot)\right)}_{\stackrel{\text { def }}{=} \mathrm{VLB}_{\theta, \phi}\left(X_{i}\right)}
\]</div>
<p>We refer to the optimization objective as the variational lower bound (VLB) or evidence lower bound (ELBO) for reasons that will be explained soon.</p>
<h2 id="vae-standard-instance">VAE standard instance<a class="headerlink" href="#vae-standard-instance" title="Permanent link">&para;</a></h2>
<p>A standard VAE setup:
Remember from hw6 that</p>
<div class="arithmatex">\[
p_{Z}=\mathcal{N}(0, I) \quad D_{\mathrm{KL}}\left(\mathcal{N}\left(\mu_{\phi}(X), \Sigma_{\phi}(X)\right) \| \mathcal{N}(0, I)\right)
\]</div>
<div class="arithmatex">\[
\begin{aligned}
&amp; q_{\phi}(z \mid x)=\mathcal{N}\left(\mu_{\phi}(x), \Sigma_{\phi}(x)\right) \text { with diagonal } \Sigma_{\phi}=\frac{1}{2}\left(\operatorname{tr}\left(\Sigma_{\phi}(X)\right)+\left\|\mu_{\phi}(X)\right\|^{2}-d-\log \operatorname{det}\left(\Sigma_{\phi}(X)\right)\right) \\
&amp; p_{\theta}(x \mid z)=\mathcal{N}\left(f_{\theta}(z), \sigma^{2} I\right)
\end{aligned}
\]</div>
<p><span class="arithmatex">\(\mu_{\phi}(x), \Sigma_{\phi}^{2}(x)\)</span>, and <span class="arithmatex">\(f_{\theta}(z)\)</span> are deterministic NN . The training objective</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta, \phi \in \Phi}{\operatorname{maximize}} \sum_{i=1}^{N} \mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\log p_{\theta}\left(X_{i} \mid Z\right)\right]-D_{\mathrm{KL}}\left(q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{Z}(\cdot)\right)
\]</div>
<p>becomes
<span class="arithmatex">\(\underset{\theta \in \Theta, \phi \in \Phi}{\operatorname{minimize}} \sum_{i=1}^{N} \frac{1}{\sigma^{2}} \mathbb{E}_{Z \sim \mathcal{N}\left(\mu_{\phi}\left(X_{i}\right), \Sigma_{\phi}\left(X_{i}\right)\right)}\left\|X_{i}-f_{\theta}(Z)\right\|^{2}+\operatorname{tr}\left(\Sigma_{\phi}\left(X_{i}\right)\right)+\left\|\mu_{\phi}\left(X_{i}\right)\right\|^{2}-\log \operatorname{det}\left(\Sigma_{\phi}\left(X_{i}\right)\right)\)</span></p>
<h2 id="with-reparameterization-trick">With reparameterization trick<a class="headerlink" href="#with-reparameterization-trick" title="Permanent link">&para;</a></h2>
<p>The standard instance of VAE
<span class="arithmatex">\(\underset{\theta \in \Theta, \phi \in \Phi}{\operatorname{minimize}} \sum_{i=1}^{N} \frac{1}{\sigma^{2}} \mathbb{E}_{Z \sim \mathcal{N}\left(\mu_{\phi}\left(X_{i}\right), \Sigma_{\phi}\left(X_{i}\right)\right)}\left\|X_{i}-f_{\theta}(Z)\right\|^{2}+\operatorname{tr}\left(\Sigma_{\phi}\left(X_{i}\right)\right)+\left\|\mu_{\phi}\left(X_{i}\right)\right\|^{2}-\log \operatorname{det}\left(\Sigma_{\phi}\left(X_{i}\right)\right)\)</span>
can be equivalently written with the reparameterization trick</p>
<div class="arithmatex">\[
\begin{gathered}
\operatorname{minimize}_{\theta \in \Theta, \phi \in \Phi} \\
\sum_{i=1}^{N} \frac{1}{\sigma^{2}} \mathbb{E}_{\varepsilon \sim \mathcal{N}(0, I)}\left\|X_{i}-f_{\theta}\left(\mu_{\phi}\left(X_{i}\right)+\Sigma_{\phi}^{1 / 2}\left(X_{i}\right) \varepsilon\right)\right\|^{2}+\operatorname{tr}\left(\Sigma_{\phi}\left(X_{i}\right)\right)+\left\|\mu_{\phi}\left(X_{i}\right)\right\|^{2}-\log \operatorname{det}\left(\Sigma_{\phi}\left(X_{i}\right)\right) \\
\text { where } \Sigma_{\phi}^{1 / 2} \text { is diagonal with } \sqrt{ } \text { of the diagonal elements of } \Sigma_{\phi} \text {. (Remember, } \Sigma_{\phi} \text { is diagonal.) }
\end{gathered}
\]</div>
<p>To clarify <span class="arithmatex">\(Z \stackrel{\mathcal{D}}{=} \mu_{\phi}\left(X_{i}\right)+\Sigma_{\phi}^{1 / 2}\left(X_{i}\right) \varepsilon\)</span>, where <span class="arithmatex">\(\stackrel{\mathcal{D}}{\underline{\mathcal{D}}}\)</span> denotes equality in distribution.</p>
<p>We now have an objective amenable to stochastic optimization.</p>
<h2 id="vae-standard-instance-architecture-training">VAE standard instance architecture: Training<a class="headerlink" href="#vae-standard-instance-architecture-training" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-364.jpg?height=1179&amp;width=1391&amp;top_left_y=491&amp;top_left_x=104" /></p>
<p>With reparameterization trick
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-364.jpg?height=1046&amp;width=1240&amp;top_left_y=491&amp;top_left_x=2009" /></p>
<h2 id="vae-standard-instance-architecture-sampling">VAE standard instance architecture: Sampling<a class="headerlink" href="#vae-standard-instance-architecture-sampling" title="Permanent link">&para;</a></h2>
<p>During sampling, only the decoder network is used.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-365.jpg?height=592&amp;width=536&amp;top_left_y=742&amp;top_left_x=1263" /></p>
<h2 id="discussions">Discussions<a class="headerlink" href="#discussions" title="Permanent link">&para;</a></h2>
<p>Review of terminology</p>
<ul>
<li>Likelihood <span class="arithmatex">\(p_{\theta}(x)\)</span> (exact evaluation intractable)</li>
<li>Prior <span class="arithmatex">\(p_{Z}(z)\)</span></li>
<li>Conditional distribution <span class="arithmatex">\(p_{\theta}(x \mid z)\)</span>
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-366.jpg?height=413&amp;width=813&amp;top_left_y=474&amp;top_left_x=1677" /></li>
<li>True posterior <span class="arithmatex">\(p_{\theta}(z \mid x)\)</span> (exact evaluation intractable)</li>
<li>Approximate posterior <span class="arithmatex">\(q_{\phi}(z \mid x)\)</span></li>
</ul>
<p>Conditional distribution <span class="arithmatex">\(p_{\theta}(x \mid z)\)</span> and prior <span class="arithmatex">\(p_{Z}(z)\)</span> determines the posterior <span class="arithmatex">\(p_{\theta}(z \mid x)\)</span>.</p>
<p>There is no easy way to evaluate <span class="arithmatex">\(p_{\theta}(x)\)</span>, but we can sample <span class="arithmatex">\(X \sim p_{\theta}(x)\)</span> easily: <span class="arithmatex">\(Z \sim p_{Z}(z)\)</span> then <span class="arithmatex">\(X \sim p_{\theta}(x \mid Z)\)</span>.</p>
<p>NN in VAE do not directly generate random output. NN outputs parameters for random sampling.</p>
<h2 id="training-vae-with-rt">Training VAE with RT<a class="headerlink" href="#training-vae-with-rt" title="Permanent link">&para;</a></h2>
<p>To obtain stochastic gradients of the VAE objective
<span class="arithmatex">\(\underset{\theta \in \Theta, \phi \in \Phi}{\operatorname{minimize}} \quad \sum_{i=1}^{N} \underbrace{\frac{1}{\sigma^{2}} \mathbb{E}_{\varepsilon \sim \mathcal{N}(0, I)}\left\|X_{i}-f_{\theta}\left(\mu_{\phi}\left(X_{i}\right)+\Sigma_{\phi}^{1 / 2}\left(X_{i}\right) \varepsilon\right)\right\|^{2}+\operatorname{tr}\left(\Sigma_{\phi}\left(X_{i}\right)\right)+\left\|\mu_{\phi}\left(X_{i}\right)\right\|^{2}-\log \operatorname{det}\left(\Sigma_{\phi}\left(X_{i}\right)\right)}\)</span>
select a data <span class="arithmatex">\(X_{i}\)</span>, sample <span class="arithmatex">\(\varepsilon_{i} \sim \mathcal{N}(0, I)\)</span>, evaluate <span class="arithmatex">\(\xlongequal{\text { def }-\mathrm{VLB}_{\theta, \phi}\left(X_{i}\right)}\)</span>
<span class="arithmatex">\(-\operatorname{VLB}_{\theta, \phi}\left(X_{i}, \varepsilon_{i}\right) \xlongequal{\text { def }} \frac{1}{\sigma^{2}}\left\|X_{i}-f_{\theta}\left(\mu_{\phi}\left(X_{i}\right)+\Sigma_{\phi}^{1 / 2}\left(X_{i}\right) \varepsilon_{i}\right)\right\|^{2}+\operatorname{tr}\left(\Sigma_{\phi}\left(X_{i}\right)\right)+\left\|\mu_{\phi}\left(X_{i}\right)\right\|^{2}-\log \operatorname{det}\left(\Sigma_{\phi}\left(X_{i}\right)\right)\)</span> and backprop on <span class="arithmatex">\(\operatorname{VLB}_{\theta, \phi}\left(X_{i}, \varepsilon_{i}\right)\)</span>.</p>
<p>Usually, batch of <span class="arithmatex">\(X_{i}\)</span> is selected.
One can sample multiple <span class="arithmatex">\(Z_{i, 1}, \ldots, Z_{i, K}\)</span> (equivalently <span class="arithmatex">\(\varepsilon_{i, 1}, \ldots, \varepsilon_{i, K}\)</span> ) for each <span class="arithmatex">\(X_{i}\)</span>.</p>
<h2 id="training-vae-with-log-derivative-trick">Training VAE with log-derivative trick<a class="headerlink" href="#training-vae-with-log-derivative-trick" title="Permanent link">&para;</a></h2>
<p>Computing stochastic gradients without the reparameterization trick.</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta, \phi \in \Phi}{\operatorname{maximize}} \sum_{i=1}^{N} \underbrace{\mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\log \left(\frac{p_{\theta}\left(X_{i} \mid Z\right) p_{Z}(Z)}{q_{\phi}\left(Z \mid X_{i}\right)}\right)\right]}_{\stackrel{\text { def }}{=} \operatorname{VLB}_{\theta, \phi}\left(X_{i}\right)}
\]</div>
<p>To obtain unbiased estimates of <span class="arithmatex">\(\nabla_{\theta}\)</span>, compute</p>
<div class="arithmatex">\[
\frac{1}{K} \sum_{k=1}^{K} \log p_{\theta}\left(X_{i} \mid Z_{i, k}\right), \quad Z_{i, 1}, \ldots, Z_{i, K} \sim q_{\phi}\left(z \mid X_{i}\right)
\]</div>
<p>and backprop with respect to <span class="arithmatex">\(\theta\)</span>.</p>
<h2 id="training-vae-with-log-derivative-trick_1">Training VAE with log-derivative trick<a class="headerlink" href="#training-vae-with-log-derivative-trick_1" title="Permanent link">&para;</a></h2>
<p>We differentiate the VLB objectives (cf. hw 8 problem 8)</p>
<div class="arithmatex">\[
\begin{aligned}
\nabla_{\phi} \mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\log \left(\frac{p_{\theta}\left(X_{i} \mid Z\right) p_{Z}(Z)}{q_{\phi}\left(Z \mid X_{i}\right)}\right)\right] &amp; =\nabla_{\phi} \int \log \left(\frac{p_{\theta}\left(X_{i} \mid z\right) p_{Z}(z)}{q_{\phi}\left(z \mid X_{i}\right)}\right) q_{\phi}\left(z \mid X_{i}\right) d z \\
&amp; =\mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\left(\nabla_{\phi} \log q_{\phi}\left(Z \mid X_{i}\right)\right) \log \left(\frac{p_{\theta}\left(X_{i} \mid Z\right) p_{Z}(Z)}{q_{\phi}\left(Z \mid X_{i}\right)}\right)\right]
\end{aligned}
\]</div>
<p>To obtain unbiased estimates of <span class="arithmatex">\(\nabla_{\phi}\)</span>, compute</p>
<div class="arithmatex">\[
\frac{1}{K} \sum_{k=1}^{K}\left(\nabla_{\phi} \log q_{\phi}\left(Z_{i, k} \mid X_{i}\right)\right) \log \left(\frac{p_{\theta}\left(X_{i} \mid Z_{i, k}\right) p_{Z}\left(Z_{i, k}\right)}{q_{\phi}\left(Z_{i, k} \mid X_{i}\right)}\right), \quad Z_{i, 1}, \ldots, Z_{i, K} \sim q_{\phi}\left(z \mid X_{i}\right)
\]</div>
<h2 id="why-variational-autoencoder">Why variational "autoencoder"?<a class="headerlink" href="#why-variational-autoencoder" title="Permanent link">&para;</a></h2>
<p>VAE loss (VLB) contains a reconstruction loss resembling that of an autoencoder.</p>
<div class="arithmatex">\[
\begin{aligned}
\operatorname{VLB}_{\theta, \phi}\left(X_{i}\right) &amp; =\mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\log p_{\theta}\left(X_{i} \mid Z\right)\right]-D_{\mathrm{KL}}\left(q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{Z}(\cdot)\right) \\
&amp; =-\frac{1}{2 \sigma^{2}} \mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\left\|X_{i}-f_{\theta}(Z)\right\|^{2}\right]-D_{\mathrm{KL}}\left(q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{Z}(\cdot)\right) \\
&amp; =-\underbrace{\frac{1}{2 \sigma^{2}} \mathbb{E}_{\varepsilon \sim \mathcal{N}(0, I)}\left\|X_{i}-f_{\theta}\left(\mu_{\phi}\left(X_{i}\right)+\Sigma_{\phi}^{1 / 2}\left(X_{i}\right) \varepsilon\right)\right\|^{2}}_{\text {Reconstruction loss }}-\underbrace{D_{\mathrm{KL}}\left(q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{Z}(\cdot)\right)}_{\text {Regularization }}
\end{aligned}
\]</div>
<p>VLB also contains a regularization term on the output of the encoder, which is not present in standard autoencoder losses.</p>
<p>The choice of <span class="arithmatex">\(\sigma\)</span> determines the relative weight between the reconstruction loss and the regularization.</p>
<h2 id="how-tight-is-the-vlb">How tight is the VLB?<a class="headerlink" href="#how-tight-is-the-vlb" title="Permanent link">&para;</a></h2>
<p>How accurate is the approximation?</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \log p_{\theta}\left(X_{i}\right)=\underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \log \mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\frac{p_{\theta}\left(X_{i} \mid Z\right) p_{Z}(Z)}{q_{\phi}\left(Z \mid X_{i}\right)}\right] \\
&amp; \stackrel{?}{\approx} \underset{\theta \in \Theta, \phi \in \Phi}{\operatorname{maximize}} \sum_{i=1}^{N} \mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\log \left(\frac{p_{\theta}\left(X_{i} \mid Z\right) p_{Z}(Z)}{q_{\phi}\left(Z \mid X_{i}\right)}\right)\right] \\
&amp;=\underset{\theta \in \Theta, \phi \in \Phi}{\operatorname{maximize}} \sum_{i=1}^{N} \operatorname{VLB}_{\theta, \phi}\left(X_{i}\right)
\end{aligned}
\]</div>
<p>This turns out that <span class="arithmatex">\(\log p_{\theta}\left(X_{i}\right) \geq \operatorname{VLB}_{\theta, \phi}\left(X_{i}\right)\)</span>. So we are maximizing a lower bound of the log likelihood. How large is the gap?</p>
<h2 id="log-likelihood-geq-vlb-derivation-1">Log-likelihood <span class="arithmatex">\(\geq\)</span> VLB: Derivation 1<a class="headerlink" href="#log-likelihood-geq-vlb-derivation-1" title="Permanent link">&para;</a></h2>
<p>Derivation via Jensen:</p>
<div class="arithmatex">\[
\begin{aligned}
\log p_{\theta}\left(X_{i}\right) &amp; =\log \mathbb{E}_{Z \sim p_{Z}}\left[p_{\theta}\left(X_{i} \mid Z\right)\right] \\
&amp; =\log \left(\mathbb{E}_{Z \sim q_{\phi}\left(Z \mid X_{i}\right)}\left[p_{\theta}\left(X_{i} \mid Z\right) \frac{p_{Z}(Z)}{q_{\phi}\left(Z \mid X_{i}\right)}\right]\right) \\
&amp; \geq \mathbb{E}_{Z \sim q_{\phi}\left(Z \mid X_{i}\right)}\left[\log \left(p_{\theta}\left(X_{i} \mid Z\right) \frac{p_{Z}(Z)}{q_{\phi}\left(Z \mid X_{i}\right)}\right)\right] \\
&amp; \stackrel{\text { def }}{=} \mathrm{VLB}_{\theta, \phi}\left(X_{i}\right)
\end{aligned}
\]</div>
<p>Does not explicitly characterize gap.</p>
<h2 id="log-likelihood-geq-vlb-derivation-2">Log-likelihood <span class="arithmatex">\(\geq\)</span> VLB: Derivation 2<a class="headerlink" href="#log-likelihood-geq-vlb-derivation-2" title="Permanent link">&para;</a></h2>
<p>Derivation via KL divergence:</p>
<div class="arithmatex">\[
\begin{aligned}
D_{\mathrm{KL}}\left[q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{\theta}\left(\cdot \mid X_{i}\right)\right] &amp; =\mathbb{E}_{Z \sim q_{\theta}\left(z \mid X_{i}\right)}\left[\log q_{\theta}\left(Z \mid X_{i}\right)-\log p_{\theta}\left(Z \mid X_{i}\right)\right] \\
&amp; =\underbrace{\mathbb{E}_{Z \sim q_{\theta}\left(z \mid X_{i}\right)}\left[\log q_{\theta}\left(Z \mid X_{i}\right)-\log p_{Z}(Z)-\log p_{\theta}\left(X_{i} \mid Z\right)\right]}_{=-\mathrm{VLB}_{\theta, \phi}\left(X_{i}\right)}+\log p_{\theta}\left(X_{i}\right)
\end{aligned}
\]</div>
<p>and</p>
<div class="arithmatex">\[
\begin{aligned}
\log p_{\theta}\left(X_{i}\right) &amp; =\operatorname{VLB}_{\theta, \phi}\left(X_{i}\right)+D_{\mathrm{KL}}\left[q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{\theta}\left(\cdot \mid X_{i}\right)\right] \\
&amp; \geq \operatorname{VLB}_{\theta, \phi}\left(X_{i}\right)
\end{aligned}
\]</div>
<p>This derivation explicitly characterizes the gap as <span class="arithmatex">\(D_{\mathrm{KL}}\left[q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{\theta}\left(\cdot \mid X_{i}\right)\right]\)</span>.</p>
<h2 id="vlb-is-tight-if-encoder-infinitely-powerful">VLB is tight if encoder infinitely powerful<a class="headerlink" href="#vlb-is-tight-if-encoder-infinitely-powerful" title="Permanent link">&para;</a></h2>
<p>If the encoder <span class="arithmatex">\(q_{\phi}\)</span> is powerful enough such that there is a <span class="arithmatex">\(\phi^{\star}\)</span> achieving</p>
<div class="arithmatex">\[
q_{\phi^{\star}}\left(\cdot \mid X_{i}\right)=p_{\theta}\left(\cdot \mid X_{i}\right)
\]</div>
<p>or equivalently</p>
<div class="arithmatex">\[
D_{\mathrm{KL}}\left[q_{\phi^{\star}}\left(\cdot \mid X_{i}\right) \| p_{\theta}\left(\cdot \mid X_{i}\right)\right]=0
\]</div>
<p>Then</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{maximize}} \sum_{i=1}^{N} \log p_{\theta}\left(X_{i}\right)={\underset{\theta}{\theta \in \Theta, \phi \in \Phi}}_{\operatorname{maximize}} \sum_{i=1}^{N} \operatorname{VLB}_{\theta, \phi}\left(X_{i}\right)
\]</div>
<p>This follows from</p>
<div class="arithmatex">\[
\log p_{\theta}\left(X_{i}\right)=\operatorname{VLB}_{\theta, \phi}\left(X_{i}\right)+\underbrace{D_{\mathrm{KL}}\left[q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{\theta}\left(\cdot \mid X_{i}\right)\right]}_{\geq 0}
\]</div>
<p>and hw 8 problem 2.</p>
<h2 id="vq-vae">VQ-VAE<a class="headerlink" href="#vq-vae" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-375.jpg?height=821&amp;width=3250&amp;top_left_y=542&amp;top_left_x=29" /></p>
<p>Figure 2: Left: ImageNet <span class="arithmatex">\(128 \times 128 \times 3\)</span> images, right: reconstructions from a VQ-VAE with a <span class="arithmatex">\(32 \times 32 \times 1\)</span> latent space, with <span class="arithmatex">\(\mathrm{K}=512\)</span>.</p>
<h2 id="vq-vae_1">VQ-VAE<a class="headerlink" href="#vq-vae_1" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-376.jpg?height=1187&amp;width=3197&amp;top_left_y=376&amp;top_left_x=63" /></p>
<p>Figure 3: Samples (128x128) from a VQ-VAE with a PixelCNN prior trained on ImageNet images.</p>
<h2 id="vq-vae-2">VQ-VAE-2<a class="headerlink" href="#vq-vae-2" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-377.jpg?height=1710&amp;width=2750&amp;top_left_y=0&amp;top_left_x=170" /></p>
<h2 id="vq-vae-2_1">VQ-VAE-2<a class="headerlink" href="#vq-vae-2_1" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-378.jpg?height=1303&amp;width=2610&amp;top_left_y=399&amp;top_left_x=338" />
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-379.jpg?height=738&amp;width=3107&amp;top_left_y=154&amp;top_left_x=224" /></p>
<div class="arithmatex">\[
\ell_{\theta, \phi}\left(X_{i}\right)=\mathbb{E}_{Z \sim q_{\phi}\left(z \mid X_{i}\right)}\left[\log p_{\theta}\left(X_{i} \mid Z\right)\right]-\beta D_{\mathrm{KL}}\left(q_{\phi}\left(\cdot \mid X_{i}\right) \| p_{Z}(\cdot)\right)
\]</div>
<p>when <span class="arithmatex">\(\beta=1, \ell_{\theta, \phi}\left(X_{i}\right)=\operatorname{VLB}_{\theta, \phi}\left(X_{i}\right)\)</span>, i.e., <span class="arithmatex">\(\beta\)</span>-VAE coincides with VAE when <span class="arithmatex">\(\beta=1\)</span>.</p>
<p>With <span class="arithmatex">\(\beta&gt;1\)</span>, authors observed better feature disentanglement.</p>
<h2 id="minimax-optimization">Minimax optimization<a class="headerlink" href="#minimax-optimization" title="Permanent link">&para;</a></h2>
<p>In a minimax optimization problem we minimize with respect to one variable and maximize with respect to another:</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{minimize}} \underset{\phi \in \Phi}{\operatorname{maximize}} \mathcal{L}(\theta, \phi)
\]</div>
<p>We say <span class="arithmatex">\(\left(\theta^{\star}, \phi^{\star}\right)\)</span> is a solution to the minimax problem if <span class="arithmatex">\(\theta^{\star} \in \Theta, \phi^{\star} \in \Phi\)</span>, and</p>
<div class="arithmatex">\[
\mathcal{L}\left(\theta^{\star}, \phi\right) \leq \mathcal{L}\left(\theta^{\star}, \phi^{\star}\right) \leq \mathcal{L}\left(\theta, \phi^{\star}\right), \quad \forall \theta \in \Theta, \phi \in \Phi .
\]</div>
<p>In other words, unilaterally deviating from <span class="arithmatex">\(\theta^{\star} \in \Theta\)</span> increases the value of <span class="arithmatex">\(\mathcal{L}(\theta, \phi)\)</span> while unilaterally deviating from <span class="arithmatex">\(\phi^{\star} \in \Phi\)</span> decreases the value of <span class="arithmatex">\(\mathcal{L}(\theta, \phi)\)</span>. In yet other words, the solution is defined as a Nash equilibrium in a 2-player zero-sum game.</p>
<h2 id="minimax-optimization_1">Minimax optimization<a class="headerlink" href="#minimax-optimization_1" title="Permanent link">&para;</a></h2>
<p>So far, we trained NN by solving minimization problems.</p>
<p>However, GANs are trained by solving minimax problems. Since the advent of GANs, minimax training has become more widely used in all areas of deep learning.</p>
<p>Examples:</p>
<ul>
<li>Adversarial training to make NN robust against adversarial attacks.</li>
<li>Domain adversarial networks to train NN to make fair decisions (e.g. not base its decision on a persons race or gender).</li>
</ul>
<h2 id="minimax-vs-maximin">Minimax vs. maximin<a class="headerlink" href="#minimax-vs-maximin" title="Permanent link">&para;</a></h2>
<p>When a solution (as we defined it) does not exist, then min-max is not the same as max-min:</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{minimize}} \underset{\phi \in \Phi}{\operatorname{maximize}} \mathcal{L}(\theta, \phi) \neq \underset{\phi \in \Phi}{\operatorname{maximize}} \underset{\theta \in \Theta}{\operatorname{minimize}} \mathcal{L}(\theta, \phi)
\]</div>
<p>This is a technical distinction that we will not explore in this class.</p>
<h2 id="minimax-optimization-algorithm">Minimax optimization algorithm<a class="headerlink" href="#minimax-optimization-algorithm" title="Permanent link">&para;</a></h2>
<p>First, consider deterministic gradient setup. Let <span class="arithmatex">\(\alpha\)</span> and <span class="arithmatex">\(\beta\)</span> be the stepsizes (learning rates) for the descent and ascent steps respectively.</p>
<p>Simultaneous gradient ascent-descent:</p>
<div class="arithmatex">\[
\begin{aligned}
\phi^{k+1} &amp; =\phi^{k}+\beta \nabla_{\phi} \mathcal{L}\left(\theta^{k}, \phi^{k}\right) \\
\theta^{k+1} &amp; =\theta^{k}-\alpha \nabla_{\theta} \mathcal{L}\left(\theta^{k}, \phi^{k}\right)
\end{aligned}
\]</div>
<p>Alternating gradient ascent-descent:</p>
<div class="arithmatex">\[
\begin{aligned}
\phi^{k+1} &amp; =\phi^{k}+\beta \nabla_{\phi} \mathcal{L}\left(\theta^{k}, \phi^{k}\right) \\
\theta^{k+1} &amp; =\theta^{k}-\alpha \nabla_{\theta} \mathcal{L}\left(\theta^{k}, \phi^{k+1}\right)
\end{aligned}
\]</div>
<h2 id="minimax-optimization-algorithm_1">Minimax optimization algorithm<a class="headerlink" href="#minimax-optimization-algorithm_1" title="Permanent link">&para;</a></h2>
<p>Gradient multi-ascent-single-descent:</p>
<div class="arithmatex">\[
\begin{aligned}
\phi_{0}^{k+1} &amp; =\phi_{n_{\mathrm{dis}}}^{k} \\
\phi_{i+1}^{k+1} &amp; =\phi_{i}^{k+1}+\beta \nabla_{\phi} \mathcal{L}\left(\theta^{k}, \phi_{i}^{k+1}\right), \quad \text { for } i=0, \ldots, n_{\mathrm{dis}}-1 \\
\theta^{k+1} &amp; =\theta^{k}-\alpha \nabla_{\theta} \mathcal{L}\left(\theta^{k}, \phi_{n_{\mathrm{dis}}}^{k+1}\right)
\end{aligned}
\]</div>
<p>( <span class="arithmatex">\(n_{\text {dis }}\)</span> stands for number of discriminator updates.) When <span class="arithmatex">\(n_{\text {dis }}=1\)</span>, this algorithm reduces to alternating ascent-descent.</p>
<h2 id="stochastic-minimax-optimization">Stochastic minimax optimization<a class="headerlink" href="#stochastic-minimax-optimization" title="Permanent link">&para;</a></h2>
<p>In deep learning, however, we have access to stochastic gradients.</p>
<p>Stochastic gradient simultaneous ascent-descent</p>
<div class="arithmatex">\[
\begin{array}{rlrl}
\phi^{k+1} &amp; =\phi^{k}+\beta g_{\phi}^{k}, &amp; \mathbb{E}\left[g_{\phi}^{k}\right]=\nabla_{\phi} \mathcal{L}\left(\theta^{k}, \phi^{k}\right) \\
\theta^{k+1} &amp; =\theta^{k}-\alpha g_{\theta}^{k}, &amp; &amp; \mathbb{E}\left[g_{\theta}^{k}\right]=\nabla_{\theta} \mathcal{L}\left(\theta^{k}, \phi^{k}\right)
\end{array}
\]</div>
<p>Stochastic gradient alternating ascent-descent</p>
<div class="arithmatex">\[
\begin{array}{rlrl}
\phi^{k+1} &amp; =\phi^{k}+\beta g_{\phi}^{k}, &amp; \mathbb{E}\left[g_{\phi}^{k}\right]=\nabla_{\phi} \mathcal{L}\left(\theta^{k}, \phi^{k}\right) \\
\theta^{k+1}=\theta^{k}-\alpha g_{\theta}^{k}, &amp; \mathbb{E}\left[g_{\theta}^{k}\right]=\nabla_{\theta} \mathcal{L}\left(\theta^{k}, \phi^{k+1}\right)
\end{array}
\]</div>
<p>Stochastic gradient multi-ascent-single-descent</p>
<div class="arithmatex">\[
\begin{array}{rlr}
\phi_{0}^{k+1} &amp; =\phi_{n_{\text {dis }}}^{k} \\
\phi_{i+1}^{k+1} &amp; =\phi_{i}^{k+1}+\beta \nabla_{\phi} g_{\phi}^{k, i}, \quad \mathbb{E}\left[g_{\phi}^{k, i}\right]=\nabla_{\phi} \mathcal{L}\left(\theta^{k}, \phi_{i}^{k+1}\right), \quad \text { for } i=0, \ldots, n_{\text {dis }}-1 \\
\theta^{k+1} &amp; =\theta^{k}-\alpha g_{\theta}^{k}, \quad \mathbb{E}\left[g_{\theta}^{k}\right]=\nabla_{\theta} \mathcal{L}\left(\theta^{k}, \phi_{n_{\text {dis }}^{k}}^{k+1}\right)
\end{array}
\]</div>
<h2 id="minimax-optimization-in-pytorch">Minimax optimization in PyTorch<a class="headerlink" href="#minimax-optimization-in-pytorch" title="Permanent link">&para;</a></h2>
<p>To perform minimax optimization in PyTorch, we maintain two separate optimizers, one for the ascent, one for the descent. The OPTIMIZER can be anything like SGD or Adam.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a>G = Generator(...).to(device)
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a>D = Discriminator(...).to(device)
</span><span id="__span-10-3"><a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a>D_optimizer = optim.OPTIMIZER(D.parameters(), lr = beta)
</span><span id="__span-10-4"><a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a>G_optimizer = optim.OPTIMIZER(G.parameters(), lr = alpha)
</span></code></pre></div>
<p>Simultaneous ascent-descent:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a>Evaluate D_loss
</span><span id="__span-11-2"><a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>D_loss.backward()
</span><span id="__span-11-3"><a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a>Evaluate G_loss
</span><span id="__span-11-4"><a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a>G_loss.backward()
</span><span id="__span-11-5"><a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a>D_optimizer.step()
</span><span id="__span-11-6"><a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a>G_optimizer.step()
</span></code></pre></div>
<h2 id="minimax-optimization-in-pytorch_1">Minimax optimization in PyTorch<a class="headerlink" href="#minimax-optimization-in-pytorch_1" title="Permanent link">&para;</a></h2>
<p>Alternating ascent-descent</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a>Evaluate D_loss
</span><span id="__span-12-2"><a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a>D_loss.backward()
</span><span id="__span-12-3"><a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a>D_optimizer.step()
</span><span id="__span-12-4"><a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a>Evaluate G_loss
</span><span id="__span-12-5"><a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a>G_loss.backward()
</span><span id="__span-12-6"><a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a>G_optimizer.step()
</span></code></pre></div>
<h2 id="minimax-optimization-in-pytorch_2">Minimax optimization in PyTorch<a class="headerlink" href="#minimax-optimization-in-pytorch_2" title="Permanent link">&para;</a></h2>
<p>Multi-ascent-single-descent</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-13-1"><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a>for _ in range(ndis) :
</span><span id="__span-13-2"><a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a>    Evaluate D loss
</span><span id="__span-13-3"><a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a>    D_loss.backward()
</span><span id="__span-13-4"><a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a>    D_optimizer.step()
</span><span id="__span-13-5"><a id="__codelineno-13-5" name="__codelineno-13-5" href="#__codelineno-13-5"></a>Evaluate G_loss
</span><span id="__span-13-6"><a id="__codelineno-13-6" name="__codelineno-13-6" href="#__codelineno-13-6"></a>G_loss.backward()
</span><span id="__span-13-7"><a id="__codelineno-13-7" name="__codelineno-13-7" href="#__codelineno-13-7"></a>G_optimizer.step()
</span></code></pre></div>
<h2 id="generative-adversarial-networks-gan">Generative adversarial networks (GAN)<a class="headerlink" href="#generative-adversarial-networks-gan" title="Permanent link">&para;</a></h2>
<p>These are synthetic (fake) images.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-389.jpg?height=1153&amp;width=3330&amp;top_left_y=597&amp;top_left_x=2" /></p>
<h2 id="gan">GAN<a class="headerlink" href="#gan" title="Permanent link">&para;</a></h2>
<p>In generative adversarial networks (GAN) a generator network and a discriminator network compete adversarially.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-390.jpg?height=792&amp;width=1778&amp;top_left_y=29&amp;top_left_x=1552" /></p>
<p>Given data <span class="arithmatex">\(X_{1}, \ldots, X_{N} \sim p_{\text {true }}\)</span>. GAN aims to learn <span class="arithmatex">\(p_{\theta} \approx p_{\text {true }}\)</span>.</p>
<p>Generator aims to generate fake data similar to training data.</p>
<p>Discriminator aims to distinguish the training data from fake data.</p>
<p>Analogy: Criminal creating fake money vs. police distinguishing fake money from real.</p>
<h2 id="generator-network">Generator network<a class="headerlink" href="#generator-network" title="Permanent link">&para;</a></h2>
<p>The generator <span class="arithmatex">\(G_{\theta}: \mathbb{R}^{k} \rightarrow \mathbb{R}^{n}\)</span> is a neural network parameterized by <span class="arithmatex">\(\theta \in \Theta\)</span>. The generator takes a random latent vector <span class="arithmatex">\(Z \sim p_{Z}\)</span> as input and outputs generated (fake) data <span class="arithmatex">\(\tilde{X}=G_{\theta}(Z)\)</span>. The latent distribution is usually <span class="arithmatex">\(p_{Z}=\mathcal{N}(0, I)\)</span>.</p>
<p>Write <span class="arithmatex">\(p_{\theta}\)</span> for the probability distribution of <span class="arithmatex">\(\tilde{X}=G_{\theta}(Z)\)</span>. Although we can't evaluate the density <span class="arithmatex">\(p_{\theta}(x)\)</span>, neither exactly nor approximately, we can sample from <span class="arithmatex">\(\tilde{X} \sim p_{\theta}\)</span>.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-391.jpg?height=422&amp;width=1226&amp;top_left_y=1226&amp;top_left_x=1798" /></p>
<h2 id="discriminator-network">Discriminator network<a class="headerlink" href="#discriminator-network" title="Permanent link">&para;</a></h2>
<p>The discriminator <span class="arithmatex">\(D_{\phi}: \mathbb{R}^{n} \rightarrow(0,1)\)</span> is a neural network parameterized by <span class="arithmatex">\(\phi \in \Phi\)</span>. The discriminator takes an image <span class="arithmatex">\(X\)</span> as input and outputs whether <span class="arithmatex">\(X\)</span> is a real or fake.#</p>
<ul>
<li><span class="arithmatex">\(D_{\phi}(X) \approx 1\)</span> : discriminator confidently predicts <span class="arithmatex">\(X\)</span> is real.</li>
<li><span class="arithmatex">\(D_{\phi}(X) \approx 0\)</span> : discriminator confidently predicts <span class="arithmatex">\(X\)</span> is fake.</li>
<li><span class="arithmatex">\(D_{\phi}(X) \approx 0.5\)</span> : discriminator is unsure whether <span class="arithmatex">\(X\)</span> is real or fake.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-392.jpg?height=784&amp;width=1532&amp;top_left_y=1071&amp;top_left_x=250" />
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-392.jpg?height=809&amp;width=1060&amp;top_left_y=1058&amp;top_left_x=1860" /></li>
</ul>
<h2 id="discriminator-loss">Discriminator loss<a class="headerlink" href="#discriminator-loss" title="Permanent link">&para;</a></h2>
<p>Cost of incorrectly classifying real as fake (type I error):</p>
<div class="arithmatex">\[
\mathbb{E}_{X \sim p_{\text {true }}}\left[-\log D_{\phi}(X)\right]
\]</div>
<p>Cost of incorrectly classifying fake as real (type II error):</p>
<div class="arithmatex">\[
\mathbb{E}_{\tilde{X} \sim p_{\theta}}\left[-\log \left(1-D_{\phi}(\tilde{X})\right)\right]=\mathbb{E}_{Z \sim \mathcal{N}(0, I)}\left[-\log \left(1-D_{\phi}\left(G_{\theta}(Z)\right)\right)\right]
\]</div>
<p>Discriminator solves</p>
<div class="arithmatex">\[
\underset{\phi \in \Phi}{\operatorname{maximize}} \quad \mathbb{E}_{X \sim p_{\text {true }}}\left[\log D_{\phi}(X)\right]+\mathbb{E}_{\tilde{X} \sim p_{\theta}}\left[\log \left(1-D_{\phi}(\tilde{X})\right)\right]
\]</div>
<p>which is equivalent to</p>
<div class="arithmatex">\[
\underset{\phi \in \Phi}{\operatorname{maximize}} \quad \mathbb{E}_{X \sim p_{\text {true }}}\left[\log D_{\phi}(X)\right]+\mathbb{E}_{Z \sim \mathcal{N}(0, I)}\left[\log \left(1-D_{\phi}\left(G_{\theta}(Z)\right)\right)\right]
\]</div>
<h2 id="discriminator-loss_1">Discriminator loss<a class="headerlink" href="#discriminator-loss_1" title="Permanent link">&para;</a></h2>
<p>We can view</p>
<div class="arithmatex">\[
\mathbb{E}_{\tilde{X} \sim p_{\theta}}\left[\log \left(1-D_{\phi}(\tilde{X})\right)\right]=\mathbb{E}_{Z \sim \mathcal{N}(0, I)}\left[\log \left(1-D_{\phi}\left(G_{\theta}(Z)\right)\right)\right]
\]</div>
<p>as an instance of the reparameterization technique.</p>
<p>The loss</p>
<div class="arithmatex">\[
\mathbb{E}_{X \sim p_{\text {true }}}\left[\log D_{\phi}(X)\right]+\mathbb{E}_{\tilde{X} \sim p_{\theta}}\left[\log \left(1-D_{\phi}(\tilde{X})\right)\right]
\]</div>
<p>puts equal weight on type I and type II errors. Alternatively, one can use the loss</p>
<div class="arithmatex">\[
\mathbb{E}_{X \sim p_{\text {true }}}\left[\log D_{\phi}(X)\right]+\lambda \mathbb{E}_{\tilde{X} \sim p_{\theta}}\left[\log \left(1-D_{\phi}(\tilde{X})\right)\right]
\]</div>
<p>where <span class="arithmatex">\(\lambda&gt;0\)</span> represents the relative significance of a type II error over a type I error.</p>
<h2 id="generator-loss">Generator loss<a class="headerlink" href="#generator-loss" title="Permanent link">&para;</a></h2>
<p>Since the goal of the generator is to deceive the discriminator, the generator minimizes the same loss.</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{minimize}} \quad \mathbb{E}_{X \sim p_{\text {true }}}\left[\log D_{\phi}(X)\right]+\mathbb{E}_{Z \sim \mathcal{N}(0, I)}\left[\log \left(1-D_{\phi}\left(G_{\theta}(Z)\right)\right)\right]
\]</div>
<p>(The generator and discriminator operate under a zero-sum game.)</p>
<p>Note, only the second term depend on <span class="arithmatex">\(\theta\)</span>, while the both terms depend on <span class="arithmatex">\(\phi\)</span>.</p>
<h2 id="empirical-risk-minimization">Empirical risk minimization<a class="headerlink" href="#empirical-risk-minimization" title="Permanent link">&para;</a></h2>
<p>In practice, we have finite samples <span class="arithmatex">\(X_{1}, \ldots, X_{N}\)</span>, so we instead use the loss</p>
<div class="arithmatex">\[
\frac{1}{N} \sum_{i=1}^{N} \log D_{\phi}\left(X_{i}\right)+\mathbb{E}_{Z \sim \mathcal{N}(0, I)}\left[\log \left(1-D_{\phi}\left(G_{\theta}(Z)\right)\right)\right]
\]</div>
<p>Since <span class="arithmatex">\(\tilde{X}=G_{\theta}(Z)\)</span> is generated with <span class="arithmatex">\(Z \sim p_{Z}\)</span>, we have unlimited <span class="arithmatex">\(\tilde{X}\)</span> samples. So we replace <span class="arithmatex">\(\mathbb{E}_{X} \approx \frac{1}{N} \sum\)</span> while leaving <span class="arithmatex">\(\mathbb{E}_{Z}\)</span> as is.</p>
<h2 id="minimax-training-zero-sum-game">Minimax training (zero-sum game)<a class="headerlink" href="#minimax-training-zero-sum-game" title="Permanent link">&para;</a></h2>
<p>Train generator and discriminator simultaneously by solving</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{minimize}} \underset{\phi \in \Phi}{\operatorname{maximize}} \mathcal{L}(\theta, \phi)
\]</div>
<p>where</p>
<div class="arithmatex">\[
\mathcal{L}(\theta, \phi)=\frac{1}{N} \sum_{i=1}^{N} \log D_{\phi}\left(X_{i}\right)+\mathbb{E}_{Z \sim \mathcal{N}(0, I)}\left[\log \left(1-D_{\phi}\left(G_{\theta}(Z)\right)\right)\right]
\]</div>
<p>It remains to specify the architectures for <span class="arithmatex">\(G_{\theta}\)</span> and <span class="arithmatex">\(D_{\phi}\)</span>.</p>
<h2 id="gan-demo">GAN demo<a class="headerlink" href="#gan-demo" title="Permanent link">&para;</a></h2>
<p>PyTorch demo</p>
<h2 id="dcgan">DCGAN<a class="headerlink" href="#dcgan" title="Permanent link">&para;</a></h2>
<p>The original GAN was also deep and convolutional. However, Radford et al.'s Deep Convolutional Generative Adversarial Networks (DCGAN) paper proposed the following architectures, which crucially utilize batchnorm.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-399.jpg?height=1005&amp;width=2434&amp;top_left_y=756&amp;top_left_x=233" /></p>
<h2 id="math-review-f-divergence">Math review: f-divergence<a class="headerlink" href="#math-review-f-divergence" title="Permanent link">&para;</a></h2>
<p>The f -divergence of <span class="arithmatex">\(p\)</span> from <span class="arithmatex">\(q\)</span>, where <span class="arithmatex">\(f\)</span> is a convex function such that <span class="arithmatex">\(f(1)=0\)</span>, is</p>
<div class="arithmatex">\[
D_{f}(p \| q)=\int f\left(\frac{p(x)}{q(x)}\right) q(x) d x,
\]</div>
<p>This includes the KL divergence:</p>
<ul>
<li>If <span class="arithmatex">\(f(u)=u \log u\)</span>, then <span class="arithmatex">\(D_{f}(p \| q)=D_{\mathrm{KL}}(p \| q)\)</span>.</li>
<li>If <span class="arithmatex">\(f(u)=-\log u\)</span>, then <span class="arithmatex">\(D_{f}(p \| q)=D_{\text {KL }}(q \| p)\)</span>.</li>
</ul>
<h2 id="math-review-js-divergence">Math review: JS-divergence<a class="headerlink" href="#math-review-js-divergence" title="Permanent link">&para;</a></h2>
<p>Jensen-Shannon-divergence (JS-divergence) is</p>
<div class="arithmatex">\[
D_{\mathrm{JS}}(p, q)=\frac{1}{2} D_{\mathrm{KL}}\left(p \| \frac{1}{2}(p+q)\right)+\frac{1}{2} D_{\mathrm{KL}}\left(q \| \frac{1}{2}(p+q)\right)
\]</div>
<p>With, <span class="arithmatex">\(f(u)=\left\{\begin{array}{ll}\frac{1}{2}\left(u \log u-(u+1) \log \frac{u+1}{2}\right) &amp; \text { for } u \geq 0 \\ \infty &amp; \text { otherwise }\end{array}\right.\)</span> we have <span class="arithmatex">\(D_{f}=D_{\mathrm{IS}}\)</span>.</p>
<p>With, <span class="arithmatex">\(f(u)=\left\{\begin{array}{ll}u \log u-(u+1) \log (u+1)+\log 4 &amp; \text { for } u \geq 0 \\ \infty &amp; \text { otherwise }\end{array}\right.\)</span> we have <span class="arithmatex">\(D_{f}=2 D_{\mathrm{JS}}\)</span>.</p>
<h2 id="gan-approx-jsd-minimization">GAN <span class="arithmatex">\(\approx\)</span> JSD minimization<a class="headerlink" href="#gan-approx-jsd-minimization" title="Permanent link">&para;</a></h2>
<p>Let us understand the minimax problem</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{minimize}} \underset{\phi \in \Phi}{\operatorname{maximize}} \mathcal{L}(\theta, \phi)
\]</div>
<p>via the minimization problem</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{minimize}} \mathcal{J}(\theta)
\]</div>
<p>where</p>
<div class="arithmatex">\[
\mathcal{J}(\theta)=\sup _{\phi \in \Phi} \mathcal{L}(\theta, \phi)
\]</div>
<p>For simplicity, assume the discriminator is infinitely powerful, i.e., <span class="arithmatex">\(D_{\phi}(x)\)</span> can represent any arbitrary function.</p>
<h2 id="gan-approx-jsd-minimization_1">GAN <span class="arithmatex">\(\approx\)</span> JSD minimization<a class="headerlink" href="#gan-approx-jsd-minimization_1" title="Permanent link">&para;</a></h2>
<p>Note</p>
<div class="arithmatex">\[
\begin{aligned}
\mathcal{L}(\theta, \phi) &amp; =\mathbb{E}_{X \sim p_{\text {true }}}\left[\log D_{\phi}(X)\right]+\mathbb{E}_{Z \sim \mathcal{N}(0, I)}\left[\log \left(1-D_{\phi}\left(G_{\theta}(Z)\right)\right)\right] \\
&amp; =\mathbb{E}_{X \sim p_{\text {true }}}\left[\log D_{\phi}(X)\right]+\mathbb{E}_{\tilde{X} \sim p_{\theta}}\left[\log \left(1-D_{\phi}(\tilde{X})\right)\right] \\
&amp; =\int p_{\text {true }}(x) \log D_{\phi}(x)+p_{\theta}(x) \log \left(1-D_{\phi}(x)\right) d x
\end{aligned}
\]</div>
<p>Since</p>
<div class="arithmatex">\[
\frac{d}{d y}(a \log y+b \log (1-y))=0 \quad \Rightarrow \quad y^{\star}=\frac{a}{a+b}
\]</div>
<p>The integral is maximized by</p>
<div class="arithmatex">\[
D_{\phi^{\star}}(x)=\frac{p_{\text {true }}(x)}{p_{\text {true }}(x)+p_{\theta}(x)}
\]</div>
<h2 id="g-a-n-approx-j-s-d-minimization"><span class="arithmatex">\(G A N \approx J S D\)</span> minimization<a class="headerlink" href="#g-a-n-approx-j-s-d-minimization" title="Permanent link">&para;</a></h2>
<p>If we plug in the optimal discriminator,</p>
<div class="arithmatex">\[
D_{\phi^{\star}}(x)=\frac{p_{\text {true }}(x)}{p_{\text {true }}(x)+p_{\theta}(x)}
\]</div>
<p>we get</p>
<div class="arithmatex">\[
\begin{aligned}
\mathcal{L}\left(\theta, \phi^{\star}\right) &amp; =\mathbb{E}_{X \sim p_{\text {true }}}\left[\log \frac{p_{\text {true }}(X)}{p_{\text {true }}(X)+p_{\theta}(X)}\right]+\mathbb{E}_{\tilde{X} \sim p_{\theta}}\left[\log \frac{p_{\theta}(\tilde{X})}{p_{\text {true }}(\tilde{X})+p_{\theta}(\tilde{X})}\right] \\
&amp; =2 D_{\mathrm{JS}}\left(p_{\text {true }}, p_{\theta}\right)-\log (4)
\end{aligned}
\]</div>
<p>Therefore,</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{minimize}} \underset{\phi \in \Phi}{\operatorname{maximize}} \mathcal{L}(\theta, \phi) \approx \underset{\theta \in \Theta}{\operatorname{minimize}} D_{\mathrm{JS}}\left(p_{\text {true }}, p_{\theta}\right)
\]</div>
<h2 id="f-gan">f-GAN<a class="headerlink" href="#f-gan" title="Permanent link">&para;</a></h2>
<p>With GANs, we started from a minimax formulation and later reinterpreted it as minimizing the JS-divergence.</p>
<p>Let us instead the start from an f-divergence minimization</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{minimize}} \quad D_{f}\left(p_{\text {true }} \| p_{\theta}\right)
\]</div>
<p>and then variationally approximate <span class="arithmatex">\(D_{f}\)</span> to obtain a minimax formulation.</p>
<p>Variational approach: Evaluating <span class="arithmatex">\(D_{f}\)</span> directly is difficult, so we pose it as a maximization problem and parameterize the maximizing function as a "discriminator" neural network.</p>
<h2 id="f-gan_1">f-GAN<a class="headerlink" href="#f-gan_1" title="Permanent link">&para;</a></h2>
<p>For simplicity, however, we only consider the order</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{minimize}} \quad D_{f}\left(p_{\text {true }} \| p_{\theta}\right)
\]</div>
<p>However, one can also consider</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{minimize}} \quad D_{f}\left(p_{\theta} \| p_{\text {true }}\right)
\]</div>
<p>to obtain similar results.
(During our coverage of f-GANs, we will have notational conflict between <span class="arithmatex">\(D_{f}\)</span>, the fdivergence, and <span class="arithmatex">\(D_{\phi}\)</span>, the discriminator network. Hopefully there won't be any confusion.)</p>
<h2 id="convex-conjugate">Convex conjugate<a class="headerlink" href="#convex-conjugate" title="Permanent link">&para;</a></h2>
<p>Let <span class="arithmatex">\(f: \mathbb{R} \rightarrow \mathbb{R} \cup\{\infty\}\)</span>. Define the convex conjugate of <span class="arithmatex">\(f\)</span> as</p>
<div class="arithmatex">\[
f^{*}(t)=\sup _{u \in \mathbb{R}}\{t u-f(u)\}
\]</div>
<p>where <span class="arithmatex">\(f^{*}: \mathbb{R} \rightarrow \mathbb{R} \cup\{\infty\}\)</span>. This is also referred to as the Legendre transform.</p>
<p>If <span class="arithmatex">\(f\)</span> is a nice <span class="arithmatex">\({ }^{\#}\)</span> convex function, then <span class="arithmatex">\(f^{*}\)</span> is convex and <span class="arithmatex">\(f^{* *}=f\)</span>, i.e., the conjugate of the conjugate is the original function. <span class="arithmatex">\({ }^{\%}\)</span> So</p>
<div class="arithmatex">\[
f(u)=\sup _{t \in \mathbb{R}}\left\{t u-f^{*}(t)\right\}
\]</div>
<h2 id="convex-conjugate-examples">Convex conjugate: Examples<a class="headerlink" href="#convex-conjugate-examples" title="Permanent link">&para;</a></h2>
<p>The following are some examples. Computation of <span class="arithmatex">\(f^{*}\)</span> uses basic calculus.</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; f_{\mathrm{KL}}(u)= \begin{cases}u \log u &amp; \text { for } u \geq 0 \\
\infty &amp; \text { otherwise } \\
-\log u &amp; \text { for } u&gt;0 \\
\infty &amp; \text { otherwise }\end{cases} \\
&amp; f_{\mathrm{LK}}(u)=\left\{\begin{array}{ll}
\mathrm{KL}
\end{array}\right)=\exp (t-1) \\
&amp; f_{\mathrm{SH}}(u)=(\sqrt{u}-1)^{2} \\
&amp; f_{\mathrm{JS}}(u)= \begin{cases}-1-\log (-t) &amp; \text { for } t&lt;0 \\
\infty &amp; f_{\mathrm{SH}}^{*}(t)= \begin{cases}\frac{1}{1 / t-1} &amp; \text { for } t&lt;1 \\
\infty \log u-(u+1) \log (u+1)+\log 4 &amp; \text { for } u \geq 0 \\
\infty &amp; \text { otherwise }\end{cases} \\
f_{\mathrm{JS}}^{*}(t)= \begin{cases}-\log (1-\exp (t))-\log 4 &amp; \text { for } t&lt;0 \\
\infty &amp; \text { otherwise }\end{cases} \end{cases}
\end{aligned}
\]</div>
<p>(Keeping track of the <span class="arithmatex">\(\infty\)</span> output is necessary.)
<span class="arithmatex">\(K L=K L\)</span>, LK=reverse-KL, SH=squared Hellinger distance, JS=JS</p>
<h2 id="convex-conjugate-examples_1">Convex conjugate: Examples<a class="headerlink" href="#convex-conjugate-examples_1" title="Permanent link">&para;</a></h2>
<p>We get the following f-divergences: <span class="arithmatex">\(D_{f_{\mathrm{KL}}}(p \| q)=D_{\mathrm{KL}}(p \| q)\)</span></p>
<div class="arithmatex">\[
\begin{aligned}
&amp; D_{f_{\mathrm{LK}}}(p \| q)=D_{\mathrm{KL}}(q \| p) \\
&amp; D_{f_{\mathrm{SH}}}(p \| q)=D_{\mathrm{SH}}(q, p) \\
&amp; D_{f_{\mathrm{JS}}}(p \| q)=2 D_{\mathrm{JS}}(q, p)
\end{aligned}
\]</div>
<p>We don't use the following property, but it's interesting so we mention it. If <span class="arithmatex">\(f\)</span> and <span class="arithmatex">\(f^{*}\)</span> are differentiable, then <span class="arithmatex">\(\left(f^{\prime}\right)^{-1}=\left(f^{*}\right)^{\prime}\)</span> :</p>
<div class="arithmatex">\[
\begin{array}{ll}
\frac{d}{d u} f_{\mathrm{KL}}(u)=1+\log u &amp; \frac{d}{d t} f_{\mathrm{KL}}^{*}(t)=\exp (t-1) \\
\frac{d}{d u} f_{\mathrm{LK}}(u)=-\frac{1}{u} &amp; \frac{d}{d t} f_{\mathrm{LK}}^{*}(t)=-\frac{1}{t} \\
\frac{d}{d u} f_{\mathrm{SH}}(u)=1-\frac{1}{\sqrt{u}} &amp; \frac{d}{d t} f_{\mathrm{SH}}^{*}(t)=\frac{1}{(1-t)^{2}} \\
\frac{d}{d u} f_{\mathrm{JS}}(u)=\log \frac{u}{1+u} &amp; \frac{d}{d t} f_{\mathrm{JS}}^{*}(t)=\frac{1}{e^{-t}-1}
\end{array}
\]</div>
<h2 id="variational-formulation-of-f-divergence">Variational formulation of f-divergence<a class="headerlink" href="#variational-formulation-of-f-divergence" title="Permanent link">&para;</a></h2>
<p>Variational formulation of f-divergence:</p>
<div class="arithmatex">\[
\begin{aligned}
D_{f}(p \| q) &amp; =\int q(x) f\left(\frac{p(x)}{q(x)}\right) d x \\
&amp; =\int q(x) \sup _{t}\left\{t \frac{p(x)}{q(x)}-f^{*}(t)\right\} d x=\int q(x) T^{\star}(x) \frac{p(x)}{q(x)}-q(x) f^{*}\left(T^{\star}(x)\right) d x \\
&amp; =\sup _{T \in \mathcal{T}}\left(\int p(x) T(x) d x-\int q(x) f^{*}(T(x)) d x\right)=\sup _{T \in \mathcal{T}}\left(\mathbb{E}_{X \sim p}[T(X)]-\mathbb{E}_{\tilde{X} \sim q}\left[f^{*}(T(\tilde{X}))\right]\right) \\
&amp; \geq \sup _{\phi \in \Phi}\left(\mathbb{E}_{X \sim p}\left[D_{\phi}(X)\right]-\mathbb{E}_{\tilde{X} \sim q}\left[f^{*}\left(D_{\phi}(\tilde{X})\right)\right]\right)
\end{aligned}
\]</div>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-410.jpg?height=171&amp;width=2804&amp;top_left_y=1424&amp;top_left_x=231" /> <span class="arithmatex">\(D_{\phi}\)</span> is a neural network parameterized by <span class="arithmatex">\(\phi\)</span>.</p>
<h2 id="f-gan-minimax-formulation">f-GAN minimax formulation<a class="headerlink" href="#f-gan-minimax-formulation" title="Permanent link">&para;</a></h2>
<p>Minimax formulation of f-GANs.</p>
<div class="arithmatex">\[
\begin{gathered}
\underset{\theta \in \Theta}{\operatorname{minimize}} D_{f}\left(p_{\text {true }} \| p_{\theta}\right) \\
\approx \underset{\theta \in \Theta}{\operatorname{minimize}} \underset{\phi \in \Phi}{\operatorname{maximize}} \mathbb{E}_{X \sim p_{\text {true }}}\left[D_{\phi}(X)\right]-\mathbb{E}_{Z \sim \mathcal{N}(0, I)}\left[f^{*}\left(D_{\phi}\left(G_{\theta}(Z)\right)\right)\right]
\end{gathered}
\]</div>
<h2 id="f-gan-with-kl-divergence">f-GAN with KL-divergence<a class="headerlink" href="#f-gan-with-kl-divergence" title="Permanent link">&para;</a></h2>
<p>Instantiate f-GAN with KL-divergence: <span class="arithmatex">\(f^{*}(t)=e^{t-1}\)</span>.</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \underset{\theta \in \Theta}{\operatorname{minimize}} \quad D_{\mathrm{KL}}\left(p_{\text {true }} \| p_{\theta}\right) \\
&amp; \approx \underset{\theta \in \Theta}{\operatorname{minimize}} \underset{\phi \in \Phi}{\operatorname{maximize}} \mathbb{E}_{X \sim p_{\text {true }}}\left[D_{\phi}(X)\right]-\mathbb{E}_{Z \sim \mathcal{N}(0, I)}\left[e^{D_{\phi}\left(G_{\theta}(Z)\right)-1}\right] \\
&amp; \stackrel{(*)}{=} \underset{\theta \in \Theta}{\operatorname{minimize}} \underset{\phi \in \Phi}{\operatorname{maximize}} 1+\mathbb{E}_{X \sim p_{\text {true }}}\left[D_{\phi}(X)\right]-\mathbb{E}_{Z \sim \mathcal{N}(0, I)}\left[e^{D_{\phi}\left(G_{\theta}(Z)\right)}\right] \\
&amp; =\underset{\theta \in \Theta}{\operatorname{minimize}} \underset{\phi \in \Phi}{\operatorname{maximize}} \mathbb{E}_{X \sim p_{\text {true }}}\left[D_{\phi}(X)\right]-\mathbb{E}_{Z \sim \mathcal{N}(0, I)}\left[e^{D_{\phi}\left(G_{\theta}(Z)\right)}\right]
\end{aligned}
\]</div>
<p>Step (*) uses the substitution <span class="arithmatex">\(D_{\phi} \mapsto D_{\phi}+1\)</span>, which is valid if the final layer of <span class="arithmatex">\(D_{\phi}\)</span> has a trainable bias term. ( <span class="arithmatex">\(D_{\phi}: \mathbb{R}^{n} \rightarrow \mathbb{R}\)</span>.)</p>
<h2 id="f-gan-with-squared-hellinger">f-GAN with squared Hellinger<a class="headerlink" href="#f-gan-with-squared-hellinger" title="Permanent link">&para;</a></h2>
<p>Instantiate f-GAN with squared Hellinger distance <span class="arithmatex">\(\#: f^{*}(t)= \begin{cases}\frac{1}{1 / t-1} &amp; \text { if } t&lt;1 \\ \infty &amp; \text { otherwise }\end{cases}\)</span></p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{minimize}} \quad D_{\mathrm{SH}}\left(p_{\text {true }}, p_{\theta}\right)
\]</div>
<div class="arithmatex">\[
\approx \begin{array}{lll}
\underset{\theta \in \Theta}{\operatorname{minimize}} &amp; \begin{array}{l}
\operatorname{maximize} \\
\\
\\
\text { subject to }
\end{array} &amp; \mathbb{E}_{X \sim p_{\text {true }}}\left[D_{\phi}(X)\right]-\mathbb{E}_{Z \sim \mathcal{N}(0, I)}\left[\frac{1}{1 /\left(D_{\phi}\left(G_{\theta}(Z)\right)\right)-1}\right] \\
\left.D_{\theta}(z)\right)&lt;1 \text { for all } z \in \mathbb{R}^{k}
\end{array}
\]</div>
<p>When the constraint is violated, the <span class="arithmatex">\(f^{*}(t)=\infty\)</span> case makes the maximization objective <span class="arithmatex">\(-\infty\)</span>. However, directly enforcing the neural networks to satisfy <span class="arithmatex">\(D_{\phi}\left(G_{\theta}(z)\right)&lt;1\)</span> is awkward.</p>
<h2 id="solution-output-activation-rho">Solution: Output activation <span class="arithmatex">\(\rho\)</span><a class="headerlink" href="#solution-output-activation-rho" title="Permanent link">&para;</a></h2>
<p>When <span class="arithmatex">\(D_{\phi}: \mathbb{R}^{n} \rightarrow \mathbb{R}\)</span> and <span class="arithmatex">\(\left\{t \mid f^{*}(t)&lt;\infty\right\} \neq \mathbb{R}\)</span>, then <span class="arithmatex">\(f^{*}\left(D_{\phi}(\tilde{X})\right)=\infty\)</span> is possible. To prevent this, substitute <span class="arithmatex">\(T(x) \mapsto \rho(\tilde{T}(x))\)</span>, where <span class="arithmatex">\(\rho: \mathbb{R} \rightarrow\left\{t \mid f^{*}(t)&lt;\infty\right\}\)</span> is a one-to-one function:</p>
<div class="arithmatex">\[
\begin{aligned}
D_{f}(p \| q) &amp; =\sup _{T \in \mathcal{T}}\left\{\mathbb{E}_{X \sim p}[T(X)]-\mathbb{E}_{\tilde{X} \sim q}\left[f^{*}(T(\tilde{X}))\right]\right\} \\
&amp; \stackrel{(*)}{=} \sup _{\substack{T \in \mathcal{T}}}\left\{\mathbb{E}_{X \sim p}[T(X)]-\mathbb{E}_{\tilde{X} \sim q}\left[f^{*}(T(\tilde{X}))\right]\right\} \\
&amp; \stackrel{(* *)}{=} \sup _{\tilde{T} \in \mathcal{T}}\left\{\mathbb{E}_{X \sim p}[\rho(\tilde{T}(X))]-\mathbb{E}_{\tilde{X} \sim q}\left[f^{*}(\rho(\tilde{T}(\tilde{X})))\right]\right\} \\
&amp; \geq \sup _{\phi \in \Phi}\left\{\mathbb{E}_{X \sim p}\left[\rho\left(D_{\phi}(X)\right)\right]-\mathbb{E}_{\tilde{X} \sim q}\left[f^{*}\left(\rho\left(D_{\phi}(\tilde{X})\right)\right)\right]\right\}
\end{aligned}
\]</div>
<p>(<em>) We can restrict the search over <span class="arithmatex">\(T\)</span> since if <span class="arithmatex">\(f^{*}(T(x))=\infty\)</span>, then the objective becomes <span class="arithmatex">\(-\infty\)</span>.# (</em>*) With <span class="arithmatex">\(T=\rho \circ \tilde{T}\)</span>, have <span class="arithmatex">\(\left[T \in \mathcal{T}\right.\)</span> and <span class="arithmatex">\(\left.f^{*}(T(x))&lt;\infty\right] \Leftrightarrow[\tilde{T} \in \mathcal{T}]\)</span> since <span class="arithmatex">\(\rho\)</span> is one-to-one.</p>
<h2 id="f-gan-with-output-activation">f-GAN with output activation<a class="headerlink" href="#f-gan-with-output-activation" title="Permanent link">&para;</a></h2>
<p>Formulate f-GAN with output activation function <span class="arithmatex">\(\rho\)</span> :</p>
<div class="arithmatex">\[
\begin{gathered}
\operatorname{minimize}_{\theta \in \Theta}^{\min } \quad D_{f}\left(p_{\text {true }} \| p_{\theta}\right) \\
\approx \underset{\theta \in \Theta}{\operatorname{minimize}} \underset{\phi \in \Phi}{\operatorname{maximize}} \quad \mathbb{E}_{X \sim p_{\text {true }}}\left[\rho\left(D_{\phi}(X)\right)\right]-\mathbb{E}_{Z \sim \mathcal{N}(0, I)}\left[f^{*}\left(\rho\left(D_{\phi}\left(G_{\theta}(Z)\right)\right)\right)\right]
\end{gathered}
\]</div>
<h2 id="f-gan-with-squared-hellinger_1">f-GAN with squared Hellinger<a class="headerlink" href="#f-gan-with-squared-hellinger_1" title="Permanent link">&para;</a></h2>
<p>Instantiate f-GAN with squared Hellinger distance using <span class="arithmatex">\(\rho(r)=1-e^{-r}\)</span> and</p>
<div class="arithmatex">\[
f^{*}(t)= \begin{cases}\frac{1}{1 / t-1} &amp; \text { if } t&lt;1 \\ \infty &amp; \text { otherwise }\end{cases}
\]</div>
<p>Note that <span class="arithmatex">\(f^{*}(\rho(r))=-1+e^{r}\)</span>.</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{minimize}} \quad D_{\mathrm{SH}}\left(p_{\text {true }}, p_{\theta}\right)
\]</div>
<div class="arithmatex">\[
\begin{array}{cc}
\approx \underset{\theta \in \Theta}{\operatorname{minimize}} &amp; \underset{\phi \in \Phi}{\operatorname{maximize}} \\
=\underset{\theta \in \Theta}{\operatorname{minimize}} &amp; 2-\mathbb{E}_{X \sim p_{\text {true }}}\left[e^{-D_{\phi}(X)}\right]-\mathbb{E}_{Z \sim \mathcal{N}(0, I)}\left[e^{D_{\phi}\left(G_{\theta}(Z)\right)}\right] \\
\underset{\phi \in \Phi}{ } \operatorname{maximize}-\mathbb{E}_{X \sim p_{\text {true }}}\left[e^{-D_{\phi}(X)}\right]-\mathbb{E}_{Z \sim \mathcal{N}(0, I)}\left[e^{D_{\phi}\left(G_{\theta}(Z)\right)}\right]
\end{array}
\]</div>
<h2 id="f-gan-with-reverse-kl">f-GAN with reverse KL<a class="headerlink" href="#f-gan-with-reverse-kl" title="Permanent link">&para;</a></h2>
<p>Instantiate f-GAN with reverse KL using <span class="arithmatex">\(\rho(r)=-e^{r}\)</span> and</p>
<div class="arithmatex">\[
f^{*}(t)= \begin{cases}-1-\log (-t) &amp; \text { if } t&lt;0 \\ \infty &amp; \text { otherwise }\end{cases}
\]</div>
<p>Note that <span class="arithmatex">\(f^{*}(\rho(r))=-1-r\)</span>.</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{minimize}} \quad D_{\mathrm{KL}}\left(p_{\theta} \| p_{\text {true }}\right)
\]</div>
<div class="arithmatex">\[
\begin{aligned}
&amp; \approx \underset{\theta \in \Theta}{\operatorname{minimize}} \underset{\phi \in \Phi}{\operatorname{maximize}} 1-\mathbb{E}_{X \sim p_{\text {true }}}\left[e^{D_{\phi}(X)}\right]+\mathbb{E}_{Z \sim \mathcal{N}(0, I)}\left[D_{\phi}\left(G_{\theta}(Z)\right)\right] \\
&amp; =\underset{\theta \in \Theta}{\operatorname{minimize}} \underset{\phi \in \Phi}{\operatorname{maximize}}-\mathbb{E}_{X \sim p_{\text {true }}}\left[e^{D_{\phi}(X)}\right]+\mathbb{E}_{Z \sim \mathcal{N}(0, I)}\left[D_{\phi}\left(G_{\theta}(Z)\right)\right]
\end{aligned}
\]</div>
<h2 id="recovering-standard-gan">Recovering standard GAN<a class="headerlink" href="#recovering-standard-gan" title="Permanent link">&para;</a></h2>
<p>We recover standard GAN with</p>
<div class="arithmatex">\[
\rho(r)=\log (\sigma(r)), \quad \sigma(r)=\frac{1}{1+e^{-r}}, \quad f^{*}(t)= \begin{cases}-\log (1-\exp (t))-\log 4 &amp; \text { for } t&lt;0 \\ \infty &amp; \text { otherwise }\end{cases}
\]</div>
<p>Note that <span class="arithmatex">\(\sigma\)</span> is the familiar sigmoid and</p>
<div class="arithmatex">\[
f^{*}(\rho(r))=-\log (1-\sigma(r))-\log 4
\]</div>
<div class="arithmatex">\[
\begin{gathered}
\operatorname{minimize}_{\theta \in \Theta} D_{\mathrm{JS}}\left(p_{\text {true }}, p_{\theta}\right) \\
\underset{\theta \in \Theta}{\operatorname{minimize}} \underset{\phi \in \Phi}{\operatorname{maximize}} \mathbb{E}_{X \sim p_{\text {true }}}\left[\log \sigma\left(D_{\phi}(X)\right)\right]+\mathbb{E}_{Z \sim \mathcal{N}(0, I)}\left[\log \left(1-\sigma\left(D_{\phi}\left(G_{\theta}(X)\right)\right)\right)\right]
\end{gathered}
\]</div>
<p>where <span class="arithmatex">\(D_{\phi}: \mathbb{R}^{n} \rightarrow \mathbb{R}\)</span>.
(Standard GAN has <span class="arithmatex">\(D_{\phi}: \mathbb{R}^{n} \rightarrow(0,1)\)</span>. Here, <span class="arithmatex">\(\left(\sigma \circ D_{\phi}\right): \mathbb{R}^{n} \rightarrow(0,1)\)</span> serves the same purpose.)</p>
<h2 id="wgan">WGAN<a class="headerlink" href="#wgan" title="Permanent link">&para;</a></h2>
<p>The Wasserstein GAN (WGAN) minimizes the Wasserstein distance:</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{minimize}} \quad W\left(p_{\text {true }}, p_{\theta}\right)
\]</div>
<p>The <span class="arithmatex">\(W(p, q)\)</span> is a distance (metric) on probability distributions defined as</p>
<div class="arithmatex">\[
W(p, q)=\inf _{f} \mathbb{E}_{(X, Y) \sim f(x, y)}\|X-Y\|
\]</div>
<p>where the infimum is taken over joint probability distributions <span class="arithmatex">\(f\)</span> with marginals <span class="arithmatex">\(p\)</span> and <span class="arithmatex">\(q\)</span>, i.e.,</p>
<div class="arithmatex">\[
p(x)=\int f(x, y) d y, \quad q(y)=\int f(x, y) d x
\]</div>
<p>(The mathematics of <span class="arithmatex">\(W(p, q)\)</span> exceeds the scope of this class, but I still want to give you a high-level exposure to WGANs.)</p>
<h2 id="wp-q-by-optimal-transport"><span class="arithmatex">\(W(p, q)\)</span> by optimal transport<a class="headerlink" href="#wp-q-by-optimal-transport" title="Permanent link">&para;</a></h2>
<p>Another equivalent formulation of the Wasserstein distance is by the theory of optimal transport. Given distributions <span class="arithmatex">\(p\)</span> and <span class="arithmatex">\(q\)</span> (initial and target)</p>
<div class="arithmatex">\[
W(p, q)=\inf _{T} \int\|x-T(x)\| p(x) d x
\]</div>
<p>where <span class="arithmatex">\(T\)</span> is a transport plan that transports <span class="arithmatex">\(p\)</span> to <span class="arithmatex">\(q .{ }^{\%}\)</span> Figuratively speaking, we are transporting grains of sand from one pile to another, and we wan to minimize the aggregate transport distance.
<img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-420.jpg?height=1216&amp;width=2243&amp;top_left_y=391&amp;top_left_x=1087" /></p>
<p>Transport plan <span class="arithmatex">\(T\)</span> from <span class="arithmatex">\(p\)</span> to <span class="arithmatex">\(q\)</span>.</p>
<h2 id="minimax-via-kr-duality">Minimax via KR duality<a class="headerlink" href="#minimax-via-kr-duality" title="Permanent link">&para;</a></h2>
<p>Kantorovich-Rubinstein duality# establishes:</p>
<div class="arithmatex">\[
W\left(p_{\text {true }}, p_{\theta}\right)=\sup _{\|T\|_{L \leq 1}} \mathbb{E}_{X \sim p_{\text {true }}}[T(X)]-\mathbb{E}_{\tilde{X} \sim p_{\theta}}[T(\tilde{X})]
\]</div>
<p>Minimax formulation of WGAN:</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{minimize}} W\left(p_{\text {true }}, p_{\theta}\right)
\]</div>
<div class="arithmatex">\[
\approx \underset{\theta \in \Theta}{\operatorname{minimize}} \begin{array}{ll}
\operatorname{maximize} \\
\text { subject to } &amp; \mathbb{E}_{X \sim p_{\text {truu }}}\left[D_{\phi}(X)\right]-\mathbb{E}_{\tilde{X} \sim p_{\theta}} \text { is 1-Lipschitz }
\end{array}
\]</div>
<h2 id="spectral-normalization">Spectral normalization<a class="headerlink" href="#spectral-normalization" title="Permanent link">&para;</a></h2>
<p>How do we enforce the constraint that <span class="arithmatex">\(D_{\phi}\)</span> is 1-Lipschitz? Consider an MLP:</p>
<div class="arithmatex">\[
\begin{aligned}
y_{L}= &amp; A_{L} y_{L-1}+b_{L} \\
y_{L-1}= &amp; \sigma\left(A_{L-1} y_{L-2}+b_{L-1}\right) \\
&amp; \vdots \\
y_{2}= &amp; \sigma\left(A_{2} y_{1}+b_{2}\right) \\
y_{1}= &amp; \sigma\left(A_{1} x+b_{1}\right),
\end{aligned}
\]</div>
<p>where <span class="arithmatex">\(\sigma\)</span> is a 1-Lipschitz continuous activation function, such as ReLU and tanh. If</p>
<div class="arithmatex">\[
\left\|A_{i}\right\|_{\mathrm{op}}=\sigma_{\max }\left(A_{i}\right) \leq 1
\]</div>
<p>for <span class="arithmatex">\(i=1, \ldots, L\)</span>, where <span class="arithmatex">\(\sigma_{\text {max }}\)</span> denotes the largest singular value, then each layer is 1-Lipschitz continuous and the entire mapping <span class="arithmatex">\(x \mapsto y_{L}\)</span> is 1 -Lipschitz. (A sufficient, but not a necessary, condition.)</p>
<h2 id="spectral-normalization_1">Spectral normalization<a class="headerlink" href="#spectral-normalization_1" title="Permanent link">&para;</a></h2>
<p>Replace Lipschitz constraint with a singular-value constraint</p>
<div class="arithmatex">\[
\begin{array}{rll}
\underset{\theta \in \Theta}{\operatorname{minimize}} &amp; \underset{\phi \in \Phi}{\operatorname{maximize}} &amp; \frac{1}{N} \sum_{i=1}^{N} D_{\phi}\left(X_{i}\right)-\mathbb{E}_{Z \sim \mathcal{N}(0, I)}\left[D_{\phi}\left(G_{\theta}(Z)\right)\right] \\
&amp; \text { subject to } &amp; \sigma_{\max }\left(A_{i}\right) \leq 1, \quad i=1, \ldots, L
\end{array}
\]</div>
<p>Constraint is handled with a projected gradient method. (Note that <span class="arithmatex">\(A_{1}, \ldots, A_{L}\)</span> are part of the discriminator parameters <span class="arithmatex">\(\phi\)</span>.)
(Specifically, one performs an (approximate) projection after the ascent step in the stochastic gradient ascent-descent methods. The approximate projection involves computing the largest singular with the power iteration.)</p>
<h2 id="conclusion_1">Conclusion<a class="headerlink" href="#conclusion_1" title="Permanent link">&para;</a></h2>
<p>We discussed the following unsupervised learning techniques:</p>
<ul>
<li>Autoencoders</li>
<li>Flow models</li>
<li>Variational autoencoders</li>
<li>GANs</li>
</ul>
<p>Unsupervised learning techniques, particularly generative models, tend to utilize more math in their formulations. This chapter provided a brief and gentle introduction to the mathematical foundations of these formulations.</p>
<h1 id="appendix-a-basics-of-monte-carlo">Appendix A: <br> Basics of Monte Carlo<a class="headerlink" href="#appendix-a-basics-of-monte-carlo" title="Permanent link">&para;</a></h1>
<p>Mathematical Foundations of Deep Neural Networks
Spring 2024
Department of Mathematical Sciences
Ernest K. Ryu
Seoul National University</p>
<h2 id="monte-carlo">Monte Carlo<a class="headerlink" href="#monte-carlo" title="Permanent link">&para;</a></h2>
<p>We quickly cover some basic notions of Monte Carlo simulations.</p>
<p>These concepts will be used with VAEs.</p>
<p>These ideas are also extensively used in reinforcement learning (although not a topic of this course).</p>
<h2 id="monte-carlo-estimation">Monte Carlo estimation<a class="headerlink" href="#monte-carlo-estimation" title="Permanent link">&para;</a></h2>
<p>Consider IID data <span class="arithmatex">\(X_{1}, \ldots, X_{N} \sim f\)</span>. Let <span class="arithmatex">\(\phi(X) \geq 0\)</span> be some function*. Consider the problem of estimating</p>
<div class="arithmatex">\[
I=\mathbb{E}_{X \sim f}[\phi(X)]=\int \phi(x) f(x) d x
\]</div>
<p>One commonly uses</p>
<div class="arithmatex">\[
\hat{I}_{N}=\frac{1}{N} \sum_{i=1}^{N} \phi\left(X_{i}\right)
\]</div>
<p>to estimate <span class="arithmatex">\(I\)</span>. After all, <span class="arithmatex">\(\mathbb{E}\left[\hat{I}_{N}\right]=I\)</span> and <span class="arithmatex">\(\hat{I}_{N} \rightarrow I\)</span> by the law of large numbers.#</p>
<h2 id="monte-carlo-estimation_1">Monte Carlo estimation<a class="headerlink" href="#monte-carlo-estimation_1" title="Permanent link">&para;</a></h2>
<p>We can quantify convergence with variance:</p>
<div class="arithmatex">\[
\operatorname{Var}_{X \sim f}\left(\hat{I}_{N}\right)=\sum_{i=1}^{N} \operatorname{Var}_{X_{i} \sim f}\left(\frac{\phi\left(X_{i}\right)}{N}\right)=\frac{1}{N} \operatorname{Var}_{X \sim f}(\phi(X))
\]</div>
<p>In other words</p>
<div class="arithmatex">\[
\mathbb{E}\left[\left(\hat{I}_{N}-I\right)^{2}\right]=\frac{1}{N} \operatorname{Var}_{X \sim f}(\phi(X))
\]</div>
<p>and</p>
<div class="arithmatex">\[
\mathbb{E}\left[\left(\hat{I}_{N}-I\right)^{2}\right] \rightarrow 0
\]</div>
<p>as <span class="arithmatex">\(N \rightarrow \infty\)</span>.#</p>
<h2 id="empirical-risk-minimization_1">Empirical risk minimization<a class="headerlink" href="#empirical-risk-minimization_1" title="Permanent link">&para;</a></h2>
<p>In machine learning and statistics, we often wish to solve</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{minimize}} \quad \mathcal{L}(\theta)
\]</div>
<p>where the objective function</p>
<div class="arithmatex">\[
\mathcal{L}(\theta)=\mathbb{E}_{X \sim p_{X}}\left[\ell\left(f_{\theta}(X), f_{\star}(X)\right)\right]
\]</div>
<p>Is the (true) risk. However, the evaluation of <span class="arithmatex">\(\mathbb{E}_{X \sim p_{X}}\)</span> is impossible (if <span class="arithmatex">\(p_{X}\)</span> is unknown) or intractable (if <span class="arithmatex">\(p_{X}\)</span> is known but the expectation has no closed-form solution). Therefore, we define the proxy loss function</p>
<div class="arithmatex">\[
\mathcal{L}_{N}(\theta)=\frac{1}{N} \sum_{i=1}^{N} \ell\left(f_{\theta}\left(X_{i}\right), f_{\star}\left(X_{i}\right)\right)
\]</div>
<p>which we call the empirical risk, and solve</p>
<div class="arithmatex">\[
\underset{\theta \in \Theta}{\operatorname{minimize}} \quad \mathcal{L}_{N}(\theta)
\]</div>
<h2 id="empirical-risk-minimization_2">Empirical risk minimization<a class="headerlink" href="#empirical-risk-minimization_2" title="Permanent link">&para;</a></h2>
<p>This is called empirical risk minimization (ERM). The idea is that</p>
<div class="arithmatex">\[
\mathcal{L}_{N}(\theta) \approx \mathcal{L}(\theta)
\]</div>
<p>with high probability, so minimizing <span class="arithmatex">\(\mathcal{L}_{N}(\theta)\)</span> should be similar to minimizing <span class="arithmatex">\(\mathcal{L}(\theta)\)</span>.</p>
<p>Technical note) The law of large numbers tells us that</p>
<div class="arithmatex">\[
\mathbb{P}\left(\left|\mathcal{L}_{N}(\theta)-\mathcal{L}(\theta)\right|&gt;\varepsilon\right)=\text { small }
\]</div>
<p>for any given <span class="arithmatex">\(\theta\)</span>, but we need</p>
<div class="arithmatex">\[
\mathbb{P}\left(\sup _{\theta \in \Theta}\left|\mathcal{L}_{N}(\theta)-\mathcal{L}(\theta)\right|&gt;\varepsilon\right)=\text { small }
\]</div>
<p>for all compact <span class="arithmatex">\(\Theta\)</span> in order to conclude that the argmins of the two losses to be similar. These types of results are established by a uniform law of large numbers.</p>
<h2 id="importance-sampling">Importance sampling<a class="headerlink" href="#importance-sampling" title="Permanent link">&para;</a></h2>
<p>Importance sampling (IS) is a technique for reducing the variance of a Monte Carlo estimator.</p>
<p>Key insight of important sampling:</p>
<div class="arithmatex">\[
I=\int \phi(x) f(x) d x=\int \frac{\phi(x) f(x)}{g(x)} g(x) d x=\mathbb{E}_{X \sim g}\left[\frac{\phi(X) f(X)}{g(X)}\right]
\]</div>
<p>(We do have to be mindful of division by 0.) Then</p>
<div class="arithmatex">\[
\hat{I}_{N}=\frac{1}{N} \sum_{i=1}^{N} \phi\left(X_{i}\right) \frac{f\left(X_{i}\right)}{g\left(X_{i}\right)}
\]</div>
<p>with <span class="arithmatex">\(X_{1}, \ldots, X_{N} \sim g\)</span> is also an estimator of <span class="arithmatex">\(I\)</span>. Indeed, <span class="arithmatex">\(\mathbb{E}\left[\hat{I}_{N}\right]=I\)</span> and <span class="arithmatex">\(\hat{I}_{N} \rightarrow I\)</span>. The weight <span class="arithmatex">\(\frac{f(x)}{g(x)}\)</span> is called the likelihood ratio or the Radon-Nikodym derivative.</p>
<p>So we can use samples from <span class="arithmatex">\(g\)</span> to compute expectation with respect to <span class="arithmatex">\(f\)</span>.</p>
<h2 id="is-example-low-probability-events">IS example: Low probability events<a class="headerlink" href="#is-example-low-probability-events" title="Permanent link">&para;</a></h2>
<p>Consider the setup of estimating the probability</p>
<div class="arithmatex">\[
\mathbb{P}(X&gt;3)=0.00135
\]</div>
<p>where <span class="arithmatex">\(X \sim \mathcal{N}(0,1)\)</span>. If we use the regular Monte Carlo estimator</p>
<div class="arithmatex">\[
\hat{I}_{N}=\frac{1}{N} \sum_{i=1}^{N} \mathbf{1}_{\left\{X_{i}&gt;3\right\}}
\]</div>
<p>where <span class="arithmatex">\(X_{i} \sim \mathcal{N}(0,1)\)</span>, if <span class="arithmatex">\(N\)</span> is not sufficiently large, we can have <span class="arithmatex">\(\hat{I}_{N}=0\)</span>. Inaccurate estimate.</p>
<p>If we use the IS estimator</p>
<div class="arithmatex">\[
\hat{I}_{N}=\frac{1}{N} \sum_{i=1}^{N} \mathbf{1}_{\left\{Y_{i}&gt;3\right\}} \exp \left(\frac{\left(Y_{i}-3\right)^{2}-Y_{i}^{2}}{2}\right)
\]</div>
<p>where <span class="arithmatex">\(Y_{i} \sim \mathcal{N}(3,1)\)</span>, having <span class="arithmatex">\(\hat{I}_{N}=0\)</span> is much less likely. Estimate is much more accurate.</p>
<h2 id="importance-sampling_1">Importance sampling<a class="headerlink" href="#importance-sampling_1" title="Permanent link">&para;</a></h2>
<p>Benefit of IS quantified by with variance:</p>
<div class="arithmatex">\[
\operatorname{Var}_{X \sim g}\left(\hat{I}_{N}\right)=\sum_{i=1}^{N} \operatorname{Var}_{X \sim g}\left(\frac{\phi\left(X_{i}\right) f\left(X_{i}\right)}{n g\left(X_{i}\right)}\right)=\frac{1}{N} \operatorname{Var}_{X \sim g}\left(\frac{\phi(X) f(X)}{g(X)}\right)
\]</div>
<p>If <span class="arithmatex">\(\operatorname{Var}_{X \sim g}\left(\frac{\phi(X) f(X)}{g(X)}\right)&lt;\operatorname{Var}_{X \sim f}(\phi(X))\)</span>, then IS provides variance reduction.</p>
<p>We call <span class="arithmatex">\(g\)</span> the importance or sampling distribution. Choosing <span class="arithmatex">\(g\)</span> poorly can increase the variance. What is the best choice of <span class="arithmatex">\(g\)</span> ?</p>
<h2 id="optimal-sampling-distribution">Optimal sampling distribution<a class="headerlink" href="#optimal-sampling-distribution" title="Permanent link">&para;</a></h2>
<p>The sampling distribution</p>
<div class="arithmatex">\[
g(x)=\frac{\phi(x) f(x)}{I}
\]</div>
<p>makes <span class="arithmatex">\(\operatorname{Var}_{X \sim g}\left(\frac{\phi(X) f(X)}{g(X)}\right)=\operatorname{Var}_{X \sim g}(I)=0\)</span> and therefore is optimal. (I serves as the normalizing factor that ensures the density <span class="arithmatex">\(g\)</span> integrates to 1.)</p>
<p>Problem: Since we do not know the normalizing factor <span class="arithmatex">\(I\)</span>, the answer we wish to estimate, sampling from <span class="arithmatex">\(g\)</span> is usually difficult.</p>
<h2 id="optimizedtrained-sampling-distribution">Optimized/trained sampling distribution<a class="headerlink" href="#optimizedtrained-sampling-distribution" title="Permanent link">&para;</a></h2>
<p>Instead, we consider the optimization problem</p>
<div class="arithmatex">\[
\underset{g \in \mathcal{G}}{\operatorname{minimize}} \quad D_{\mathrm{KL}}\left(g \| \frac{\phi f}{I}\right)
\]</div>
<p>and compute a suboptimal, but good, sampling distribution within a class of sampling distributions <span class="arithmatex">\(\mathcal{G}\)</span>. (In ML, <span class="arithmatex">\(\mathcal{G}=\left\{g_{\theta} \mid \theta \in \Theta\right\}\)</span> is parameterized by neural networks.)</p>
<p>Importantly, this optimization problem does not require knowledge of <span class="arithmatex">\(I\)</span>.</p>
<div class="arithmatex">\[
\begin{aligned}
D_{\mathrm{KL}}\left(g_{\theta} \| \phi f / I\right) &amp; =\mathbb{E}_{X \sim g_{\theta}}\left[\log \left(\frac{I g_{\theta}(X)}{\phi(X) f(X)}\right)\right] \\
&amp; =\mathbb{E}_{X \sim g_{\theta}}\left[\log \left(\frac{g_{\theta}(X)}{\phi(X) f(X)}\right)\right]+\log I \\
&amp; =\mathbb{E}_{X \sim g_{\theta}}\left[\log \left(\frac{g_{\theta}(X)}{\phi(X) f(X)}\right)\right]+\text { constant independent of } \theta
\end{aligned}
\]</div>
<p>How do we compute stochastic gradients?</p>
<h2 id="log-derivative-trick">Log-derivative trick<a class="headerlink" href="#log-derivative-trick" title="Permanent link">&para;</a></h2>
<p>Generally, consider the setup where we wish to solve</p>
<div class="arithmatex">\[
\underset{\theta \in \mathbb{R}^{p}}{\operatorname{minimize}} \mathbb{E}_{X \sim f_{\theta}}[\phi(X)]
\]</div>
<p>with SGD.
(Previous slide had <span class="arithmatex">\(\theta\)</span>-dependence both on and inside the expectation. For now, let's simplify the problem so that <span class="arithmatex">\(\phi\)</span> does not depend on <span class="arithmatex">\(\theta\)</span>.)</p>
<p>Incorrect gradient computation:</p>
<div class="arithmatex">\[
\nabla_{\theta} \mathbb{E}_{X \sim f_{\theta}}[\phi(X)] \stackrel{?}{=} \mathbb{E}_{X \sim f_{\theta}}\left[\nabla_{\theta} \phi(X)\right]=\mathbb{E}_{X \sim f_{\theta}}[0]=0
\]</div>
<h2 id="log-derivative-trick_1">Log-derivative trick<a class="headerlink" href="#log-derivative-trick_1" title="Permanent link">&para;</a></h2>
<p>Correct gradient computation:</p>
<div class="arithmatex">\[
\begin{aligned}
\nabla_{\theta} \mathbb{E}_{X \sim f_{\theta}}[\phi(X)] &amp; =\nabla_{\theta} \int \phi(x) f_{\theta}(x) d x=\int \phi(x) \nabla_{\theta} f_{\theta}(x) d x \\
&amp; =\int \phi(x) \frac{\nabla_{\theta} f_{\theta}(x)}{f_{\theta}(x)} f_{\theta}(x) d x=\mathbb{E}_{X \sim f_{\theta}}\left[\phi(X) \frac{\nabla_{\theta} f_{\theta}(X)}{f_{\theta}(X)}\right] \\
&amp; =\mathbb{E}_{X \sim f_{\theta}}\left[\phi(X) \nabla_{\theta} \log \left(f_{\theta}(X)\right)\right]
\end{aligned}
\]</div>
<p>Therefore, <span class="arithmatex">\(\phi(X) \nabla_{\theta} \log \left(f_{\theta}(X)\right)\)</span> with <span class="arithmatex">\(X \sim f_{\theta}\)</span> is a stochastic gradient of the loss function. This technique is called the log-derivative trick, the likelihood ratio gradient#, or REINFORCE*.</p>
<p>Formula with the log-derivative <span class="arithmatex">\(\left(\nabla_{\theta} \log (\cdot)\right)\)</span> is convenient when dealing with Gaussians, or more generally exponential families, since the densities are of the form</p>
<div class="arithmatex">\[
f_{\theta}(x)=h(x) \exp (\text { function of } \theta)
\]</div>
<h2 id="log-derivative-trick-example">Log-derivative trick example<a class="headerlink" href="#log-derivative-trick-example" title="Permanent link">&para;</a></h2>
<p>Learn <span class="arithmatex">\(\mu \in \mathbb{R}^{2}\)</span> to minimize the objective below.</p>
<div class="arithmatex">\[
\underset{\mu \in \mathbb{R}^{2}}{\operatorname{minimize}} \mathbb{E}_{X \sim \mathcal{N}(\mu, I)}\left\|X-\binom{5}{5}\right\|^{2}
\]</div>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-438.jpg?height=732&amp;width=881&amp;top_left_y=0&amp;top_left_x=2451" /></p>
<p>Then the loss function is</p>
<div class="arithmatex">\[
\mathcal{L}(\mu)=\mathbb{E}_{X \sim \mathcal{N}(\mu, I)}\left\|X-\binom{5}{5}\right\|^{2}=\int\left\|x-\binom{5}{5}\right\|^{2} \frac{1}{2 \pi} \exp \left(-\frac{1}{2}\|x-\mu\|^{2}\right) d x
\]</div>
<p>And, using <span class="arithmatex">\(X_{1}, \ldots, X_{B} \sim \mathcal{N}(\mu, I)\)</span>, we have stochastic gradients</p>
<div class="arithmatex">\[
\nabla_{\mu} \mathcal{L}(\mu)=\mathbb{E}_{X \sim q_{\mu}}\left[\left\|x-\binom{5}{5}\right\|^{2} \nabla_{\mu}\left(-\frac{1}{2}\|x-\mu\|^{2}\right)\right] \approx \frac{1}{B} \sum_{i=1}^{B}\left\|X_{i}-\binom{5}{5}\right\|^{2}\left(X_{i}-\mu\right)
\]</div>
<p>These stochastic gradients have large variance and thus SGD is slow.</p>
<h2 id="log-derivative-trick-example_1">Log-derivative trick example<a class="headerlink" href="#log-derivative-trick-example_1" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-439.jpg?height=1438&amp;width=1953&amp;top_left_y=395&amp;top_left_x=601" /></p>
<h2 id="reparameterization-trick">Reparameterization trick<a class="headerlink" href="#reparameterization-trick" title="Permanent link">&para;</a></h2>
<p>The reparameterization trick (RT) or the pathwise derivative (PD) relies on the key insight.</p>
<div class="arithmatex">\[
\mathbb{E}_{X \sim \mathcal{N}\left(\mu, \sigma^{2}\right)}[\phi(X)]=\mathbb{E}_{Y \sim \mathcal{N}(0,1)}[\phi(\mu+\sigma Y)]
\]</div>
<p>Gradient computation:</p>
<div class="arithmatex">\[
\begin{aligned}
\nabla_{\mu, \sigma} \mathbb{E}_{X \sim \mathcal{N}\left(\mu, \sigma^{2}\right)}[\phi(X)] &amp; =\mathbb{E}_{Y \sim \mathcal{N}(0,1)}\left[\nabla_{\mu, \sigma} \phi(\mu+\sigma Y)\right]=\mathbb{E}_{Y \sim \mathcal{N}(0,1)}\left[\phi^{\prime}(\mu+\sigma Y)\left[\begin{array}{c}
1 \\
Y
\end{array}\right]\right] \\
&amp; \approx \frac{1}{B} \sum_{i=1}^{B} \phi^{\prime}\left(\mu+\sigma Y_{i}\right)\left[\begin{array}{c}
1 \\
Y_{i}
\end{array}\right], \quad Y_{1}, \ldots, Y_{B} \sim \mathcal{N}(0, I)
\end{aligned}
\]</div>
<p>RT is less general than log-derivative trick, but it usually produces stochastic gradients with lower variance.</p>
<h2 id="reparameterization-trick-example">Reparameterization trick example<a class="headerlink" href="#reparameterization-trick-example" title="Permanent link">&para;</a></h2>
<p>Consider the same example as before</p>
<div class="arithmatex">\[
\mathcal{L}(\mu)=\mathbb{E}_{X \sim \mathcal{N}(\mu, I)}\left\|X-\binom{5}{5}\right\|^{2}=\mathbb{E}_{Y \sim \mathcal{N}(0, I)}\left\|Y+\mu-\binom{5}{5}\right\|^{2}
\]</div>
<p>Gradient computation:</p>
<div class="arithmatex">\[
\begin{aligned}
\nabla_{\mu} \mathcal{L}(\mu) &amp; =\mathbb{E}_{Y \sim \mathcal{N}(0, I)} \nabla_{\mu}\left\|Y+\mu-\binom{5}{5}\right\|^{2}=2 \mathbb{E}_{Y \sim \mathcal{N}(0, I)}\left(Y+\mu-\binom{5}{5}\right) \\
&amp; \approx \frac{2}{B} \sum_{i=1}^{B}\left(Y_{i}+\mu-\binom{5}{5}\right), \quad Y_{1}, \ldots, Y_{B} \sim \mathcal{N}(0, I)
\end{aligned}
\]</div>
<p>These stochastic gradients have smaller variance and thus SGD is faster.</p>
<h2 id="reparameterization-trick-example_1">Reparameterization trick example<a class="headerlink" href="#reparameterization-trick-example_1" title="Permanent link">&para;</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2025_01_07_dc39ed2e168ab0674c3ag-442.jpg?height=1434&amp;width=1974&amp;top_left_y=397&amp;top_left_x=595" /></p>
<div class="language-text highlight"><pre><span></span><code>Dropout (0.5)
Local response normalization (preserves spatial dimension\&amp;channel \#s) (outdated technique)
Max pool $f=3, s=2$ (overlapping max pool)
Fully connected layer+ReLU
</code></pre></div>
<p>[^1]:    *R. M. Schmidt, F. Schneider, and P. Hennig, Descending through a crowded valley — benchmarking deep learning optimizers, ICML, 2021.
    <span class="arithmatex">\({ }^{\dagger}\)</span> M. Tan and Q. V. Le, EfficientNet: Rethinking model scaling for convolutional neural networks, ICML, 2019.
    #A. C. Wilson, R. Roelofs, M. Stern, N. Srebro, and B. Recht, The marginal value of adaptive gradient methods in machine learning, NeurlPS, 2017.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  맨위로
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/arnold518" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../..", "features": ["content.code.copy", "header.autohide", "navigation.instant", "navigation.tracking", "navigation.tabs", "toc.follow", "navigation.top", "search.suggest", "search.highlight", "search.share", "navigation.indexes"], "search": "../../../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "\ud074\ub9bd\ubcf4\ub4dc\uc5d0 \ubcf5\uc0ac\ub428", "clipboard.copy": "\ud074\ub9bd\ubcf4\ub4dc\ub85c \ubcf5\uc0ac", "search.result.more.one": "\uc774 \ubb38\uc11c\uc5d0\uc11c 1\uac1c\uc758 \uac80\uc0c9 \uacb0\uacfc \ub354 \ubcf4\uae30", "search.result.more.other": "\uc774 \ubb38\uc11c\uc5d0\uc11c #\uac1c\uc758 \uac80\uc0c9 \uacb0\uacfc \ub354 \ubcf4\uae30", "search.result.none": "\uac80\uc0c9\uc5b4\uc640 \uc77c\uce58\ud558\ub294 \ubb38\uc11c\uac00 \uc5c6\uc2b5\ub2c8\ub2e4", "search.result.one": "1\uac1c\uc758 \uc77c\uce58\ud558\ub294 \ubb38\uc11c", "search.result.other": "#\uac1c\uc758 \uc77c\uce58\ud558\ub294 \ubb38\uc11c", "search.result.placeholder": "\uac80\uc0c9\uc5b4\ub97c \uc785\ub825\ud558\uc138\uc694", "search.result.term.missing": "\ud3ec\ud568\ub418\uc9c0 \uc54a\uc740 \uac80\uc0c9\uc5b4", "select.version": "\ubc84\uc804 \uc120\ud0dd"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>